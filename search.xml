<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>How to generate access token in Databricks</title>
      <link href="2023/01/20/generate-access-token-in-databricks/"/>
      <url>2023/01/20/generate-access-token-in-databricks/</url>
      
        <content type="html"><![CDATA[<p>In Databricks, personal access tokens can be used for secure authentication to the Databricks API instead of passwords.</p><p>The process of generating a new access token is very easy.</p><p>Step1. Click your user profile (email address) on the top right. Then click User Settings.<br><img src="/content/images/2023-01-20-1.png"></p><p>Step2.  Choose the “Access tokens” menu, and click “Generate new token”.<br>Give it a new name, and choose the expiration date. Then remember copy the token and store somewhere.<br><img src="/content/images/2023-01-20-2.png"></p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> databricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FAISS index and normalization</title>
      <link href="2023/01/18/fais-index-and-normalization/"/>
      <url>2023/01/18/fais-index-and-normalization/</url>
      
        <content type="html"><![CDATA[<p>Previously, we have discussed how to implement a real time semantic search using sentence transformer and FAISS.<br><a href="https://www.datasciencebyexample.com/2023/01/14/embedding-plus-faiss-semantic-search/">real time semantic search</a></p><p>Here, we talk more about indexing in FAISS.<br>The most popular indexes we should look at are the simplest — flat indexes.</p><p>Flat indexes are ‘flat’ because we do not modify the vectors that we feed into them.</p><p>Because there is no approximation or clustering of our vectors — these indexes produce the most accurate results. While we have perfect search quality, this comes at the cost of significant search times.</p><h2 id="Two-flat-indexes"><a href="#Two-flat-indexes" class="headerlink" title="Two flat indexes"></a>Two flat indexes</h2><p>Two common flat index:</p><ul><li>IndexFlatL2, which uses Euclidean/L2 distance</li><li>IndexFlatIP, which uses inner product distance (similar as cosine distance but without normalization)</li></ul><p>The search speed between these two flat indexes are very similar, and IndexFlatIP is slightly faster for larger datasets.<br>See the following query time vs dataset size comparison:<br><img src="/content/images/2023-01-18-1.png"></p><h2 id="how-to-normalize-similarity-metrics"><a href="#how-to-normalize-similarity-metrics" class="headerlink" title="how to normalize similarity metrics"></a>how to normalize similarity metrics</h2><p>If the vectors we indexed are not normalized, the similarity metrics came out from FAISS are not normalized either.<br>For example, sometimes we want to have a cosine similarity metrics, where we can have a more meaningful threshold to compare.</p><p>It’s very easy to do it with FAISS, just need to make sure vectors are normalized before indexing, and before sending the query vector.</p><p>Example code, during indexing time:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">index = faiss.IndexIDMap(faiss.IndexFlatIP(768))</span><br><span class="line">faiss.normalize_L2(encoded_data)</span><br><span class="line">index.add_with_ids(encoded_data, np.array(range(0, len(encoded_data))))</span><br></pre></td></tr></table></figure><p>during query time:</p><pre><code>query_vector = model.encode([query])k = 3faiss.normalize_L2(query_vector)top_k = index.search(query_vector, k)</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> semantic search </tag>
            
            <tag> FAISS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The fanaticism and reality of Web3</title>
      <link href="2023/01/15/the-fanaticism-and-reality-of-Web3/"/>
      <url>2023/01/15/the-fanaticism-and-reality-of-Web3/</url>
      
        <content type="html"><![CDATA[<p>In the past two years, the concept of “Web3” has become increasingly popular in the IT industry. In the past 2022, web3 can be said to be on the cusp of public opinion, and it is really popular.</p><p>But today, many people still feel confused when facing this term, and they don’t know the similarities and differences between it and existing Internet technologies. On the other hand, web3.0 evangelists believe that this technology will become the infrastructure of the next generation Internet, and many companies have also begun to invest in early research and development in related fields. In addition, the relationship between the concept of the metaverse of the fire and web3.0 has also made people curious.</p><p>Recently, InfoQ interviewed Kaiyun Labs CTO Yang Weili (Wiliam Yang). Kaiyun Lab is a start-up company, determined to build a trust-free database for web3. In the interview, Yang Weili shared his many views on the technology of web3, and described a blueprint for a new generation of Internet industry based on web3.</p><h2 id="Web3-boom"><a href="#Web3-boom" class="headerlink" title="Web3 boom"></a>Web3 boom</h2><p><mark> InfoQ: Please explain what web3 is in plain language. At present, is there a generally accepted definition of this technology? </mark><br>Weili Yang: From a technical point of view, we generally think that Web3 is a new generation of Internet ecosystem with decentralized technology as its core. Web3 uses blockchain technology as the core to build a new generation of decentralized Internet components, and then build the services and applications we want to provide based on them. The purpose of building these network components with blockchain technology is to allow users to truly own the Internet, to make the identity and data of Internet users our own, and to make us the masters of the data. We can display personal data through this network and use them to trade and realize.</p><p>From another perspective, in the Web1 era, we can only read data, and read information and information by browsing the web. The biggest change in the Web2 era is that each of our Internet users has become a creator of content, and we are constantly exporting content to the Internet.</p><p>In this process, at first we used a browser to operate on the computer, such as opening a blog page to write an article. With the maturity of the mobile Internet, we are now accustomed to operating on mobile phones, a large number of mobile applications have emerged, and Internet companies have begun to record personal content and data.</p><p>The difference that Web3 brings is that we can make our own decisions about the Internet. For example, Weibo is a product promoted to us by Sina, and all data information is centralized under the management of Sina. And Web3 is a decentralized network, without such a single point of control or management, what these resources in the network should do will be decided by a mechanism similar to public voting. We also have full control over how the data posted by individuals is managed and who has access to our data. At the same time, Web3 resources can always be accessed, and there will be no problem that a certain manufacturer’s server cannot be accessed due to a failure.</p><p>Web3 is an Internet ecosystem centered on decentralized technology. We can compare the ecology of the earth we live in now, and these elements will also be necessary on the Internet. We may only be able to do some limited things on the Internet now, so in the new generation of Internet ecosystem, it can not only meet the traditional needs of our Internet access, but also meet the needs that are getting closer to our real life. some needs. For example, the concept of Metaverse means that the Internet is more like a virtual world, bringing us better and better experiences.</p><p><mark> InfoQ: From the perspective of historical development, do you think the Internet has evolved to the stage of Web3? </mark><br>Weili Yang: We are still in the early stages of the third iteration. First of all, there is a consensus that blockchain technology is the core of the third iteration. This technology has been proposed for many years, and many excellent products and projects have been launched. But from the perspective of end Internet users, these products, as Web3 infrastructure, are not enough to match the Internet products we use every day. From user experience to performance, they are still different from Web2 products in all aspects. In order for the third iteration to enter a relatively mature stage, it must first rely on the further improvement of the underlying infrastructure. For example, for the very important distributed storage technology, although we have seen many promising products at present, compared with the existing storage services, these current Web3 products still need better improvement.</p><p>In addition, for the entire Web3, these future products need to redefine the economic model and user behavior of the Internet. Web3 believes that the personal data of users is valuable. For example, a Weibo article or a video posted by a user is valuable in itself. How is this value reflected in Web3? We can think that readers need to pay, which may sound like a subversion of everyone’s usage habits, but this may be the user behavior pattern of the Internet in the future. It will take a long time for the developers of enterprise products and Internet users to continue to practice and adapt to the new economic model.</p><p><mark> InfoQ: The concept of Web3 has probably become popular in the past year, but it is not a particularly new concept. Then it has suddenly become popular in the past year. What do you think is the main reason?</mark><br>Yang Weili: The concept of Web3 has been particularly popular in the past year, and I can attribute it to two aspects. On the one hand, it is because of the concept of metaverse, and on the other hand, it is NFT. After these two concepts became popular, everyone began to pay attention to and explore, and touched the concept of Web3 behind it.</p><p>What exactly are NFTs? Why is everyone so interested? That’s because NFT allows us to see the so-called digital assets, that is, personal data on the Internet, such as articles and pictures, which have channels for realizing value in Web3. It gives us a possibility. We may be used to using various applications on the Internet to communicate, post articles, pictures, videos… but we may never have thought that NFT can turn the content data we retain on the Internet into value. NFT marks the uniqueness of user assets. For example, Xiao Ming’s book is the only one, which belongs to Xiao Ming. Then I define this book in the form of NFT and record it on the blockchain. Maybe it has some special features. value, so that we can realize it through NFT channels.</p><p>In addition, the epidemic has changed our way of life a lot in the past few years, which has brought the concept of metaverse into flames. The metaverse gives us the possibility of virtualizing office, entertainment and life. When everyone learns about NFT and metaverse, they finally find that the very big concept behind it is Web3, which is why Web3 has become more and more popular in this year. The reason for getting hotter.</p><h2 id="Web3-0-infrastructure-construction"><a href="#Web3-0-infrastructure-construction" class="headerlink" title="Web3.0 infrastructure construction"></a>Web3.0 infrastructure construction</h2><p><mark> InfoQ: What are the differences and advantages of Web3 compared to Web2?</mark><br>Weili Yang: The biggest advantage of Web3 is that Internet users have data ownership. A lot of our personal data is stored on the servers of Internet companies, and these companies completely own and control our user data. Although we use these applications for free, the business always needs to make a profit. Where does the money come from? A large part of it comes from marketing and advertising based on user data, making money in this way. In this mode of single data storage and enterprise side, there are some privacy issues of personal data. We cannot fully control the use of personal data by these enterprises, and we do not know whether they have modified the data, etc.</p><p>A very important point is that in the Web2 era, we cannot guarantee that our personal data can be accessed at any time, because enterprises may cut off access to some resources for some reason. For example, if we upload a picture, the server may be turned off and it will no longer be accessible. In the era of Web3, data is not owned by a certain company, it is securely encrypted and stored on the network. When a party needs to access our data, the user needs to authorize, so that the user can safely manage personal data. There will be a concept of key management in the middle. The user has his own key, he can decide whether the data can be accessed by other services, and this ownership is given to the user, which is the ownership of the data.</p><p>Another aspect is the change of user identity mechanism. With the development of Web3 technology, decentralized identity becomes possible. Decentralized identity is the ability for users to fully manage their identities and data in a decentralized manner. Because blockchain technology provides the functions of non-deletable and ledger, it is distributed, so users can prove themselves through cryptographically verifiable digital identities, which is a very safe way of proof without revealing our personal information.</p><p>Another very important difference is the form of organizational governance. The organizational form of Web3 will change fundamentally. The current mainstream organizational form is a company, which needs to be registered and has employees and different roles. The management is responsible for the company’s future development according to the company’s system and their decisions. In Web3, there is a decentralized autonomous organization. In this form of organization, there will be no CEO, but the holders of tokens. The organization will pre-set its structure and rules, define them in the form of smart contracts, publish them on the network, and all rules will be strictly enforced. In this way, some privileges of a small group of people will not cause company decisions to be made or implemented in a democratic manner, and promote the democratization of Web3 organizational management.</p><p>Finally, just because there is no single entity in Web3, all architectures are decentralized. Therefore, on such an ecosystem, data and services can always be accessed and cannot be blocked, and transaction data cannot be blocked. All are stored on the blockchain and cannot be tampered with. The above is the biggest difference between Web3 and Web2.</p><p><mark> InfoQ: Will Web3 coexist with Web2 next, or will it completely replace the latter after a certain stage?</mark><br>Weili Yang: I think it depends on how we define Web3 and Web2. From a technical point of view, both Web3 and Web2 make full use of the achievements of human beings in the fields of computer science and non-computer science. They just present different user experiences for Internet users, define different roles of users, and serve users. In Web2, we can think that users are only using some functions provided by the Internet, and do not really fully own the Internet. Personal data is not completely for their own use, and cannot be traded for cash, and cannot reflect its more value.</p><p>When the Internet develops to Web3, users have different roles, and we become the masters of these data, we can perform some operations on it, and even sell it. From a technical point of view, Web3 is not the opposite of Web2, so it does not mean that with Web3, Web2 will be subverted, and there will be no more. Up to now, Web3 has not had any disruptive new technologies. Instead, it still uses some relatively mature technologies and concepts in the Internet, and has carried out certain innovations and reorganizations to bring a new concept to the Internet. The Web3 community also draws on a lot of Web2 technical achievements.</p><p>In the near future, we should be able to see that entrepreneurs in the Web3 field launch a large number of innovative products. For example, the decentralized blog in Web3 can always be accessed. Even if one or two host servers in the network are shut down, or even leave the network permanently, our access to these articles will not be affected. From the perspective of users, we will see that some Internet application products have been successfully copied from 2.0 to 3.0. As for whether the game between them will eventually lead to the demise of 2.0 products, it will take time to tell us. There is a very high probability that they will coexist, it all depends on the user. If our users can adapt to different economic models or user behaviors, this model may coexist.</p><p><mark> InfoQ: Facing the current upsurge, how should Web2 companies deploy Web3?</mark><br>Weili Yang: At present, a large number of Web2 companies have begun to pay attention to this emerging field. To start the layout in this field, the first thing is to do research based on the company’s own business model. At least you should understand what Web3 is and what different experiences it can bring to the company’s users. The company should once again think about the issue of user value from the perspective of users, and help users realize value transfer. At the same time, after all, Web2 companies provide users with services and products to make profits, so we have to consider how to make the same money under the new technical architecture and business model. In the Web3 era, companies can no longer control all user data, so can advertising still be done? Does this kind of money-making channel still exist? If you can no longer make money in this way, how can you make money? This is a very important point that Web2 companies have to consider.</p><p>We believe that companies should take the initiative to investigate the feasibility of blockchain technology in the company’s business and consider how to reconstruct our business model. A change that is required in the future is to provide a transaction and realization platform for user data through the blockchain, and earn service fees for it. Still take the blog system as an example. In the era of Web3, the articles posted by bloggers may already have value, and users will naturally have to pay to read his articles, so that bloggers can earn profits. So how will this profit be given to this enterprise? The publisher of the blog system can charge a certain handling fee from this transaction to obtain profits. Of course, whether this income situation can support the company’s operations and ensure that the company makes money is something that Web2 companies need to investigate.</p><p>On the other hand, many Web2 companies are originally engaged in Internet infrastructure, and it is necessary for such companies to deploy Web3. Because Web3 has a very big goal in decentralized storage and distributed storage, Web2 companies can use existing mature technology and experience to quickly enter the Web3 field, and in this field, earn the first pot of gold as a pioneer , to establish their industry status in this field.</p><p><mark> InfoQ: Decentralization is considered to be the core feature of Web3. Can you explain to us in detail how web3.0 makes the Internet decentralized?</mark><br>Weili Yang: The technology stack of Web3 can be divided into five layers from bottom to top. The first is the infrastructure and network layer, which provides the communication mechanism, interface, protocol, etc. of the entire Internet. The most famous one is P2P, a peer-to-peer network protocol. Blockchain technology is also established based on P2P, which provides a decentralized foundation for Web3 from the bottom layer. There is a layer above it called the middle layer, or the off-chain layer, and then the protocol layer, which can also be called the on-chain layer. The purpose of the middle layer is to solve the scalability and performance problems of the protocol layer, and transfer part of the computing work from the blockchain to the off-chain solution. Above these three layers are the API layer and the application layer, which provide developers and ordinary Internet users with blockchain access interfaces. These layers provide us with a decentralized mechanism layer by layer, thus realizing the decentralization of the entire Internet.</p><p><mark> InfoQ: Blockchain is the key technology behind Web3.0, why will blockchain become the core of this Internet iteration (revolution)?</mark><br>Weili Yang: When we defined Web3, we expected the Internet to undergo another revolution, expecting users to truly own their data and determine the shape of the Internet. We found that decentralization can achieve this goal for us, and decentralization is just the product of blockchain technology, so blockchain has become the very core infrastructure of Web3.</p><p>Blockchain is an implementation of a distributed database. Once the data is connected to the chain, it cannot be modified, so it also solves the problem of data exchange between different websites. There is only one copy of user data, which is stored on the Web3 network and on the blockchain; different products and applications that need to access the user’s personal data require user authorization. But there is only one piece of data, as long as it can be authorized, it can use its data under the authorization of the user, which solves the problem of data exchange between websites or applications to a certain extent.</p><p><mark> InfoQ: Is blockchain the only technical support for realizing Web3? What role do these technologies such as artificial intelligence, machine learning, and cloud play in the Web3 world? Now, has the infrastructure construction of Web3 entered a mature stage?</mark><br>Yang Weili: The blockchain only provides a means of decentralized distributed accounting, and the core components necessary for Web3 include storage, computing, and networking. Then the blockchain can solve some problems for us, such as storage, and it may also Solve some computational problems. At present, with the development of IPFS technology, decentralized storage is gradually taking shape, but it has not yet reached the level in the vision and needs further development.</p><p>Next is calculation. Smart contracts have brought us computing power. Developers of Web3 applications can define business logic based on smart contracts. Smart contracts help with specific calculations and implementations to support Web3 applications. Artificial intelligence, machine learning, and cloud technology are relatively higher-level applications, and they will also be applied to Web3. For example, artificial intelligence can distribute data more efficiently and intelligently, and optimize network performance. Behind cloud computing is a distributed technical architecture, which is not particularly different from Web3 in terms of technology. These mature cloud vendors now have a lot of experience and technology accumulation, which will greatly promote the development of Web3. At the same time, these cloud service providers are very likely to play the role of pioneers in the Web3 field, and they may be the first to usher in industrial changes.</p><p>In terms of Web3 infrastructure construction, from the perspective of the five-tier architecture, each field has star products. Web3 is still in the early stage of development, so artificial intelligence and cloud technology can be applied to the field of Web3. There are no disruptive new technologies in the Web3 field. It is more about the integration of current mature technologies and achievements, so as to solve some pain points in the Internet.</p><p><mark> InfoQ: What is the current status of Web3 application development?</mark><br>Yang Weili: The current development work is mainly divided into two aspects. On the one hand, some innovations based on decentralized technology are still in the prototype stage to a certain extent. In this aspect, relatively few people will use or try them.</p><p>Another major direction is to move the mature products of Web2 to Web3. For example, products such as Youtube and Facebook have competing products on Web3. Because the community ecology of Web3 is very active, developers are also happy to deploy these mature products and concepts on Web3. This in itself is very important to the infrastructure development of Web3, because the needs of users and the functional requirements of products can reflect the insufficiency of the infrastructure, thereby promoting the further development of the infrastructure, which is a very good promotion for Web3 itself.</p><p><mark> InfoQ: What is the employment situation in the Web3 space?</mark><br>Weili Yang: Over the past year, the Web3 entrepreneurial boom has continued to heat up. There are indeed a large number of Web2 engineers transitioning to Web3. This trend must exist. As for more and less, this is indeed a relative concept, which is not easy to measure.</p><p>There are also many domestic teams dedicated to the technical research and development of Web3-related fields, but there is still no established ecosystem of Web3 in China. On the other hand, how to define the practitioners of Web3 is also a problem. We cannot say that someone is researching the blockchain, he is a practitioner of Web3, and this definition cannot be clarified.</p><p><mark> InfoQ: If there is an engineer who wants to become a Web3 developer, what skills should he learn?</mark><br>Yang Weili: In the field of Web3, especially the block chain, the entire community prefers programming languages, one is Go and the other is Rust, and these two are also the preferred languages ​​for development. The programming skills of Web3 developers are important in this area. JavaScript also has a decent percentage of usage. Of course, as a developer, basic computer science knowledge is necessary, and you must be familiar with data, structures, algorithms, and networks. You also need to understand the fields of distributed systems, blockchain technology, and smart contracts.</p><p><mark> InfoQ: For today’s technology companies, since Web3 is the future form of the Internet, should everyone be aware of it from now on, and more or less start to prepare for the future?</mark><br>Yang Weili: Yes. Technology companies should examine Web3 technology from the perspective of user value to see what kind of user experience it can bring to users, including data integration, personal privacy data protection, and high security. Blockchain technologies are very important. Important, but not the highest priority. After all, technology companies still consider corporate profits and business models, so they have to think about what role blockchain technology can play in the business model, and what changes other components in Web3 can bring to the business model of technology companies. What form will the company’s products be provided to users.</p><p>The other is the subject of marketing. At present, marketing is still a very important channel to acquire customers, but Web3 will be different. The focus in the Web3 world is to build consumer and customer communities, and to drive the arrival of new customers by motivating the first batch of users. In the age of Web3, all enterprises need to consider this question.</p><h2 id="next-generation-Internet"><a href="#next-generation-Internet" class="headerlink" title="next generation Internet?"></a>next generation Internet?</h2><p><mark> InfoQ: As the next generation of Internet, Web3 has now entered the initial stage. So will its actual realization be anything iconic?</mark><br>Yang Weili: It should be difficult to have a clear sign, event, and time point. The consensus we can reach on Web3 is that Internet users can truly own personal data, which is a very different Internet ecology. Then as we feel more and more changes in our own permissions in our daily Internet use, we may gradually feel the arrival of Web3.</p><p>Another very important point is the value of users. In the era of Web2, we may not realize this concept. We don’t pay to use the Internet now, and most apps are free to use. It is very likely that in the Web3 ecology, we have to pay for using the Internet, which is very different from the current usage habits, but this is likely to be a reality in the Web3 ecology.</p><p>So how do users get income to pay for this fee? In Web3, it is very likely that everyone is valuable on the Internet. We can create value in this virtual world. Everyone’s value is not only reflected in offline work, but also online. If we have writing skills, we can monetize our works. If we are good at music, we can monetize music works. Everyone not only consumes content on the Internet, but also has the ability to monetize our own value. When it comes to payment channels, there are also digital wallets in Web3. Digital wallets can facilitate the management of our digital assets and personal identities. Things that seem troublesome now will have very convenient solutions.</p><p><mark> InfoQ: What are the differences and connections between the concepts of Web3 and Metaverse?</mark><br>Weili Yang: There is no necessary connection between Web3 and the Metaverse. The reason why people often compare them is that Metaverse and Web3 have many intersections at the core technology level. But Metaverse puts more emphasis on the concept of virtual reality, mainly to allow users to interact virtualized. Web3 is not limited to this direction, it is a decentralized network based on blockchain technology. Metaverse will use some very important technologies and infrastructure in Web3, so we can regard Metaverse as a form of Web3 to a certain extent.</p><p>On the other hand, many giants are betting on the metaverse field, so how decentralized are the metaverse products or concepts they launched? This is a very worthwhile question. If they are still making very centralized products, they will be very different from Web3. From this perspective, it is also difficult for us to define the future of the Internet as a metaverse. What route these companies hope to take in the field of Web3 and Metaverse must also follow their own research and decision-making. It is difficult to say that they will definitely develop in this direction in the future.</p><p><mark> InfoQ: Why did Kaiyun Lab decide to make a layout in this direction? What actions has your company made around this strategy?</mark><br>Weili Yang: Kaiyun Lab has been doing research on storage and computing for a long time. We are also optimistic about and recognize the field of decentralized distributed storage and computing, and believe that they are the two cornerstones of Web3. Because we are also optimistic about the future of Web3, we have conducted long-term research in this field and finally determined the main battlefield of decentralized storage.</p><p>In this field, we also found that there is still a long way to go for decentralized storage, so we have invested a lot of research and development resources to improve the scalability of storage and retrieval in the form of open source solutions, combined with decentralized databases and Decentralized computing provides computing power for the entire storage, and expects to provide data processing capabilities for the decentralized network, making data truly valuable.</p><p>What we are currently focusing on building is a Web3 database with ledger functions, aiming to provide storage and computing solutions for Web3. Judging from the current development, because the entire Web3 ecology is still a bottom-up layered architecture, we should first consolidate the bottom layer, and then gradually develop to the application layer. Only with a complete infrastructure can we provide a complete user experience interface.</p><h2 id="Controversy-and-the-future"><a href="#Controversy-and-the-future" class="headerlink" title="Controversy and the future"></a>Controversy and the future</h2><p><mark> InfoQ: There are also some opposing voices about the concept of Web3, and many articles say it is a hoax. What do you think of some doubting voices that exist today?</mark><br>Yang Weili: First of all, this concept is very popular. At the same time, because Web3 is gradually improving and maturing based on some technologies we now recognize, there will be a small number of people who take advantage of the loopholes in technology and supervision to carry out the so-called behavior of cutting leeks. Of course, I think the emergence of these scams and problems is also an education for the public. The Web3 ecology is definitely not a scam game, and the emergence of these scams or problems reflects some of the current problems in Web3. Feedback from the market can help Web3 continue to mature and develop, and this so-called behavior of cutting leeks will become less and less.</p><p>Specifically, from the perspective of the economic model of Web3, the rules of the game in this ecosystem are not perfect, and these loopholes are just used by these illegal people to carry out some leek-cutting behaviors. Just like in the process of making software in the early days, there will be many fatal flaws and loopholes in the IT industry. It is through the feedback from the market and users that we discover these loopholes, thereby promoting the continuous development of the technical field of the software industry, and then making up for these loopholes to provide better products. I believe that Web3 will also go through the same process.</p><p>In the end, there are still many areas to be explored in the development of Web3. The reason why the mainstream of the Internet is centralized technology is also because the technology itself is not enough to make these platforms decentralized. Since it is currently centralized, it still has something we can explore. Practitioners of Web3 can think about how to turn it into a decentralized architecture. At present, many organizations in the world, including domestic industries and universities, are actively exploring, researching and trying technologies in the Web3 field, and many innovative achievements have emerged.</p>]]></content>
      
      
      <categories>
          
          <category> web3 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Real time in memory semantic search with deep learning embedding and FAISS</title>
      <link href="2023/01/14/embedding-plus-faiss-semantic-search/"/>
      <url>2023/01/14/embedding-plus-faiss-semantic-search/</url>
      
        <content type="html"><![CDATA[<p>We use sentence transformer to encode short texts, and then index the results using in memory search engine FAISS;<br>Togehter we can achieve real time performance of the semantic search simply on CPU platforms.</p><h1 id="install-packages-if-necessary"><a href="#install-packages-if-necessary" class="headerlink" title="install packages if necessary"></a>install packages if necessary</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install faiss-cpu</span><br><span class="line">!pip install -U sentence-transformers</span><br></pre></td></tr></table></figure><h1 id="import-libraries"><a href="#import-libraries" class="headerlink" title="import libraries"></a>import libraries</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> faiss</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = SentenceTransformer(<span class="string">&#x27;distilbert-base-nli-mean-tokens&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.encode([<span class="string">&#x27;how are you&#x27;</span>])[<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure><pre><code>(768,)</code></pre><h1 id="get-data"><a href="#get-data" class="headerlink" title="get data"></a>get data</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = fetch_20newsgroups()[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">subjects = [item.split(<span class="string">&#x27;\n&#x27;</span>)[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> data]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">subjects[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><pre><code>[&#39;Subject: WHAT car is this!?&#39;, &#39;Subject: SI Clock Poll - Final Call&#39;, &#39;Subject: PB questions...&#39;, &#39;Subject: Re: Weitek P9000 ?&#39;, &#39;Subject: Re: Shuttle Launch Question&#39;, &#39;Subject: Re: Rewording the Second Amendment (ideas)&#39;, &#39;Subject: Brain Tumor Treatment (thanks)&#39;, &#39;Subject: Re: IDE vs SCSI&#39;, &#39;Subject: WIn 3.0 ICON HELP PLEASE!&#39;, &#39;Subject: Re: Sigma Designs Double up??&#39;]</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">encoded_data = model.encode(subjects)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">encoded_data.shape</span><br></pre></td></tr></table></figure><pre><code>(11314, 768)</code></pre><h1 id="indexing-the-dataset"><a href="#indexing-the-dataset" class="headerlink" title="indexing the dataset"></a>indexing the dataset</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">index = faiss.IndexIDMap(faiss.IndexFlatIP(<span class="number">768</span>))</span><br><span class="line">index.add_with_ids(encoded_data, np.array(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(encoded_data))))</span><br></pre></td></tr></table></figure><h2 id="serializing-the-index-to-disk-The-serialized-index-can-be-then-exported-into-any-machine-for-hosting-the-search-engine"><a href="#serializing-the-index-to-disk-The-serialized-index-can-be-then-exported-into-any-machine-for-hosting-the-search-engine" class="headerlink" title="serializing the index to disk, The serialized index can be then exported into any machine for hosting the search engine"></a>serializing the index to disk, The serialized index can be then exported into any machine for hosting the search engine</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">faiss.write_index(index, <span class="string">&#x27;20news&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="read-the-index-back-from-disk-for-demo-purpose-so-called-desearializing"><a href="#read-the-index-back-from-disk-for-demo-purpose-so-called-desearializing" class="headerlink" title="read the index back from disk for demo purpose,  so called desearializing"></a>read the index back from disk for demo purpose,  so called desearializing</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">index = faiss.read_index(<span class="string">&#x27;20news&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="Now-do-the-semantic-search"><a href="#Now-do-the-semantic-search" class="headerlink" title="Now do the semantic search"></a>Now do the semantic search</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">query</span>):</span></span><br><span class="line">    start=time.time()</span><br><span class="line">    query_vector = model.encode([query])</span><br><span class="line">    k = <span class="number">5</span></span><br><span class="line">    top_k = index.search(query_vector, k)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;spent time: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(time.time()-start))</span><br><span class="line">    <span class="keyword">return</span> [subjects[_<span class="built_in">id</span>] <span class="keyword">for</span> _<span class="built_in">id</span> <span class="keyword">in</span> top_k[<span class="number">1</span>].tolist()[<span class="number">0</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># type the query</span></span><br><span class="line"><span class="comment"># query=str(input())</span></span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;auto&quot;</span></span><br><span class="line">results=search(query)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;results :&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;\t&#x27;</span>,result)</span><br></pre></td></tr></table></figure><pre><code>spent time: 0.035505056381225586results :     Subject: (w)rec.autos     Subject: Re: DRIVE     Subject: WHAT car is this!?     Subject: Re: WHAT car is this!?     Subject: Car AMP [Forsale]</code></pre><h1 id="Code-link"><a href="#Code-link" class="headerlink" title="Code link"></a>Code link</h1><p><a href="https://github.com/robotlearner001/blog/blob/main/embedding-plus-faiss/2023-01-13-sentence-transformer-ebmedding-faiss-semantic-search.ipynb">github link</a></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> semantic search </tag>
            
            <tag> FAISS </tag>
            
            <tag> vector search </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Feature reduction and visualization using autoencoder with Pytorch</title>
      <link href="2022/12/19/autoencoder-feature-reduction-and-visualization-pytorch/"/>
      <url>2022/12/19/autoencoder-feature-reduction-and-visualization-pytorch/</url>
      
        <content type="html"><![CDATA[<p>In this notebook, we are going to use autoencoder architecture in Pytorch to reduce feature dimensions and visualiations.</p><p>First, to install PyTorch, you may use the following pip command,</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip install torch torchvision</span><br></pre></td></tr></table></figure><p>The <code>torchvision</code> package contains the image data sets that are ready for use in PyTorch.</p><p>More details on its installation through <a href="https://pytorch.org/get-started/locally/">this guide</a> from <a href="pytorch.org">pytorch.org</a>.</p><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>importing relevant dependencies.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br></pre></td></tr></table></figure><p>Set seed and other configurations for reproducibility.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">21</span></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>Set the batch size, the number of training epochs, and the learning rate.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">512</span></span><br><span class="line">epochs = <span class="number">50</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br></pre></td></tr></table></figure><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>load the MNIST dataset as a convienient exampe using the <code>torchvision</code> package. </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&quot;~/torch_datasets&quot;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>check one example data</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">examples = <span class="built_in">enumerate</span>(train_loader)</span><br><span class="line">batch_idx, (example_data, example_targets) = <span class="built_in">next</span>(examples)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">example_data[<span class="number">0</span>][<span class="number">0</span>].<span class="built_in">max</span>()</span><br></pre></td></tr></table></figure><pre><code>tensor(1.)</code></pre><h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><p>An autoencoder is a type of neural network that finds the function mapping the features x to itself. This objective is known as reconstruction, and an autoencoder accomplishes this through the following process:<br>(1) an encoder learns the data representation in lower-dimension space,<br>(2) a decoder learns to reconstruct the original data based on the learned representation by the encoder.</p><p>In the following we define our autoencoder class with fully connected layers and activation functions for both its encoder and decoder components.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AE</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.encoder_hidden_layer = nn.Linear(</span><br><span class="line">            in_features=kwargs[<span class="string">&quot;input_shape&quot;</span>], out_features=<span class="number">1000</span></span><br><span class="line">        )</span><br><span class="line">        self.encoder_output_layer = nn.Linear(</span><br><span class="line">            in_features=<span class="number">1000</span>, out_features=<span class="number">128</span></span><br><span class="line">        )</span><br><span class="line">        self.encoder_output_layer2 = nn.Linear(</span><br><span class="line">            in_features=<span class="number">128</span>, out_features=<span class="number">32</span></span><br><span class="line">        )</span><br><span class="line">        self.encoder_output_layer3 = nn.Linear(</span><br><span class="line">            in_features=<span class="number">32</span>, out_features=<span class="number">2</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">            </span><br><span class="line">        self.decoder_hidden_layer = nn.Linear(</span><br><span class="line">            in_features=<span class="number">2</span>, out_features=<span class="number">32</span></span><br><span class="line">        )</span><br><span class="line">        self.decoder_hidden_layer2 = nn.Linear(</span><br><span class="line">            in_features=<span class="number">32</span>, out_features=<span class="number">128</span></span><br><span class="line">        )</span><br><span class="line">        self.decoder_hidden_layer3 = nn.Linear(</span><br><span class="line">            in_features=<span class="number">128</span>, out_features=<span class="number">1000</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        self.decoder_output_layer = nn.Linear(</span><br><span class="line">            in_features=<span class="number">1000</span>, out_features=kwargs[<span class="string">&quot;input_shape&quot;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">self, features: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        code = self.encoder_hidden_layer(features)</span><br><span class="line">        code = torch.relu(code)</span><br><span class="line">        code = self.encoder_output_layer(code)</span><br><span class="line">        code = torch.relu(code)</span><br><span class="line">        code = self.encoder_output_layer2(code)</span><br><span class="line">        code = torch.relu(code)</span><br><span class="line">        code = self.encoder_output_layer3(code)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> code</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">self, encoded: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        </span><br><span class="line">        encode = self.decoder_hidden_layer(encoded)</span><br><span class="line">        encode = torch.relu(encode)</span><br><span class="line">        encode = self.decoder_hidden_layer2(encode)</span><br><span class="line">        encode = torch.relu(encode)</span><br><span class="line">        encode = self.decoder_hidden_layer3(encode)</span><br><span class="line">        encode = torch.relu(encode)</span><br><span class="line">        encode = self.decoder_output_layer(encode)</span><br><span class="line">        reconstructed = torch.sigmoid(encode)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> reconstructed   </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        encoded = self.encode(features)</span><br><span class="line">        <span class="keyword">return</span> self.decode(encoded)</span><br></pre></td></tr></table></figure><p>Before using our defined autoencoder class, we have the following things to do:<br>    1. We configure which device we want to run on.<br>    2. We instantiate an <code>AE</code> object.<br>    3. We define our optimizer.<br>    4. We define our reconstruction loss.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  use gpu if available</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a model from `AE` autoencoder class</span></span><br><span class="line"><span class="comment"># load it to the specified device, either gpu or cpu</span></span><br><span class="line">model = AE(input_shape=<span class="number">784</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create an optimizer object</span></span><br><span class="line"><span class="comment"># Adam optimizer with learning rate 1e-3</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean-squared error loss</span></span><br><span class="line">criterion = nn.MSELoss()</span><br></pre></td></tr></table></figure><p>We train our autoencoder for our specified number of epochs.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_features, _ <span class="keyword">in</span> train_loader:</span><br><span class="line">        <span class="comment"># reshape mini-batch data to [N, 784] matrix</span></span><br><span class="line">        <span class="comment"># load it to the active device</span></span><br><span class="line">        batch_features = batch_features.view(-<span class="number">1</span>, <span class="number">784</span>).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># reset the gradients back to zero</span></span><br><span class="line">        <span class="comment"># PyTorch accumulates gradients on subsequent backward passes</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># compute reconstructions</span></span><br><span class="line">        outputs = model(batch_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># compute training reconstruction loss</span></span><br><span class="line">        train_loss = criterion(outputs, batch_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># compute accumulated gradients</span></span><br><span class="line">        train_loss.backward()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># perform parameter update based on current gradients</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># add the mini-batch training loss to epoch loss</span></span><br><span class="line">        loss += train_loss.item()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute the epoch training loss</span></span><br><span class="line">    loss = loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># display the epoch training loss</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;epoch : &#123;&#125;/&#123;&#125;, recon loss = &#123;:.8f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, epochs, loss))</span><br></pre></td></tr></table></figure><pre><code>epoch : 1/50, recon loss = 0.07389576epoch : 2/50, recon loss = 0.05296296epoch : 3/50, recon loss = 0.04810659epoch : 4/50, recon loss = 0.04541392epoch : 5/50, recon loss = 0.04336656epoch : 6/50, recon loss = 0.04195889epoch : 7/50, recon loss = 0.04092639epoch : 8/50, recon loss = 0.04033839epoch : 9/50, recon loss = 0.03984492epoch : 10/50, recon loss = 0.03948938epoch : 11/50, recon loss = 0.03939159epoch : 12/50, recon loss = 0.03877884epoch : 13/50, recon loss = 0.03859487epoch : 14/50, recon loss = 0.03825530epoch : 15/50, recon loss = 0.03797148epoch : 16/50, recon loss = 0.03789599epoch : 17/50, recon loss = 0.03754379epoch : 18/50, recon loss = 0.03740290epoch : 19/50, recon loss = 0.03735819epoch : 20/50, recon loss = 0.03729593epoch : 21/50, recon loss = 0.03699356epoch : 22/50, recon loss = 0.03768872epoch : 23/50, recon loss = 0.03694447epoch : 24/50, recon loss = 0.03680794epoch : 25/50, recon loss = 0.03654349epoch : 26/50, recon loss = 0.03630730epoch : 27/50, recon loss = 0.03620429epoch : 28/50, recon loss = 0.03615394epoch : 29/50, recon loss = 0.03615029epoch : 30/50, recon loss = 0.03593704epoch : 31/50, recon loss = 0.03589566epoch : 32/50, recon loss = 0.03570651epoch : 33/50, recon loss = 0.03599412epoch : 34/50, recon loss = 0.03587519epoch : 35/50, recon loss = 0.03641265epoch : 36/50, recon loss = 0.03615064epoch : 37/50, recon loss = 0.03541873epoch : 38/50, recon loss = 0.03545310epoch : 39/50, recon loss = 0.03534035epoch : 40/50, recon loss = 0.03541123epoch : 41/50, recon loss = 0.03511182epoch : 42/50, recon loss = 0.03499481epoch : 43/50, recon loss = 0.03487989epoch : 44/50, recon loss = 0.03506399epoch : 45/50, recon loss = 0.03487079epoch : 46/50, recon loss = 0.03481269epoch : 47/50, recon loss = 0.03454635epoch : 48/50, recon loss = 0.03444027epoch : 49/50, recon loss = 0.03448961epoch : 50/50, recon loss = 0.03482613</code></pre><p>Let’s extract some test examples to reconstruct using our trained autoencoder.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_dataset = torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&quot;~/torch_datasets&quot;</span>, train=<span class="literal">False</span>, transform=transform, download=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    test_dataset, batch_size=<span class="number">10</span>, shuffle=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_examples = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># loop the test data once to get the first batch of 10 datapoints for reconstruction quality check</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> batch_features <span class="keyword">in</span> test_loader:</span><br><span class="line">        batch_features = batch_features[<span class="number">0</span>]</span><br><span class="line">        test_examples = batch_features.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">        reconstruction = model(test_examples)</span><br><span class="line">        reconstruction_hidden = model.encode(test_examples)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h2 id="Visualize-Reconstruction-Quality"><a href="#Visualize-Reconstruction-Quality" class="headerlink" title="Visualize Reconstruction Quality"></a>Visualize Reconstruction Quality</h2><p>Let’s try to reconstruct some test images using our trained autoencoder.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    number = <span class="number">10</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">20</span>, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(number):</span><br><span class="line">        <span class="comment"># display original</span></span><br><span class="line">        ax = plt.subplot(<span class="number">2</span>, number, index + <span class="number">1</span>)</span><br><span class="line">        plt.imshow(test_examples[index].numpy().reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">        plt.gray()</span><br><span class="line">        ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># display reconstruction</span></span><br><span class="line">        ax = plt.subplot(<span class="number">2</span>, number, index + <span class="number">1</span> + number)</span><br><span class="line">        plt.imshow(reconstruction[index].numpy().reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">        plt.gray()</span><br><span class="line">        ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-12-19-1.png" alt="png"></p><h2 id="Analysis-so-far"><a href="#Analysis-so-far" class="headerlink" title="Analysis so far"></a>Analysis so far</h2><p>as we can see the reconstruciton is good, but not super great; this is mainly because we use only 2 nodes for the<br>middle hidden layer. Using only 2 nodes is easy for us to see the reduced dimensions, but probably not good enough<br>to capture all the sailent features. For pure feature reduction purpose, we can choose a bigger number of nodes<br>for the middel hidden layer.</p><h2 id="Visualize-the-middel-hidden-layer-with-2-nodes-for-lower-dimension-reduction"><a href="#Visualize-the-middel-hidden-layer-with-2-nodes-for-lower-dimension-reduction" class="headerlink" title="Visualize the middel hidden layer with 2 nodes for lower dimension reduction"></a>Visualize the middel hidden layer with 2 nodes for lower dimension reduction</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reduce dimension example</span></span><br><span class="line"></span><br><span class="line">results =[]</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> batch_features <span class="keyword">in</span> test_loader:</span><br><span class="line">        batch_features = batch_features[<span class="number">0</span>]</span><br><span class="line">        test_examples = batch_features.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">        reconstruction_hidden = model.encode(test_examples)</span><br><span class="line">        results.append(reconstruction_hidden.numpy())</span><br><span class="line">        </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">all_hidden = np.concatenate(results)</span><br><span class="line">all_hidden</span><br></pre></td></tr></table></figure><pre><code>array([[-0.43485078,  0.31671965],       [ 1.5935664 ,  4.4088674 ],       [ 9.075943  ,  4.4781566 ],       ...,       [-0.90027434,  0.3994102 ],       [-2.9567816 ,  2.2586362 ],       [-4.884531  ,  1.9589175 ]], dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels = test_dataset.targets.numpy()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">rdf = pd.DataFrame(all_hidden)</span><br><span class="line">rdf[<span class="string">&#x27;lable&#x27;</span>] = labels</span><br><span class="line">rdf.columns = [<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))  </span><br><span class="line">sns.scatterplot(data=rdf,x=<span class="string">&#x27;x&#x27;</span>,y=<span class="string">&#x27;y&#x27;</span>,hue=<span class="string">&#x27;label&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;AxesSubplot:xlabel=&#39;x&#39;, ylabel=&#39;y&#39;&gt;</code></pre><p><img src="/content/images/2022-12-19-2.png" alt="png"></p><h2 id="code-link"><a href="#code-link" class="headerlink" title="code link"></a>code link</h2><p><a href="https://github.com/robotlearner001/blog/blob/main/autoencoder-pytorch-feature-reduction-and-visualization/2022-12-19-autoencoder-feature-reduction-visualization-in-pytorch.ipynb">code link</a></p>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> deep learning </tag>
            
            <tag> autoencoder </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Revolutionizing Robotics, How RT-1 is Paving the Way for Intelligent Machines</title>
      <link href="2022/12/15/revolutionizing-robotics-the-emergence-of-RT-1/"/>
      <url>2022/12/15/revolutionizing-robotics-the-emergence-of-RT-1/</url>
      
        <content type="html"><![CDATA[<p>Great progress of robotics and learning from language models.</p><p>Researchers at OpenAI have developed the Robotics Transformer 1 (RT-1), a machine learning model that’s designed to help robots learn from large and diverse datasets. </p><p>RT-1, which is built on a transformer architecture, takes a short history of images from a robot’s camera alongside task descriptions, expressed in natural language, as inputs and directly outputs tokenized actions such as motor commands. </p><p>RT-1 is trained on a real-world robotics dataset of 130,000 episodes covering over 700 tasks, and is able to exhibit improved zero-shot generalisation to new tasks and environments compared to previous techniques. </p><p>RT-1 is also able to compress image tokens and adaptively select soft combinations that can be compressed based on their impact towards learning, resulting in a more than 2.4x inference speed-up.</p><h2 id="open-source-links"><a href="#open-source-links" class="headerlink" title="open source links"></a>open source links</h2><p><a href="https://github.com/google-research/robotics_transformer">code link</a><br><a href="https://robotics-transformer.github.io/assets/rt1.pdf">paper link</a><br><a href="https://robotics-transformer.github.io/">project website</a></p>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> robotics </tag>
            
            <tag> news </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A list of poupular but hard leetcode problems for interview</title>
      <link href="2022/12/14/populad-and-hard-leetcode-problems-and-solutions/"/>
      <url>2022/12/14/populad-and-hard-leetcode-problems-and-solutions/</url>
      
        <content type="html"><![CDATA[<p>Here is the list most popular but hard interview questions that according to leetcode.</p><h2 id="List-of-problems-and-solutions"><a href="#List-of-problems-and-solutions" class="headerlink" title="List of problems and solutions"></a>List of problems and solutions</h2><ol><li><a href="https://www.datasciencebyexample.com/2022/10/24/2022-10-24-1/">find median of two sorted arrays</a></li><li><a href="https://www.datasciencebyexample.com/2022/10/25/2022-10-25-1/">Regular expression matching</a></li><li><a href="https://www.datasciencebyexample.com/2022/10/27/2022-10-27-1/">Merge K sorted lists</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/01/2022-11-01-1/">Find first missing positive </a></li><li><a href="https://www.datasciencebyexample.com/2022/11/02/2022-11-02-1/">Trapping rain water</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/06/2022-11-05-01/">Wildcard matching</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/08/2022-11-08-01/">Minimum window substring</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/12/largest-rectangle-in-histogram/">Largest rectangle in histogram</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/17/binary-tree-maximum-path-sum/">Binary Tree Maximum Path Sum</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/17/word-ladder/">Word ladder</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/28/word-break-II/">word break II</a></li><li><a href="https://www.datasciencebyexample.com/2022/11/30/max-points-on-a-line/">Max points on a line</a></li></ol><h2 id="link-in-github"><a href="#link-in-github" class="headerlink" title="link in github"></a>link in github</h2><p><a href="https://github.com/robotlearner001/blog/tree/main/leetcode-popular-and-hard-problems">github link</a></p><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A custom scikit-learn transformer example with parameter input and avoid possible None error</title>
      <link href="2022/12/12/custom-sckikt-learn-transformer-with-parameter-and-avoid-none-error/"/>
      <url>2022/12/12/custom-sckikt-learn-transformer-with-parameter-and-avoid-none-error/</url>
      
        <content type="html"><![CDATA[<p>A customer scikit-learn transfomer example with parameter.<br>It takes a pandas DataFrame with a column called input as input, and returns a DataFrame with a column called output containing the transformed data:</p><h2 id="define-custom-transformer"><a href="#define-custom-transformer" class="headerlink" title="define custom transformer"></a>define custom transformer</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PowerTransformer</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, power=<span class="number">1</span></span>):</span></span><br><span class="line">        self.power = power</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># Fit simply returns self, nothing else to do</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="comment"># Check if input is a DataFrame</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, pd.DataFrame):</span><br><span class="line">            <span class="comment"># If so, return a DataFrame with the transformed data</span></span><br><span class="line">            <span class="keyword">return</span> pd.DataFrame(&#123;<span class="string">&#x27;output&#x27;</span>: X[<span class="string">&#x27;input&#x27;</span>] ** self.power&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># If not, return a plain NumPy array with the transformed data</span></span><br><span class="line">            <span class="keyword">return</span> X[<span class="string">&#x27;input&#x27;</span>] ** self.power</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>To use this transformer, we would first instantiate it with the desired power parameter, and then call its fit_transform method on a DataFrame with an input column. For example:</p><h2 id="generate-some-sample-data-and-dataframe"><a href="#generate-some-sample-data-and-dataframe" class="headerlink" title="generate some sample data and dataframe"></a>generate some sample data and dataframe</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate some sample data</span></span><br><span class="line">data = np.random.randn(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a DataFrame with an &#x27;input&#x27; column</span></span><br><span class="line">X = pd.DataFrame(&#123;<span class="string">&#x27;input&#x27;</span>: data&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the DataFrame</span></span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>      input0 -1.4601351  0.1885322 -0.2726003  0.3068804 -0.221020</code></pre><h2 id="use-the-transfomer-with-parameter-intilization"><a href="#use-the-transfomer-with-parameter-intilization" class="headerlink" title="use the transfomer, with parameter intilization"></a>use the transfomer, with parameter intilization</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the transformer</span></span><br><span class="line">transformer = PowerTransformer(power=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit and transform the data</span></span><br><span class="line">X_transformed = transformer.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X_transformed)</span><br></pre></td></tr></table></figure><pre><code>     output0  2.1319941  0.0355442  0.0743113  0.0941754  0.048850</code></pre><h2 id="possible-error-Parameter-sees-none-value"><a href="#possible-error-Parameter-sees-none-value" class="headerlink" title="possible error:  Parameter sees none value"></a>possible error:  Parameter sees none value</h2><p>the above example shows some practices: (1) the transformer have an default value in the init function (2) when calling the transfomer make sure to have the ···parameter=value format</p><p>   For example,  We can skip the parameter name like this, it will work for one time use:<br><code>transformer = PowerTransformer(2)   </code></p><p>But it will raise None error in using with other methos such as <code>sklearn.model_selection.cross_val_score</code></p><h2 id="code-link"><a href="#code-link" class="headerlink" title="code link"></a>code link</h2><p><a href="https://github.com/robotlearner001/blog/blob/main/custom_scikit-learn_transformer/2022-12-12-custom-transformer-with-parameter.ipynb">github link</a></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> scikit-learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenAI&#39;s chatbot has just changed the search engine industry</title>
      <link href="2022/12/02/openai-chatbot-has-just-changed-the-search-engine-industry/"/>
      <url>2022/12/02/openai-chatbot-has-just-changed-the-search-engine-industry/</url>
      
        <content type="html"><![CDATA[<p><img src="/content/images/2022-12-02-1.png"></p><p>The game of the search engine has just been changed!</p><p>The reaction to OpenAI’s new chatbot product on Dec 1st 2022 has been overwhelmingly positive. The sheer volume of people wanting to experience it crashed the website for one whole day, demonstrating just how popular the product has become. It’s clear that people are excited to explore the potential of this technology, and to see how it can be used to help improve their lives. </p><p>For years, the search engines giant, such as Google and Baidu have been trying to better understand user’s intention. instead of just searching for specific keywords, search engines are getting better to understand more natural language inquiries. This means that instead of just typing in specific keywords, users can ask questions in their own words and get more accurate results. This shift has created greater accuracy and relevance for search engine results, which can help people find what they’re looking for more quickly and easily.</p><p>But the introduction of OpenAI’s chatbot has further changed the game of search engine. Chatbots are capable of understanding natural language queries, which means users can ask questions in their own words and get more accurate results. Chatbots can also be used to provide personalized recommendations, further improving the search experience. </p><p>Two fundamental differences of OpenAI’s chatbot and Google’s search engine:<br>(1) cost to the users:  Search engine is free in general if you don’t consider the ad.  OpenAI’s chatbot will charge people for its usage.<br>(2)  with search engine, the most relevant raw data can be found for the users to further digest and research; but with OpenAI’s chatbot, the users don’t need to any research and simply get the answers right away.</p><p>The question people need to ask themselves now is: do you want to pay for results and enjoy being lazy or doing some research based on relevant raw data.</p><p>Here we ask OpenAI one question for fun, the question is “ who will win the 2022 FIFA world cup?”<br>and the answer is very honest:<br>“I’m sorry, but I am a large language model trained by OpenAI and my knowledge cutoff is 2021, so I do not have any information about the 2022 FIFA World Cup. My training only goes up until 2021, and I am not currently able to browse the internet, so I cannot provide any updated information on current events or future events. My function is to assist with general knowledge and provide information based on my training, not to provide current or future event predictions.”</p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gpt3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Max points on a line</title>
      <link href="2022/11/30/max-points-on-a-line/"/>
      <url>2022/11/30/max-points-on-a-line/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given an array of points where points[i] = [xi, yi] represents a point on the X-Y plane, return the maximum number of points that lie on the same straight line.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br><img src="/content/images/2022-11-30-1.jpg"></p><p>Input: points = [[1,1],[2,2],[3,3]]<br>Output: 3</p><p>Example 2:<br><img src="/content/images/2022-11-30-2.jpg"></p><p>Input: points = [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]<br>Output: 4</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= points.length &lt;= 300<br>points[i].length == 2<br>-104 &lt;= xi, yi &lt;= 104<br>All the points are unique.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxPoints(self, points):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type points: List[List[int]]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        n = len(points)</span><br><span class="line">        if n &lt; 3:</span><br><span class="line">            return n</span><br><span class="line">        </span><br><span class="line">        ans = 0</span><br><span class="line">        for i in range(n):</span><br><span class="line">            dic = &#123;&#x27;inf&#x27;:0&#125;</span><br><span class="line">            samePointsNum = 0</span><br><span class="line">            x1, y1 = points[i]</span><br><span class="line">            for j in range(i+1, n):</span><br><span class="line">                x2, y2 = points[j]</span><br><span class="line">                if x1 == x2 and y1 == y2:</span><br><span class="line">                    samePointsNum += 1</span><br><span class="line">                    continue</span><br><span class="line">                if x1 == x2:</span><br><span class="line">                    slope = &#x27;inf&#x27;</span><br><span class="line">                else:</span><br><span class="line">                    slope = (y2-y1)*1.0/(x2-x1)</span><br><span class="line">                if slope not in dic:</span><br><span class="line">                    dic[slope] = 1</span><br><span class="line">                else:</span><br><span class="line">                    dic[slope] += 1</span><br><span class="line">            ans = max(ans, max(dic.values())+samePointsNum+1)</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">points = [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]</span><br><span class="line">print(Solution().maxPoints(points))</span><br><span class="line"></span><br><span class="line">points = [[1,1],[2,2],[3,3]]</span><br><span class="line">print(Solution().maxPoints(points))</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Word break II</title>
      <link href="2022/11/28/word-break-II/"/>
      <url>2022/11/28/word-break-II/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given a string s and a dictionary of strings wordDict, add spaces in s to construct a sentence where each word is a valid dictionary word. Return all such possible sentences in any order.<br>Note that the same word in the dictionary may be reused multiple times in the segmentation.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: s = “catsanddog”, wordDict = [“cat”,”cats”,”and”,”sand”,”dog”]<br>Output: [“cats and dog”,”cat sand dog”]</p><p>Example 2:<br>Input: s = “pineapplepenapple”, wordDict = [“apple”,”pen”,”applepen”,”pine”,”pineapple”]<br>Output: [“pine apple pen apple”,”pineapple pen apple”,”pine applepen apple”]<br>Explanation: Note that you are allowed to reuse a dictionary word.</p><p>Example 3:<br>Input: s = “catsandog”, wordDict = [“cats”,”dog”,”sand”,”and”,”cat”]<br>Output: []</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= s.length &lt;= 20<br>1 &lt;= wordDict.length &lt;= 1000<br>1 &lt;= wordDict[i].length &lt;= 10<br>s and wordDict[i] consist of only lowercase English letters.<br>All the strings of wordDict are unique.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wordBreak(self, s, wordDict):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type s: str</span><br><span class="line">        :type wordDict: List[str]</span><br><span class="line">        :rtype: List[str]</span><br><span class="line">        &quot;&quot;&quot;        </span><br><span class="line">        dp = [None] * (len(s) + 1)</span><br><span class="line">        dp[0] = [&#x27;&#x27;]</span><br><span class="line">        for i in range(1, len(s) + 1):</span><br><span class="line">            dp[i] = []</span><br><span class="line">            for j in range(i):</span><br><span class="line">                if dp[j] and s[j:i] in wordDict:</span><br><span class="line">                    for word in dp[j]:</span><br><span class="line">                        dp[i].append(word + (&#x27; &#x27; if word else &#x27;&#x27;) + s[j:i])</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = &quot;catsanddog&quot;</span><br><span class="line">wordDict = [&quot;cat&quot;,&quot;cats&quot;,&quot;and&quot;,&quot;sand&quot;,&quot;dog&quot;]</span><br><span class="line">print(Solution().wordBreak(s, wordDict))</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Predict the 2022 world cup using Poisson distribution</title>
      <link href="2022/11/20/fifa-world-cup-2022-prediction-with-poisson-distribution/"/>
      <url>2022/11/20/fifa-world-cup-2022-prediction-with-poisson-distribution/</url>
      
        <content type="html"><![CDATA[<p>There are many ways to predict the world cup or any games, complex machine learning models are one of those choices.<br>Here we introduct one simple way but many of the times robust way to predict by using Poisson distribution.</p><p>The code can be found here:<br><a href="https://github.com/robotlearner001/blog/tree/main/world-cup-2022-prediction">github link</a></p><p>And the following image shows the prediction:<br><img src="/content/images/2022-11-20-1.jpg"></p><p>and the predicted final winner of 2022 world cup is:<br>Brazil</p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> poisson distribution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to fix google cloud API user rate limit exceeded error</title>
      <link href="2022/11/19/google-cloud-user-rate-limit-exceeded/"/>
      <url>2022/11/19/google-cloud-user-rate-limit-exceeded/</url>
      
        <content type="html"><![CDATA[<p>We are using the google cloud translate API, and suddenly noticed it gives error.<br>A closer check of the logs shows there is some 403 error, which complains “user rate limit exceeded”.</p><p>Then checking the google cloud console, and realized it’s because of the credit card associated with billing expired.</p><p>So the the steps to fix the error are:<br>(1) go to billing page, and update the credit card information.<br>(2) go the account management, and reactivate the account.</p><p>Now the API works correctly again.</p><p><img src="/content/images/2022-11-19-1.png"></p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> google cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Binary Tree Maximum Path Sum</title>
      <link href="2022/11/17/binary-tree-maximum-path-sum/"/>
      <url>2022/11/17/binary-tree-maximum-path-sum/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>A path in a binary tree is a sequence of nodes where each pair of adjacent nodes in the sequence has an edge connecting them. A node can only appear in the sequence at most once. Note that the path does not need to pass through the root.<br>The path sum of a path is the sum of the node’s values in the path.<br>Given the root of a binary tree, return the maximum path sum of any non-empty path.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p><img src="/content/images/2022-11-16-1.jpg"></p><p>Example 1:<br>Input: root = [1,2,3]<br>Output: 6<br>Explanation: The optimal path is 2 -&gt; 1 -&gt; 3 with a path sum of 2 + 1 + 3 = 6.</p><p><img src="/content/images/2022-11-16-2.jpg"></p><p>Example 2:<br>Input: root = [-10,9,20,null,null,15,7]<br>Output: 42<br>Explanation: The optimal path is 15 -&gt; 20 -&gt; 7 with a path sum of 15 + 20 + 7 = 42.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>The number of nodes in the tree is in the range [1, 3 * 104].<br>-1000 &lt;= Node.val &lt;= 1000</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line"># class TreeNode(object):</span><br><span class="line">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.left = left</span><br><span class="line">#         self.right = right</span><br><span class="line">class Solution(object):</span><br><span class="line">    def maxPathSum(self, root):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type root: TreeNode</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.max_sum = float(&#x27;-inf&#x27;)</span><br><span class="line">        self.max_gain(root)</span><br><span class="line">        return self.max_sum</span><br><span class="line">    </span><br><span class="line">    def max_gain(self, node):</span><br><span class="line">        if not node:</span><br><span class="line">            return 0</span><br><span class="line">        </span><br><span class="line">        left_gain = max(self.max_gain(node.left), 0)</span><br><span class="line">        right_gain = max(self.max_gain(node.right), 0)</span><br><span class="line">        </span><br><span class="line">        price_newpath = node.val + left_gain + right_gain</span><br><span class="line">        </span><br><span class="line">        self.max_sum = max(self.max_sum, price_newpath)</span><br><span class="line">        </span><br><span class="line">        return node.val + max(left_gain, right_gain)</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class TreeNode(object):</span><br><span class="line">    def __init__(self, val=0, left=None, right=None):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line">root = TreeNode(1)</span><br><span class="line">root.left = TreeNode(2)</span><br><span class="line">root.right = TreeNode(3)</span><br><span class="line"></span><br><span class="line">solution = Solution()</span><br><span class="line">print( solution.maxPathSum(root) )</span><br><span class="line"></span><br><span class="line"># output: 6</span><br><span class="line"></span><br><span class="line"># test the solution      </span><br><span class="line">class TreeNode(object):</span><br><span class="line">    def __init__(self, val=0, left=None, right=None):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line">root = TreeNode(-10)</span><br><span class="line">root.left = TreeNode(9)</span><br><span class="line">root.right = TreeNode(20)</span><br><span class="line">root.right.left = TreeNode(15)</span><br><span class="line">root.right.right = TreeNode(7)</span><br><span class="line"></span><br><span class="line">solution = Solution()</span><br><span class="line">print(solution.maxPathSum(root))</span><br><span class="line"></span><br><span class="line"># output: 42</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Word ladder</title>
      <link href="2022/11/17/word-ladder/"/>
      <url>2022/11/17/word-ladder/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>A transformation sequence from word beginWord to word endWord using a dictionary wordList is a sequence of words beginWord -&gt; s1 -&gt; s2 -&gt; … -&gt; sk such that:<br>Every adjacent pair of words differs by a single letter.<br>Every si for 1 &lt;= i &lt;= k is in wordList. Note that beginWord does not need to be in wordList.<br>sk == endWord<br>Given two words, beginWord and endWord, and a dictionary wordList, return the number of words in the shortest transformation sequence from beginWord to endWord, or 0 if no such sequence exists.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: beginWord = “hit”, endWord = “cog”, wordList = [“hot”,”dot”,”dog”,”lot”,”log”,”cog”]<br>Output: 5<br>Explanation: One shortest transformation sequence is “hit” -&gt; “hot” -&gt; “dot” -&gt; “dog” -&gt; cog”, which is 5 words long.</p><p>Example 2:<br>Input: beginWord = “hit”, endWord = “cog”, wordList = [“hot”,”dot”,”dog”,”lot”,”log”]<br>Output: 0<br>Explanation: The endWord “cog” is not in wordList, therefore there is no valid transformation sequence.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= beginWord.length &lt;= 10<br>endWord.length == beginWord.length<br>1 &lt;= wordList.length &lt;= 5000<br>wordList[i].length == beginWord.length<br>beginWord, endWord, and wordList[i] consist of lowercase English letters.<br>beginWord != endWord<br>All the words in wordList are unique.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import collections</span><br><span class="line">class Solution(object):</span><br><span class="line">    def ladderLength(self, beginWord, endWord, wordList):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type beginWord: str</span><br><span class="line">        :type endWord: str</span><br><span class="line">        :type wordList: List[str]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if endWord not in wordList:</span><br><span class="line">            return 0</span><br><span class="line">        wordList = set(wordList)</span><br><span class="line">        queue = collections.deque([(beginWord, 1)])</span><br><span class="line">        while queue:</span><br><span class="line">            word, length = queue.popleft()</span><br><span class="line">            if word == endWord:</span><br><span class="line">                return length</span><br><span class="line">            for i in range(len(word)):</span><br><span class="line">                for c in &#x27;abcdefghijklmnopqrstuvwxyz&#x27;:</span><br><span class="line">                    next_word = word[:i] + c + word[i+1:]</span><br><span class="line">                    if next_word in wordList:</span><br><span class="line">                        wordList.remove(next_word)</span><br><span class="line">                        queue.append((next_word, length + 1))</span><br><span class="line">        return 0</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">beginWord = &quot;hit&quot;</span><br><span class="line">endWord = &quot;cog&quot;</span><br><span class="line">wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]</span><br><span class="line">solution = Solution()</span><br><span class="line">print(solution.ladderLength(beginWord, endWord, wordList))</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Largest rectangle in histogram</title>
      <link href="2022/11/12/largest-rectangle-in-histogram/"/>
      <url>2022/11/12/largest-rectangle-in-histogram/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given an array of integers heights representing the histogram’s bar height where the width of each bar is 1, return the area of the largest rectangle in the histogram.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br><img src="/content/images/2022-11-12-1.jpg"></p><p>Input: heights = [2,1,5,6,2,3]<br>Output: 10<br>Explanation: The above is a histogram where width of each bar is 1.<br>The largest rectangle is shown in the red area, which has an area = 10 units.</p><p>Example 2:<br><img src="/content/images/2022-11-12-2.jpg"><br>Input: heights = [2,4]<br>Output: 4</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= heights.length &lt;= 105<br>0 &lt;= heights[i] &lt;= 104</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def largestRectangleArea(self, heights):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type heights: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not heights:</span><br><span class="line">            return 0</span><br><span class="line">        stack = []</span><br><span class="line">        max_area = 0</span><br><span class="line">        for i in range(len(heights)):</span><br><span class="line">            if not stack or heights[i] &gt;= heights[stack[-1]]:</span><br><span class="line">                stack.append(i)</span><br><span class="line">            else:</span><br><span class="line">                while stack and heights[i] &lt; heights[stack[-1]]:</span><br><span class="line">                    h = heights[stack.pop()]</span><br><span class="line">                    w = i if not stack else i - stack[-1] - 1</span><br><span class="line">                    max_area = max(max_area, h * w)</span><br><span class="line">                stack.append(i)</span><br><span class="line">        while stack:</span><br><span class="line">            h = heights[stack.pop()]</span><br><span class="line">            w = len(heights) if not stack else len(heights) - stack[-1] - 1</span><br><span class="line">            max_area = max(max_area, h * w)</span><br><span class="line">        return max_area</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = Solution()</span><br><span class="line">print(s.largestRectangleArea([2,1,5,6,2,3]))</span><br><span class="line">print(s.largestRectangleArea([2,4]))</span><br><span class="line">print(s.largestRectangleArea([2,4,5,6,7,8,9]))</span><br><span class="line">print(s.largestRectangleArea([9,8,7,6,5,4,3,2,1]))</span><br><span class="line">print(s.largestRectangleArea([1,2,3,4,5,6,7,8,9]))</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Minimum window substring</title>
      <link href="2022/11/08/2022-11-08-01/"/>
      <url>2022/11/08/2022-11-08-01/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given two strings s and t of lengths m and n respectively, return the minimum window substring of s such that every character in t (including duplicates) is included in the window.<br>If there is no such substring, return the empty string “”.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: s = “ADOBECODEBANC”, t = “ABC”<br>Output: “BANC”<br>Explanation: The minimum window substring “BANC” includes ‘A’, ‘B’, and ‘C’ from string t.</p><p>Example 2:<br>Input: s = “a”, t = “a”<br>Output: “a”<br>Explanation: The entire string s is the minimum window.</p><p>Example 3:<br>Input: s = “a”, t = “aa”<br>Output: “”<br>Explanation: Both ‘a’s from t must be included in the window.<br>Since the largest window of s only has one ‘a’, return empty string.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>m == s.length<br>n == t.length<br>1 &lt;= m, n &lt;= 105<br>s and t consist of uppercase and lowercase English letters.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def minWindow(self, s, t):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type s: str</span><br><span class="line">        :type t: str</span><br><span class="line">        :rtype: str</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not s or not t or len(s) &lt; len(t):</span><br><span class="line">            return &quot;&quot;</span><br><span class="line">        n = len(s)</span><br><span class="line">        m = len(t)</span><br><span class="line">        hash_map = &#123;&#125;</span><br><span class="line">        for i in t:</span><br><span class="line">            hash_map[i] = hash_map.get(i, 0) + 1</span><br><span class="line">        left = right = 0</span><br><span class="line">        count = len(hash_map)</span><br><span class="line">        min_len = n+1</span><br><span class="line">        min_start = 0</span><br><span class="line">        while right &lt; n:</span><br><span class="line">            if s[right] in hash_map:</span><br><span class="line">                hash_map[s[right]] -= 1</span><br><span class="line">                if hash_map[s[right]] == 0:</span><br><span class="line">                    count -= 1</span><br><span class="line">            right += 1</span><br><span class="line">            while count == 0:</span><br><span class="line">                if right - left &lt; min_len:</span><br><span class="line">                    min_len = right - left</span><br><span class="line">                    min_start = left</span><br><span class="line">                if s[left] in hash_map:</span><br><span class="line">                    hash_map[s[left]] += 1</span><br><span class="line">                    if hash_map[s[left]] &gt; 0:</span><br><span class="line">                        count += 1</span><br><span class="line">                left += 1</span><br><span class="line">        if min_len == n+1:</span><br><span class="line">            return &quot;&quot;</span><br><span class="line">        return s[min_start:min_start+min_len]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import unittest</span><br><span class="line"></span><br><span class="line">class TestSolution(unittest.TestCase):</span><br><span class="line">    def setUp(self):</span><br><span class="line">        self.s = Solution()</span><br><span class="line"></span><br><span class="line">    def test_case1(self):</span><br><span class="line">        str1 = &quot;ADOBECODEBANC&quot;</span><br><span class="line">        str2 = &quot;ABC&quot;</span><br><span class="line">        result = &quot;BANC&quot;</span><br><span class="line">        self.assertEqual(self.s.minWindow(str1,str2),result)</span><br><span class="line"></span><br><span class="line">    def test_case2(self):</span><br><span class="line">        str1 = &quot;a&quot;</span><br><span class="line">        str2 = &quot;b&quot;</span><br><span class="line">        result = &quot;&quot;</span><br><span class="line">        self.assertEqual(self.s.minWindow(str1,str2),result)</span><br><span class="line"></span><br><span class="line">    def test_case3(self):</span><br><span class="line">        str1 = &quot;a&quot;</span><br><span class="line">        str2 = &quot;aa&quot;</span><br><span class="line">        result = &quot;&quot;</span><br><span class="line">        self.assertEqual(self.s.minWindow(str1,str2),result)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    unittest.main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>wildcard matching using dynamic programming</title>
      <link href="2022/11/06/2022-11-05-01/"/>
      <url>2022/11/06/2022-11-05-01/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given an input string (s) and a pattern (p), implement wildcard pattern matching with support for ‘?’ and ‘<em>‘ where:<br>‘?’ Matches any single character.<br>‘</em>‘ Matches any sequence of characters (including the empty sequence).<br>The matching should cover the entire input string (not partial).</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: s = “aa”, p = “a”<br>Output: false<br>Explanation: “a” does not match the entire string “aa”.</p><p>Example 2:<br>Input: s = “aa”, p = “<em>“<br>Output: true<br>Explanation: ‘</em>‘ matches any sequence.</p><p>Example 3:<br>Input: s = “cb”, p = “?a”<br>Output: false<br>Explanation: ‘?’ matches ‘c’, but the second letter is ‘a’, which does not match ‘b’.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>0 &lt;= s.length, p.length &lt;= 2000<br>s contains only lowercase English letters.<br>p contains only lowercase English letters, ‘?’ or ‘*’.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def isMatch(self, s, p):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type s: str</span><br><span class="line">        :type p: str</span><br><span class="line">        :rtype: bool</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # dp[i][j] = dp[i-1][j-1] if s[i] == p[j] or p[j] == &#x27;?&#x27;</span><br><span class="line">        # dp[i][j] = dp[i-1][j] or dp[i][j-1] if p[j] == &#x27;*&#x27;</span><br><span class="line">        # dp[0][0] = True</span><br><span class="line">        # dp[i][0] = False</span><br><span class="line">        # dp[0][j] = dp[0][j-1] if p[j] == &#x27;*&#x27;</span><br><span class="line">        # dp[0][j] = False if p[j] != &#x27;*&#x27;</span><br><span class="line">        # return dp[-1][-1]</span><br><span class="line">        dp = [[False] * (len(p) + 1) for _ in range(len(s) + 1)]</span><br><span class="line">        dp[0][0] = True</span><br><span class="line">        for j in range(1, len(p) + 1):</span><br><span class="line">            if p[j - 1] == &#x27;*&#x27;:</span><br><span class="line">                dp[0][j] = dp[0][j - 1]</span><br><span class="line">        for i in range(1, len(s) + 1):</span><br><span class="line">            for j in range(1, len(p) + 1):</span><br><span class="line">                if p[j - 1] == &#x27;?&#x27; or p[j - 1] == s[i - 1]:</span><br><span class="line">                    dp[i][j] = dp[i - 1][j - 1]</span><br><span class="line">                elif p[j - 1] == &#x27;*&#x27;:</span><br><span class="line">                    dp[i][j] = dp[i - 1][j] or dp[i][j - 1]</span><br><span class="line">        return dp[-1][-1]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = Solution()</span><br><span class="line">assert s.isMatch(&quot;aa&quot;, &quot;a&quot;) == False</span><br><span class="line">assert s.isMatch(&quot;aa&quot;, &quot;*&quot;) == True</span><br><span class="line">assert s.isMatch(&quot;cb&quot;, &quot;?a&quot;) == False</span><br><span class="line">assert s.isMatch(&quot;adceb&quot;, &quot;*a*b&quot;) == True</span><br><span class="line">assert s.isMatch(&quot;acdcb&quot;, &quot;a*c?b&quot;) == False</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compute how much water are trapped after raining (trapping rain water)</title>
      <link href="2022/11/02/2022-11-02-1/"/>
      <url>2022/11/02/2022-11-02-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it can trap after raining.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br><img src="/content/images/2022-11-02-1.png"><br>Input: height = [0,1,0,2,1,0,1,3,2,1,2,1]<br>Output: 6<br>Explanation: The above elevation map (black section) is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped.</p><p>Example 2:<br>Input: height = [4,2,0,3,2,5]<br>Output: 9</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>n == height.length<br>1 &lt;= n &lt;= 2 * 104<br>0 &lt;= height[i] &lt;= 105</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def trap(self, height):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type height: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not height:</span><br><span class="line">            return 0</span><br><span class="line">        left = 0</span><br><span class="line">        right = len(height) - 1</span><br><span class="line">        left_max = height[left]</span><br><span class="line">        right_max = height[right]</span><br><span class="line">        res = 0</span><br><span class="line">        while left &lt; right:</span><br><span class="line">            if height[left] &lt; height[right]:</span><br><span class="line">                if height[left] &gt;= left_max:</span><br><span class="line">                    left_max = height[left]</span><br><span class="line">                else:</span><br><span class="line">                    res += left_max - height[left]</span><br><span class="line">                left += 1</span><br><span class="line">            else:</span><br><span class="line">                if height[right] &gt;= right_max:</span><br><span class="line">                    right_max = height[right]</span><br><span class="line">                else:</span><br><span class="line">                    res += right_max - height[right]</span><br><span class="line">                right -= 1</span><br><span class="line">        return res</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = Solution()</span><br><span class="line">print(s.trap([0,1,0,2,1,0,1,3,2,1,2,1]))</span><br><span class="line">print(s.trap([4,2,0,3,2,5]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Find first missing positive integer in an unsorted array</title>
      <link href="2022/11/01/2022-11-01-1/"/>
      <url>2022/11/01/2022-11-01-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given an unsorted integer array nums, return the smallest missing positive integer.<br>You must implement an algorithm that runs in O(n) time and uses constant extra space.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: nums = [1,2,0]<br>Output: 3<br>Explanation: The numbers in the range [1,2] are all in the array.</p><p>Example 2:<br>Input: nums = [3,4,-1,1]<br>Output: 2<br>Explanation: 1 is in the array but 2 is missing.</p><p>Example 3:<br>Input: nums = [7,8,9,11,12]<br>Output: 1<br>Explanation: The smallest positive integer 1 is missing.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= nums.length &lt;= 105<br>-231 &lt;= nums[i] &lt;= 231 - 1</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># runs in O(n) time and uses constant extra space.</span><br><span class="line">class Solution(object):</span><br><span class="line">    def firstMissingPositive(self, nums):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if len(nums) == 0:</span><br><span class="line">            return 1</span><br><span class="line">        </span><br><span class="line">        # mark the number from 0 to n</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if nums[i] &lt;= 0:</span><br><span class="line">                nums[i] = len(nums) + 1</span><br><span class="line"></span><br><span class="line">        # mark the number that exists in nums</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            num = abs(nums[i])</span><br><span class="line">            if num &lt;= len(nums):</span><br><span class="line">                nums[num - 1] = -abs(nums[num - 1])</span><br><span class="line">                </span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if nums[i] &gt; 0:</span><br><span class="line">                return i + 1</span><br><span class="line">        </span><br><span class="line">        return len(nums) + 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># just do the same thing without using extra space</span><br><span class="line">class Solution2(object):</span><br><span class="line">    def firstMissingPositive(self, nums):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if len(nums) == 0:</span><br><span class="line">            return 1</span><br><span class="line"></span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            n = nums[i]</span><br><span class="line">            while 0 &lt; n &lt;= len(nums) and n != nums[n-1]:</span><br><span class="line">                nums[i], nums[n-1] = nums[n-1], nums[i]</span><br><span class="line">                n = nums[i]</span><br><span class="line"></span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            if nums[i] != i + 1:</span><br><span class="line">                return i + 1</span><br><span class="line">        return len(nums) + 1</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Test solution</span><br><span class="line">print(Solution().firstMissingPositive([1,2,0]))</span><br><span class="line">print(Solution().firstMissingPositive([3,4,-1,1]))</span><br><span class="line">print(Solution().firstMissingPositive([7,8,9,11,12]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to call a function multi-times with try and catch before raise error in Python</title>
      <link href="2022/10/28/2022-10-28-1/"/>
      <url>2022/10/28/2022-10-28-1/</url>
      
        <content type="html"><![CDATA[<p>Here is one task that we might be doing: scraping some webpages in a for loop. Then some error happens for one of the pages,<br>and then the whole process breaks, and we didn’t store results to disk yet. So we have to restart the process again.</p><p>Why don’t we just retry one of the steps multiple times, we may get it right at the second time?</p><p>Here is a function example to return the same task multiple times with try and catch block, before finally raise the error.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_try_function_call</span>(<span class="params"> num_retries = <span class="number">5</span> </span>):</span></span><br><span class="line">    <span class="keyword">for</span> attempt_no <span class="keyword">in</span> <span class="built_in">range</span>(num_retries):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;************* try time at <span class="subst">&#123;attempt_no&#125;</span>*************&#x27;</span>)</span><br><span class="line">            failure_chance =  random.random()</span><br><span class="line">                        </span><br><span class="line">            <span class="keyword">if</span> failure_chance&gt;<span class="number">0.6</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;there is going to be error&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>/<span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;no error&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>/<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">            <span class="keyword">if</span> attempt_no &lt; (num_retries - <span class="number">1</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">str</span>(error))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> error</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">multi_try_function_call()</span><br></pre></td></tr></table></figure><pre><code>************* try time at 0*************there is going to be errordivision by zero************* try time at 1*************there is going to be errordivision by zero************* try time at 2*************there is going to be errordivision by zero************* try time at 3*************there is going to be errordivision by zero************* try time at 4*************no error0.0</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Merge K sorted lists</title>
      <link href="2022/10/27/2022-10-27-1/"/>
      <url>2022/10/27/2022-10-27-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>You are given an array of k linked-lists lists, each linked-list is sorted in ascending order.<br>Merge all the linked-lists into one sorted linked-list and return it.</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: lists = [[1,4,5],[1,3,4],[2,6]]<br>Output: [1,1,2,3,4,4,5,6]<br>Explanation: The linked-lists are:<br>[<br>  1-&gt;4-&gt;5,<br>  1-&gt;3-&gt;4,<br>  2-&gt;6<br>]<br>merging them into one sorted list:<br>1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6</p><p>Example 2:<br>Input: lists = []<br>Output: []</p><p>Example 3:<br>Input: lists = [[]]<br>Output: []</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>k == lists.length<br>0 &lt;= k &lt;= 104<br>0 &lt;= lists[i].length &lt;= 500<br>-104 &lt;= lists[i][j] &lt;= 104<br>lists[i] is sorted in ascending order.<br>The sum of lists[i].length will not exceed 104.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line">class ListNode(object):</span><br><span class="line">     def __init__(self, val=0, next=None):</span><br><span class="line">         self.val = val</span><br><span class="line">         self.next = next</span><br><span class="line">         </span><br><span class="line">class Solution(object):</span><br><span class="line">    def mergeKLists(self, lists):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type lists: List[ListNode]</span><br><span class="line">        :rtype: ListNode</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not lists:</span><br><span class="line">            return None</span><br><span class="line">        if len(lists) == 1:</span><br><span class="line">            return lists[0]</span><br><span class="line">        if len(lists) == 2:</span><br><span class="line">            return self.mergeTwoLists(lists[0], lists[1])</span><br><span class="line">        mid = len(lists) // 2</span><br><span class="line">        left = self.mergeKLists(lists[:mid])</span><br><span class="line">        right = self.mergeKLists(lists[mid:])</span><br><span class="line">        return self.mergeTwoLists(left, right)</span><br><span class="line">    </span><br><span class="line">    def mergeTwoLists(self, l1, l2):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type l1: ListNode</span><br><span class="line">        :type l2: ListNode</span><br><span class="line">        :rtype: ListNode</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not l1:</span><br><span class="line">            return l2</span><br><span class="line">        if not l2:</span><br><span class="line">            return l1</span><br><span class="line">        if l1.val &lt; l2.val:</span><br><span class="line">            l1.next = self.mergeTwoLists(l1.next, l2)</span><br><span class="line">            return l1</span><br><span class="line">        else:</span><br><span class="line">            l2.next = self.mergeTwoLists(l1, l2.next)</span><br><span class="line">            return l2</span><br><span class="line">            </span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = Solution()</span><br><span class="line">l1 = ListNode(1, ListNode(4, ListNode(5)))</span><br><span class="line">l2 = ListNode(1, ListNode(3, ListNode(4)))</span><br><span class="line">l3 = ListNode(2, ListNode(6))</span><br><span class="line">lists = [l1, l2, l3]</span><br><span class="line">result = s.mergeKLists(lists)</span><br><span class="line"></span><br><span class="line">#loop and print each element of the result</span><br><span class="line">while result:</span><br><span class="line">    print(result.val)</span><br><span class="line">    result = result.next</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Regular expression matching</title>
      <link href="2022/10/25/2022-10-25-1/"/>
      <url>2022/10/25/2022-10-25-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given an input string s and a pattern p, implement regular expression matching with support for ‘.’ and ‘*’ where:</p><ul><li>‘.’ Matches any single character.​​​​</li><li>‘*’ Matches zero or more of the preceding element.<br>The matching should cover the entire input string (not partial).</li></ul><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: s = “aa”, p = “a”<br>Output: false<br>Explanation: “a” does not match the entire string “aa”.</p><p>Example 2:<br>Input: s = “aa”, p = “a*”<br>Output: true<br>Explanation: ‘*’ means zero or more of the preceding element, ‘a’. Therefore, by repeating ‘a’ once, it becomes “aa”.</p><p>Example 3:<br>Input: s = “ab”, p = “.<em>“<br>Output: true<br>Explanation: “.</em>“ means “zero or more (*) of any character (.)”.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>1 &lt;= s.length &lt;= 20<br>1 &lt;= p.length &lt;= 30<br>s contains only lowercase English letters.<br>p contains only lowercase English letters, ‘.’, and ‘<em>‘.<br>It is guaranteed for each appearance of the character ‘</em>‘, there will be a previous valid character to match.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def isMatch(self, s, p):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type s: str</span><br><span class="line">        :type p: str</span><br><span class="line">        :rtype: bool</span><br><span class="line">        &quot;&quot;&quot;        </span><br><span class="line">        if not p:</span><br><span class="line">            return not s</span><br><span class="line">        first_match = bool(s) and p[0] in &#123;s[0], &#x27;.&#x27;&#125;</span><br><span class="line">        if len(p) &gt;= 2 and p[1] == &#x27;*&#x27;:</span><br><span class="line">            return self.isMatch(s, p[2:]) or first_match and self.isMatch(s[1:], p)</span><br><span class="line">        else:</span><br><span class="line">            return first_match and self.isMatch(s[1:], p[1:])</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = &quot;aa&quot;</span><br><span class="line">p = &quot;a&quot;</span><br><span class="line">print(Solution().isMatch(s, p))</span><br><span class="line"></span><br><span class="line">s = &quot;aa&quot;</span><br><span class="line">p = &quot;a*&quot;</span><br><span class="line">print(Solution().isMatch(s, p))</span><br><span class="line"></span><br><span class="line">s = &quot;ab&quot;</span><br><span class="line">p = &quot;.*&quot;</span><br><span class="line">print(Solution().isMatch(s, p))</span><br><span class="line"></span><br><span class="line">s = &quot;aab&quot;</span><br><span class="line">p = &quot;c*a*b&quot;</span><br><span class="line">print(Solution().isMatch(s, p))</span><br><span class="line"></span><br><span class="line">s = &quot;mississippi&quot;</span><br><span class="line">p = &quot;mis*is*p*.&quot;</span><br><span class="line">print(Solution().isMatch(s, p))</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Find median of two sorted arrays</title>
      <link href="2022/10/24/2022-10-24-1/"/>
      <url>2022/10/24/2022-10-24-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h2><p>Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays. </p><p>The overall run time complexity should be O(log (m+n)).</p><h2 id="Input-and-output-examples"><a href="#Input-and-output-examples" class="headerlink" title="Input and output examples"></a>Input and output examples</h2><p>Example 1:<br>Input: nums1 = [1,3], nums2 = [2]<br>Output: 2.00000<br>Explanation: merged array = [1,2,3] and median is 2.</p><p>Example 2:<br>Input: nums1 = [1,2], nums2 = [3,4]<br>Output: 2.50000<br>Explanation: merged array = [1,2,3,4] and median is (2 + 3) / 2 = 2.5.</p><h2 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints:"></a>Constraints:</h2><p>nums1.length == m<br>nums2.length == n<br>0 &lt;= m &lt;= 1000<br>0 &lt;= n &lt;= 1000<br>1 &lt;= m + n &lt;= 2000<br>-106 &lt;= nums1[i], nums2[i] &lt;= 106</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findMedianSortedArrays(self, nums1, nums2):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type nums1: List[int]</span><br><span class="line">        :type nums2: List[int]</span><br><span class="line">        :rtype: float</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        nums = nums1 + nums2</span><br><span class="line">        nums.sort()</span><br><span class="line">        if len(nums) % 2 == 0:</span><br><span class="line">            return (nums[len(nums)//2] + nums[len(nums)//2 - 1])/2.0</span><br><span class="line">        else:</span><br><span class="line">            return nums[len(nums)//2]</span><br></pre></td></tr></table></figure><h3 id="Test-the-the-solution"><a href="#Test-the-the-solution" class="headerlink" title="Test the the solution:"></a>Test the the solution:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nums1 = [1,2,5,]</span><br><span class="line">nums2 = [3,4,8,10]</span><br><span class="line">solution = Solution()</span><br><span class="line">result = solution.findMedianSortedArrays(nums1,nums2)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><p>More interview questions can be found here:<br><a href="/categories/algorithm/">Algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> interview questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Create secrets scopes and keys for databricks, and how to give scope access to someone else</title>
      <link href="2022/10/16/2022-10-16-1/"/>
      <url>2022/10/16/2022-10-16-1/</url>
      
        <content type="html"><![CDATA[<p>In previous blogs, we have discussed about how to install the databricks command line tool (CLI),<br>and how to add authentication to the databricks website host.</p><p>Steps to install databricks command line for both linux and windows system can be found here:<br><a href="https://www.datasciencebyexample.com/2022/10/11/2022-10-11-1/">https://www.datasciencebyexample.com/2022/10/11/2022-10-11-1/</a></p><p>Steps to add authentication to the databricks website host can be found here:<br><a href="https://www.datasciencebyexample.com/2022/10/12/2022-10-12-1/">https://www.datasciencebyexample.com/2022/10/12/2022-10-12-1/</a></p><p>Now back to how to create secrets scopes and keys uisng databricks command line tool.<br>Go to your terminal where you have installed the CLT.</p><h2 id="1-add-scope-in-databricks"><a href="#1-add-scope-in-databricks" class="headerlink" title="1. add scope in databricks"></a>1. add scope in databricks</h2><p>Step 1: Creating a New Scope<br>scope name that make sense to yourself, where token will live</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks secrets create-scope --scope &lt;scope-name&gt;</span><br></pre></td></tr></table></figure><p>Step 2: Pushing Token to Scope as the key for the scope</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks secrets put --scope &lt;scope-name&gt; --key &lt;key-name&gt;</span><br></pre></td></tr></table></figure><p>Step 3: Access token in Databricks Notebook</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dbutils.secrets.get(scope=&lt;scope-name&gt;, key=&lt;key-name&gt;)</span><br></pre></td></tr></table></figure><p>if you try to print out the key obtained by dbutils in the databricks notebook, it will be something that doesn’t make sense.<br>This is expected behavior to protect the key; Just define some variable to hold the key and use in later operations that will expect the key.</p><h2 id="2-Managing-Scope-Giving-Scope-Access-to-Someone-Else"><a href="#2-Managing-Scope-Giving-Scope-Access-to-Someone-Else" class="headerlink" title="2. Managing Scope - Giving Scope Access to Someone Else"></a>2. Managing Scope - Giving Scope Access to Someone Else</h2><p>check what users have access to scope:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks secrets list-acls --scope &lt;name-of-scope&gt;</span><br></pre></td></tr></table></figure><p>Now give access to other users:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks secrets put-acl --scope &lt;name-of-scope&gt; --principal &lt;email-of-user&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> databricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to authenticate databricks command line tool</title>
      <link href="2022/10/12/2022-10-12-1/"/>
      <url>2022/10/12/2022-10-12-1/</url>
      
        <content type="html"><![CDATA[<p>Once we have installed the databricks command line tool (CLI), we still need to add authentication to the databricks website host.</p><p>Steps to install databricks command line for both linux and windows system can be found here:<br><a href="https://www.datasciencebyexample.com/2022/10/11/2022-10-11-1/">https://www.datasciencebyexample.com/2022/10/11/2022-10-11-1/</a></p><p>First, To authenticate to the CLI you use a Databricks personal access token. In order to generate a personal token, go to the workspace and click user setting as the following:</p><p><img src="/content/images/2022-10-12-1.png"><br><img src="/content/images/2022-10-12-2.png"></p><p>Following the above screen shots, generated a token and saved it somewhere for later use.</p><p>Second, on your local comuter, type the following databricks command:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks configure --token</span><br></pre></td></tr></table></figure><p>The command begins by issuing the prompt:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Databricks Host (should begin with https://):</span><br></pre></td></tr></table></figure><p>Now enter your workspace URL, with the format https://<instance-name>.cloud.databricks.com.<br>The command continues by issuing the prompt to enter your personal access token you saved from the first step:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Token:</span><br></pre></td></tr></table></figure><p>After you complete the prompts, your access credentials are stored in the file ~/.databrickscfg on Unix, Linux, or macOS, or %USERPROFILE%.databrickscfg on Windows.<br>The file contains a default profile entry:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">host = &lt;workspace-URL&gt;</span><br><span class="line">token = &lt;personal-access-token&gt;</span><br></pre></td></tr></table></figure><p>Now you should be able to continue other work, such as create secret scope and key.</p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> databricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to install databricks command line tool in linux and windows</title>
      <link href="2022/10/11/2022-10-11-1/"/>
      <url>2022/10/11/2022-10-11-1/</url>
      
        <content type="html"><![CDATA[<p>Sometimes we need to interact with databricks command line to get work done, for example, create new secrets scope and key.</p><p>Install the databricks command line in linux or MAC OS is pretty easy:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install databricks-cli</span><br></pre></td></tr></table></figure><p>or if you want to install the latest version, do this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install databricks-cli --upgrade</span><br></pre></td></tr></table></figure><p>After the the package is installed, check to see if it’s working:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks --version</span><br></pre></td></tr></table></figure><p>Install the databricks command line in Windows will take longer time.<br>First, we still need to install the databricks-cli library, go to your python environment in windows, such as Anaconda:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install databricks-cli</span><br></pre></td></tr></table></figure><p>Now if we try the databricks command, it might complain with this error:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">databricks : The term &#x27;databricks&#x27; is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was</span><br><span class="line">included, verify that the path is correct and try again.</span><br></pre></td></tr></table></figure><p>This is because the command is not in the default system PATH. To add the databricks command in the system path in windows,<br>First observe where the databricks-cli library is installed, you might see this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Requirement already satisfied: databricks-cli in c:\users\&lt;yourusername&gt;\appdata\roaming\python\python38\site-packages (0.17.3)</span><br></pre></td></tr></table></figure><p>Or just run </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip --version</span><br></pre></td></tr></table></figure><p>You will see the pip path under windows; Usually the python package is installed under the same directory as pip.  However this is not true all the time,<br>so the safest method is still trying to figure out the path by checking the specific package you just installed.</p><p>Now, the databricks command installation path should be as the following:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Users\&lt;yourusername&gt;\AppData\Roaming\Python\Python38\Scripts\databricks.exe</span><br></pre></td></tr></table></figure><p>We can use the command with the whole path, or we could put the following path in the system path in windows:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Users\&lt;yourusername&gt;\AppData\Roaming\Python\Python38\Scripts\</span><br></pre></td></tr></table></figure><p>Search “Edit the system environment variable” in windows, and add the above path as a new variable under PATH:<br><img src="/content/images/2022-10-11-1.png"></p><p>After the above step, you can try this command again, and it should be working:</p><figure class="highlight plaintext"><figcaption><span>--version</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> databricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to add watermark using Python</title>
      <link href="2022/10/08/2022-10-08-1/"/>
      <url>2022/10/08/2022-10-08-1/</url>
      
        <content type="html"><![CDATA[<p>The main idea of adding watermark with PIL library in Python is this：</p><p>(1) First create new empty image RGBA with the same size as original image but with transparent background (…, …, …, 0), e.g. a totally transparent black image (255,255,255,0).</p><p>(2) Next draw on this new image text with different transparency (e.g. 180 out of 255) and in different place. </p><p>(3) Finally use Image.alpha_composite(original_image, text_image) to put text on image with expected transparency.</p><h2 id="1-Put-a-watermark-text-in-the-center-of-an-image"><a href="#1-Put-a-watermark-text-in-the-center-of-an-image" class="headerlink" title="1. Put a watermark text in the center of an image"></a>1. Put a watermark text in the center of an image</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"></span><br><span class="line">watermark = <span class="string">&#x27;demo&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- original image ---</span></span><br><span class="line">original_image = Image.<span class="built_in">open</span>(<span class="string">&#x27;lena.png&#x27;</span>).convert(<span class="string">&quot;RGBA&quot;</span>)</span><br><span class="line">original_image_size = original_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- watermarks image ---</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># image with the same size and transparent color (..., ..., ..., 0)</span></span><br><span class="line">watermarks_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, original_image_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">watermarks_draw = ImageDraw.Draw(watermarks_image)</span><br><span class="line"></span><br><span class="line">font = ImageFont.truetype(<span class="string">&#x27;arial.ttf&#x27;</span>, <span class="number">55</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate text size in pixels (width, height)</span></span><br><span class="line">text_size = font.getsize(watermark) </span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate top/left corner for centered text</span></span><br><span class="line">x = original_image_size[<span class="number">0</span>]//<span class="number">2</span> - text_size[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line">y = original_image_size[<span class="number">1</span>]//<span class="number">2</span> - text_size[<span class="number">1</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># draw text </span></span><br><span class="line">watermarks_draw.text((x, y), watermark, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">180</span>), font=font)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- put watermarks image on original image ---</span></span><br><span class="line">combined_image = Image.alpha_composite(original_image, watermarks_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- result ---</span></span><br><span class="line">display(combined_image)</span><br><span class="line"><span class="comment"># save result to a new image</span></span><br><span class="line">combined_image.save(<span class="string">f&#x27;lena_watermark_1.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/content/images/lena_watermark_1.png"></p><h2 id="2-Put-multiple-watermark-texts-in-the-center-of-an-image"><a href="#2-Put-multiple-watermark-texts-in-the-center-of-an-image" class="headerlink" title="2. Put multiple watermark texts in the center of an image"></a>2. Put multiple watermark texts in the center of an image</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"></span><br><span class="line">watermark = <span class="string">&#x27;demo&#x27;</span></span><br><span class="line"><span class="comment"># --- original image ---</span></span><br><span class="line">original_image = Image.<span class="built_in">open</span>(<span class="string">&#x27;lena.png&#x27;</span>).convert(<span class="string">&quot;RGBA&quot;</span>)</span><br><span class="line">original_image_size = original_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- watermarks image ---</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># image with the same size and transparent color (..., ..., ..., 0)</span></span><br><span class="line">watermarks_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, original_image_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">watermarks_draw = ImageDraw.Draw(watermarks_image)</span><br><span class="line"></span><br><span class="line">font = ImageFont.truetype(<span class="string">&#x27;arial.ttf&#x27;</span>, <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate text size in pixels (width, height)</span></span><br><span class="line">text_size = font.getsize(watermark) </span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate top/left corner for centered text</span></span><br><span class="line">parts = <span class="number">8</span></span><br><span class="line">offset_x = original_image_size[<span class="number">0</span>]//parts</span><br><span class="line">offset_y = original_image_size[<span class="number">1</span>]//parts</span><br><span class="line"></span><br><span class="line">start_x = original_image_size[<span class="number">0</span>]//parts - text_size[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line">start_y = original_image_size[<span class="number">1</span>]//parts - text_size[<span class="number">1</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, parts, <span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, parts, <span class="number">2</span>):</span><br><span class="line">        x = start_x + a*offset_x</span><br><span class="line">        y = start_y + b*offset_y</span><br><span class="line">        watermarks_draw.text((x, y), watermark, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">200</span>), font=font)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># --- put watermarks image on original image ---</span></span><br><span class="line"></span><br><span class="line">combined_image = Image.alpha_composite(original_image, watermarks_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- result ---</span></span><br><span class="line"></span><br><span class="line">display(combined_image)</span><br><span class="line">combined_image.save(<span class="string">f&#x27;lena_watermark_2.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/content/images/lena_watermark_2.png"></p><h2 id="3-Put-a-rotated-watermark-text-in-the-center-of-an-image"><a href="#3-Put-a-rotated-watermark-text-in-the-center-of-an-image" class="headerlink" title="3. Put a rotated watermark text in the center of an image"></a>3. Put a rotated watermark text in the center of an image</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">watermark = <span class="string">&#x27;demo&#x27;</span></span><br><span class="line"><span class="comment"># --- original image ---</span></span><br><span class="line">original_image = Image.<span class="built_in">open</span>(<span class="string">&#x27;lena.png&#x27;</span>).convert(<span class="string">&quot;RGBA&quot;</span>)</span><br><span class="line">original_image_size = original_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- text image ---</span></span><br><span class="line"></span><br><span class="line">font = ImageFont.truetype(<span class="string">&#x27;arial.ttf&#x27;</span>, <span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate text size in pixels (width, height)</span></span><br><span class="line">text_size = font.getsize(watermark) </span><br><span class="line"></span><br><span class="line"><span class="comment"># create image for text</span></span><br><span class="line">text_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, text_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">text_draw = ImageDraw.Draw(text_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw text on image</span></span><br><span class="line">text_draw.text((<span class="number">0</span>, <span class="number">0</span>), watermark, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">129</span>), font=font)</span><br><span class="line"></span><br><span class="line"><span class="comment"># rotate text image and fill with transparent color</span></span><br><span class="line">rotated_text_image = text_image.rotate(<span class="number">45</span>, expand=<span class="literal">True</span>, fillcolor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">rotated_text_image_size = rotated_text_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment">#rotated_text_image.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- watermarks image ---</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># image with the same size and transparent color (..., ..., ..., 0)</span></span><br><span class="line">watermarks_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, original_image_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate top/left corner for centered text</span></span><br><span class="line">x = original_image_size[<span class="number">0</span>]//<span class="number">2</span> - rotated_text_image_size[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line">y = original_image_size[<span class="number">1</span>]//<span class="number">2</span> - rotated_text_image_size[<span class="number">1</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># put text on watermarks image</span></span><br><span class="line">watermarks_image.paste(rotated_text_image, (x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- put watermarks image on original image ---</span></span><br><span class="line"></span><br><span class="line">combined_image = Image.alpha_composite(original_image, watermarks_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- result ---</span></span><br><span class="line"></span><br><span class="line">display(combined_image)</span><br><span class="line">combined_image.save(<span class="string">f&#x27;lena_watermark_3.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/content/images/lena_watermark_3.png"></p><h2 id="4-Put-multiple-rotated-watermark-text-in-the-center-of-an-image"><a href="#4-Put-multiple-rotated-watermark-text-in-the-center-of-an-image" class="headerlink" title="4. Put multiple rotated watermark text in the center of an image"></a>4. Put multiple rotated watermark text in the center of an image</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">watermark = <span class="string">&#x27;demo&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- original image ---</span></span><br><span class="line">original_image = Image.<span class="built_in">open</span>(<span class="string">&#x27;lena.png&#x27;</span>).convert(<span class="string">&quot;RGBA&quot;</span>)</span><br><span class="line">original_image_size = original_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- text image ---</span></span><br><span class="line"></span><br><span class="line">font = ImageFont.truetype(<span class="string">&#x27;arial.ttf&#x27;</span>, <span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate text size in pixels (width, height)</span></span><br><span class="line">text_size = font.getsize(watermark) </span><br><span class="line"></span><br><span class="line"><span class="comment"># create image for text</span></span><br><span class="line">text_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, text_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">text_draw = ImageDraw.Draw(text_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw text on image</span></span><br><span class="line">text_draw.text((<span class="number">0</span>, <span class="number">0</span>), watermark, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">129</span>), font=font)</span><br><span class="line"></span><br><span class="line"><span class="comment"># rotate text image and fill with transparent color</span></span><br><span class="line">rotated_text_image = text_image.rotate(<span class="number">45</span>, expand=<span class="literal">True</span>, fillcolor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">rotated_text_image_size = rotated_text_image.size</span><br><span class="line"></span><br><span class="line"><span class="comment">#rotated_text_image.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- watermarks image ---</span></span><br><span class="line"></span><br><span class="line">combined_image = original_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate top/left corner for centered text</span></span><br><span class="line">parts = <span class="number">8</span></span><br><span class="line">offset_x = original_image_size[<span class="number">0</span>]//parts</span><br><span class="line">offset_y = original_image_size[<span class="number">1</span>]//parts</span><br><span class="line"></span><br><span class="line">start_x = original_image_size[<span class="number">0</span>]//parts - rotated_text_image_size[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line">start_y = original_image_size[<span class="number">1</span>]//parts - rotated_text_image_size[<span class="number">1</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, parts, <span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, parts, <span class="number">2</span>):</span><br><span class="line">        x = start_x + a*offset_x</span><br><span class="line">        y = start_y + b*offset_y</span><br><span class="line">        <span class="comment"># image with the same size and transparent color (..., ..., ..., 0)</span></span><br><span class="line">        watermarks_image = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, original_image_size, (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># put text in expected place on watermarks image</span></span><br><span class="line">        watermarks_image.paste(rotated_text_image, (x, y))</span><br><span class="line">        <span class="comment"># put watermarks image on original image</span></span><br><span class="line">        combined_image = Image.alpha_composite(combined_image, watermarks_image)</span><br><span class="line">        </span><br><span class="line"><span class="comment">#combined_image.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- result ---</span></span><br><span class="line"></span><br><span class="line">display(combined_image)</span><br><span class="line">combined_image.save(<span class="string">f&#x27;lena_watermark_4.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/content/images/lena_watermark_4.png"></p>]]></content>
      
      
      <categories>
          
          <category> image processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> PIL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to make AWS S3 buckets public through bucket policy</title>
      <link href="2022/10/01/2022-10-01-1/"/>
      <url>2022/10/01/2022-10-01-1/</url>
      
        <content type="html"><![CDATA[<p>The first step is to create a S3 buckets, here is how we can create one on AWS website through UI:<br><img src="/content/images/2022-10-01-1.png" alt="create S3 bucket"></p><p>After clicking the “create bucket”, in the following configuration page, give it a name.<br>Notice that the bucket name should be unique among all AWS buckets, not only unique to your own buckets.<br>We call it “datasciencebyexample-demo” here.</p><p>If we want to make part or all of the contents in this bucket public, unlick the “Block all public access”<br>option in this step as the following screenshot:<br><img src="/content/images/2022-10-01-2.png" alt="allow public access in S3"></p><p>Clicking into this new bucket, and let’s create one new folder called “test”:<br><img src="/content/images/2022-10-01-3.png" alt="create folder in S3"></p><p>Get into the test folder, and upload some files, for example, we uploaded a file called text.txt.<br>But if we open the url of this just uploaded file in the bucket, you will find the file is still not publicly accessible.<br><img src="/content/images/2022-10-01-4.png"></p><p>Why is that? The previous step we did actually only make this bucket “Objects can be public”.<br>We still need to add bucket policy to make all of the bucket or part of bucket contents really public.</p><p>Now go back to the bucket level, find Permission tab, and click the Edit button under bucket policy:<br><img src="/content/images/2022-10-01-5.png"></p><p>If we want to make all objects under this bucket to be public, put the following policy statement in the text box:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">            &quot;Principal&quot;: &quot;*&quot;,</span><br><span class="line">            &quot;Action&quot;: &quot;s3:GetObject&quot;,</span><br><span class="line">            &quot;Resource&quot;: &quot;arn:aws:s3:::datasciencebyexample-demo/*&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If we only want to make objects under the “test” directory to be public, put the following policy statement in the text box:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class="line">    &quot;Statement&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class="line">            &quot;Principal&quot;: &quot;*&quot;,</span><br><span class="line">            &quot;Action&quot;: &quot;s3:GetObject&quot;,</span><br><span class="line">            &quot;Resource&quot;: &quot;arn:aws:s3:::datasciencebyexample-demo/test/*&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>After saving the bucket policy, you will find your file urls are now public!</p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> s3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Human&#39;s first asteroid impact experiment, NASA Double Asteroid Redirection Test (DART)</title>
      <link href="2022/09/28/2022-09-28-1/"/>
      <url>2022/09/28/2022-09-28-1/</url>
      
        <content type="html"><![CDATA[<p>Dinosaurs would dream of getting this capability.</p><p>In NASA’s “Double Asteroid Redirection Test (DART)”, an unmanned spacecraft launched from Earth successfully hit an asteroid,<br>which NASA says is the world’s first “planet” Defense” test. At the time of impact, they were relatively close to Earth—just under 11 million kilometers.</p><p>Dimorphos is an asteroid moon orbiting the near-Earth asteroid Didymos, which astronomers discovered more than two decades ago, meaning “twin” in Greek.<br>Didymos is about 780 meters wide, and the Dimorphos running around it have a diameter of 160 meters, and its name means “two forms”<br><img src="/content/images/2022-09-28-1.png" alt="DART size comparison"></p><p>Despite the small target chosen, the fast impact would change only 1% of the speed at which Dimorphos orbits Didymos, which doesn’t sound like much,<br>but it’s enough change to be seen through a telescope.</p><p>According to its original orbit, Dimorphos circles Didymos every 11 hours and 55 minutes.<br>It is expected that the period may change to 11 hours and 45 minutes after the impact.<br>DART team members say it will take scientists about two months to determine whether the asteroid’s orbit has changed.</p><p><img src="/content/images/2022-09-28-2.png" alt="orbit change expected for DART"></p>]]></content>
      
      
      <categories>
          
          <category> physics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DART </tag>
            
            <tag> Asteroid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV and Pillow color code order difference, BGR vs RGB</title>
      <link href="2022/09/19/2022-09-19-1/"/>
      <url>2022/09/19/2022-09-19-1/</url>
      
        <content type="html"><![CDATA[<p>We can use opencv to read in a video, and extract each frame as an image.  Then we can use Python Image Library to further analyze or edit<br>the image. But when you open the image, you might find it the color seems totally wrong.</p><p>This is just because opencv and Python Image Library (PIL) use different order of color code. The order in opencv is BGR, while in PIL it’s RGB. Fortunately, it’s easy to correct it as you will find in the following example</p><h2 id="Read-a-short-video-of-Robin-bird-using-opencv"><a href="#Read-a-short-video-of-Robin-bird-using-opencv" class="headerlink" title="Read a short video of Robin bird using opencv"></a>Read a short video of Robin bird using opencv</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">vidcap = cv2.VideoCapture(<span class="string">&#x27;robin.mp4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">success = <span class="literal">True</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> success <span class="keyword">and</span> count&lt;<span class="number">100</span>:</span><br><span class="line">    success,image = vidcap.read()</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># we got the 100th frame in the video as an image array</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Now we use PIL to view the image, and find the Robin in blue color. If you checked the original video, or you have seen a Robin before,<br>you know there is something wrong.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">display(Image.fromarray(image))</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-09-19-1.png"></p><h2 id="Switch-from-BGR-to-RGB-using-opencv"><a href="#Switch-from-BGR-to-RGB-using-opencv" class="headerlink" title="Switch from BGR to RGB using opencv"></a>Switch from BGR to RGB using opencv</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br></pre></td></tr></table></figure><p>Now we get the correct image of Robin, much better!</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">display(Image.fromarray(image_rgb))</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-09-19-2.png"></p><h2 id="code-link-in-github"><a href="#code-link-in-github" class="headerlink" title="code link in github"></a>code link in github</h2><p><a href="https://github.com/robotlearner001/blog/blob/main/opencv-and-pillow-color-order-difference/2022-09-20-opencv-and-pillow-channel-difference.ipynb">https://github.com/robotlearner001/blog/blob/main/opencv-and-pillow-color-order-difference/2022-09-20-opencv-and-pillow-channel-difference.ipynb</a></p>]]></content>
      
      
      <categories>
          
          <category> image processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
            <tag> PIL </tag>
            
            <tag> image editing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to remove part of an image using Python</title>
      <link href="2022/09/18/2022-09-18-1/"/>
      <url>2022/09/18/2022-09-18-1/</url>
      
        <content type="html"><![CDATA[<p>What does remove part of an image mean? mathematically and programmatically, most of the times, it means convert the array for corresponding area of the image to be<br>(0,0,0) for the RGB channel value,  or a black color.</p><p>Removing part of an image is useful in many situations. For example, in the text to image application, using Dallie2,<br>we can edit part of the image with inpainting. </p><h2 id="Image-processing-using-Python-Image-Library"><a href="#Image-processing-using-Python-Image-Library" class="headerlink" title="Image processing using Python Image Library"></a>Image processing using Python Image Library</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np      </span><br><span class="line">  </span><br><span class="line"><span class="comment"># Opening the image and converting </span></span><br><span class="line"><span class="comment"># it to RGB color mode</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;lena.png&quot;</span>).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">display(img)</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-09-18-1.png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Extracting the image data &amp;</span></span><br><span class="line"><span class="comment"># creating an numpy array out of it</span></span><br><span class="line">img_arr = np.array(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check the pixel size of this image</span></span><br><span class="line"><span class="built_in">print</span>(img_arr.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check some of the values</span></span><br><span class="line">img_arr</span><br></pre></td></tr></table></figure><pre><code>(225, 400, 3)array([[[108,  73,  53],        [109,  72,  54],        [109,  67,  51],        ...,        [ 56,  41,  44],        [ 62,  47,  50],        [ 70,  54,  57]],       [[110,  75,  55],        [110,  73,  55],        [109,  67,  51],        ...,        [ 54,  39,  42],        [ 57,  42,  45],        [ 64,  48,  51]],       [[109,  74,  55],        [110,  73,  55],        [107,  68,  53],        ...,        [ 51,  39,  41],        [ 56,  41,  44],        [ 61,  46,  49]],       ...,       [[130,  75,  54],        [128,  74,  50],        [130,  78,  56],        ...,        [123,  75,  61],        [122,  74,  60],        [128,  80,  66]],       [[129,  72,  52],        [127,  70,  50],        [131,  77,  53],        ...,        [126,  78,  64],        [122,  74,  60],        [126,  78,  64]],       [[134,  72,  49],        [133,  72,  51],        [126,  71,  51],        ...,        [140,  87,  71],        [135,  79,  64],        [140,  84,  67]]], dtype=uint8)</code></pre><p>from the the above results, we can see that, the image has 225 (y direction) times 400 (x direction) pixels; At each pixel, there is a tuple of size 3 represents the RGB color. </p><p>One thing to be careful is the channel difference between RGB and RGBA. If you take a snapshot of the screen. The pixels inside the bounding box are returned as an “RGB” image on Windows or “RGBA” on macOS. For RGB channel, it needs 24 bits to encode the pixel, while for RGBA, it needs 32 bits to encode the pixel.</p><p>If the original image has RGB channel, but we need RGBA channel, we can use the following function to convert the image from RGB channel to RGBA channel, or vice versa.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_rgba = Image.<span class="built_in">open</span>(<span class="string">&quot;lena.jpg&quot;</span>).convert(<span class="string">&#x27;RGBA&#x27;</span>)</span><br><span class="line">img_arr_rgba = np.array(img_rgba)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check the pixel size of this new image</span></span><br><span class="line"><span class="built_in">print</span>(img_arr_rgba.shape)</span><br></pre></td></tr></table></figure><pre><code>(225, 400, 4)</code></pre><p>Let us get back to our task of removing parts of the image as the following</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Turning part of the the pixel values of to be black</span></span><br><span class="line"><span class="comment"># the order is  ymin: ymax,  xmin:xmax</span></span><br><span class="line">img_arr[<span class="number">150</span> : <span class="number">225</span>, <span class="number">0</span> : <span class="number">100</span>] = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating an image out of the previously modified array</span></span><br><span class="line">img_edit = Image.fromarray(img_arr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Displaying the image</span></span><br><span class="line">display(img_edit)</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-09-18-2.png"></p><p>Now you can see the left corner of the image is black now.</p><h2 id="code-link-in-github"><a href="#code-link-in-github" class="headerlink" title="code link in github"></a>code link in github</h2><p><a href="https://github.com/robotlearner001/blog/blob/main/remove-part-of-image-using-python/2022-09-17-remove-part-of-image-using-python.ipynb">https://github.com/robotlearner001/blog/blob/main/remove-part-of-image-using-python/2022-09-17-remove-part-of-image-using-python.ipynb</a></p>]]></content>
      
      
      <categories>
          
          <category> image processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PIL </tag>
            
            <tag> image editing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ways to make your Pandas operatoins 100 times faster</title>
      <link href="2022/09/10/2022-09-10-1/"/>
      <url>2022/09/10/2022-09-10-1/</url>
      
        <content type="html"><![CDATA[<p>Today we discusses three ways to speed up operations in the Python data analysis library Pandas. Pandas is useful for working with tabular data stored in spreadsheets and databases. It provides many functions for manipulating and transforming dataframes, or structural data.</p><h2 id="Method-1-using-itertuples-to-iterate-over-dataframe-rows"><a href="#Method-1-using-itertuples-to-iterate-over-dataframe-rows" class="headerlink" title="Method 1: using itertuples() to iterate over dataframe rows"></a>Method 1: using itertuples() to iterate over dataframe rows</h2><p>explain: There are many places that we need to iterate rows of a dataframe and do some manipulations.  Naively, we just check each row of data without thinking too much, here we use a simple sum operations to show the performance change</p><h3 id="generate-a-dataframe-from-random-numbers"><a href="#generate-a-dataframe-from-random-numbers" class="headerlink" title="generate a dataframe from random numbers"></a>generate a dataframe from random numbers</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: [random.randint(<span class="number">0</span>,<span class="number">100</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>)],</span><br><span class="line">    <span class="string">&quot;b&quot;</span>: [random.randint(<span class="number">100</span>,<span class="number">200</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>)],</span><br><span class="line">&#125;</span><br><span class="line">)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>a</th>      <th>b</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>17</td>      <td>161</td>    </tr>    <tr>      <th>1</th>      <td>77</td>      <td>150</td>    </tr>    <tr>      <th>2</th>      <td>30</td>      <td>121</td>    </tr>    <tr>      <th>3</th>      <td>18</td>      <td>130</td>    </tr>    <tr>      <th>4</th>      <td>31</td>      <td>178</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>99995</th>      <td>5</td>      <td>183</td>    </tr>    <tr>      <th>99996</th>      <td>46</td>      <td>138</td>    </tr>    <tr>      <th>99997</th>      <td>9</td>      <td>133</td>    </tr>    <tr>      <th>99998</th>      <td>25</td>      <td>162</td>    </tr>    <tr>      <th>99999</th>      <td>98</td>      <td>144</td>    </tr>  </tbody></table><p>100000 rows × 2 columns</p></div><h3 id="situation-1-naive-loop"><a href="#situation-1-naive-loop" class="headerlink" title="situation 1:  naive loop"></a>situation 1:  naive loop</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(df)):</span><br><span class="line">    results.append(df.iloc[i][<span class="string">&#x27;a&#x27;</span>]+df.iloc[i][<span class="string">&#x27;b&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>11.9 s ± 297 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><h3 id="situation-2-using-iterrows"><a href="#situation-2-using-iterrows" class="headerlink" title="situation 2: using iterrows()"></a>situation 2: using iterrows()</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    results.append(row[<span class="string">&#x27;a&#x27;</span>]+row[<span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>3.61 s ± 156 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><h3 id="situation-3-using-itertuples"><a href="#situation-3-using-itertuples" class="headerlink" title="situation 3: using itertuples()"></a>situation 3: using itertuples()</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():</span><br><span class="line">    results.append(row.a+row.b)</span><br></pre></td></tr></table></figure><pre><code>69.4 ms ± 3.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre><p>conclusion:  using itertuples() is 52 times faster than iterrows(), and  171 times than naive looping!</p><h2 id="Method-2-how-to-create-new-dataframe-efficiently"><a href="#Method-2-how-to-create-new-dataframe-efficiently" class="headerlink" title="Method 2: how to create new dataframe efficiently"></a>Method 2: how to create new dataframe efficiently</h2><p>explain: when we need to make a new dataframe and add a new column to it, for example, a sum of two existing columns</p><h3 id="situation-1-get-data-list-then-make-a-new-dataframe-from-the-data"><a href="#situation-1-get-data-list-then-make-a-new-dataframe-from-the-data" class="headerlink" title="situation 1: get data list, then make a new dataframe from the data"></a>situation 1: get data list, then make a new dataframe from the data</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():</span><br><span class="line">    results.append( (row.a, row.b, row.a+row.b) )</span><br><span class="line">    </span><br><span class="line">new_df = pd.DataFrame(data=results)    </span><br></pre></td></tr></table></figure><pre><code>133 ms ± 2.43 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre><h3 id="situation-2-copy-the-old-dataframe-to-a-new-one-then-make-new-column-using-apply-function"><a href="#situation-2-copy-the-old-dataframe-to-a-new-one-then-make-new-column-using-apply-function" class="headerlink" title="situation 2:  copy the old dataframe to a new one, then make new column using apply() function"></a>situation 2:  copy the old dataframe to a new one, then make new column using apply() function</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line">new_df = df.copy()</span><br><span class="line"></span><br><span class="line">new_df[<span class="string">&#x27;c&#x27;</span>] = new_df.apply(<span class="keyword">lambda</span> row: row[<span class="string">&#x27;a&#x27;</span>]+row[<span class="string">&#x27;b&#x27;</span>],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>988 ms ± 106 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><h3 id="situation-3-copy-the-old-dataframe-to-a-new-one-then-make-new-column-using-native-dataframe-vectorized-operation"><a href="#situation-3-copy-the-old-dataframe-to-a-new-one-then-make-new-column-using-native-dataframe-vectorized-operation" class="headerlink" title="situation 3:  copy the old dataframe to a new one, then make new column using native dataframe vectorized operation"></a>situation 3:  copy the old dataframe to a new one, then make new column using native dataframe vectorized operation</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line">new_df = df.copy()</span><br><span class="line"></span><br><span class="line">new_df[<span class="string">&#x27;c&#x27;</span>] = new_df[<span class="string">&#x27;a&#x27;</span>]+new_df[<span class="string">&#x27;b&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>956 µs ± 14 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)</code></pre><p>conclusion:  if we can leverage native df operations without for looping, it’s the best, could be 1000 times faster; if we have complex<br>manipulation, making new data then create dataframe out of it, might be a better choice </p><h2 id="Method-3-how-to-use-apply-function-efficiently"><a href="#Method-3-how-to-use-apply-function-efficiently" class="headerlink" title="Method 3: how to use apply() function efficiently"></a>Method 3: how to use apply() function efficiently</h2><p>under the hood, the popular apply() function is a for loop with some overhead; when possible, we can leverage benefits of vectorized operations;  we take a conditional multiplication as an example here</p><h3 id="situation-1-use-apply-directly"><a href="#situation-1-use-apply-directly" class="headerlink" title="situation 1:  use apply() directly"></a>situation 1:  use apply() directly</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">condition_multi</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">if</span> a&gt;<span class="number">30</span>:</span><br><span class="line">        <span class="keyword">return</span> a*<span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> a*<span class="number">3</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>] = df[<span class="string">&#x27;a&#x27;</span>].apply(condition_multi)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>33.4 ms ± 2.41 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><h3 id="situation-2-leverage-NumPy-operations"><a href="#situation-2-leverage-NumPy-operations" class="headerlink" title="situation 2: leverage NumPy operations"></a>situation 2: leverage NumPy operations</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%timeit</span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>] = np.where(df[<span class="string">&#x27;a&#x27;</span>]&gt;<span class="number">30</span>, df[<span class="string">&#x27;a&#x27;</span>]*<span class="number">2</span>,df[<span class="string">&#x27;a&#x27;</span>]*<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>1.18 ms ± 304 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><p>conclusion: using numpy makes it 28 times faster!</p><h2 id="Link-to-the-code"><a href="#Link-to-the-code" class="headerlink" title="Link to the code:"></a>Link to the code:</h2><p><a href="https://github.com/robotlearner001/blog/tree/main/Make-pandas-100-times-faster">https://github.com/robotlearner001/blog/tree/main/Make-pandas-100-times-faster</a></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Be an AWS lambda expert No.3 - How to handle CORS errors when calling AWS API Gateway endpoint from frontend</title>
      <link href="2022/09/03/2022-09-03-1/"/>
      <url>2022/09/03/2022-09-03-1/</url>
      
        <content type="html"><![CDATA[<p>We have developed a AWS lambda function, then we put it online by using AWS API gateway in our previous blogs:<br><a href="https://www.datasciencebyexample.com/2022/09/01/2022-09-01-1/">https://www.datasciencebyexample.com/2022/09/01/2022-09-01-1/</a><br><a href="https://www.datasciencebyexample.com/2022/09/02/2022-09-02-1/">https://www.datasciencebyexample.com/2022/09/02/2022-09-02-1/</a>  </p><p>We could also test the API and verify it is working as what we expect, things really look awesome.</p><p>So we are ready to send the API endpoint to our frontend and call it from the website.</p><p>As soon as we did that, we found some CORS errors like this:</p><p>Error message:<br><em>Access to XMLHttpRequest at ‘<a href="https://xxx.execute-api.us-east-1.amazonaws.com/prod/&#39;">https://xxx.execute-api.us-east-1.amazonaws.com/prod/&#39;</a> from origin ‘<a href="https://www.datasciencebyexample.com&/#39;">https://www.datasciencebyexample.com&#39;</a> has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.</em></p><p>The CORS error stands for Cross-Origin Resource Sharing (CORS) error. By default, the server side and web side can’t be talking from different domains.<br>So we need to relax this requirement from both sides. </p><h2 id="Enable-CORS-on-AWS-API-gateway"><a href="#Enable-CORS-on-AWS-API-gateway" class="headerlink" title="Enable CORS on AWS API gateway"></a>Enable CORS on AWS API gateway</h2><p>First, on the server side, we need to make sure the response from the server side, i.e. the API, should have the header including ‘Access-Control-Allow-Origin’ key, to tell which domain is allowed to call the API. We can put specific domain to be the value for the value, or ‘*’ to stand for all sites are allowed. Notice that this header is provided by the API side, not from the frontend side.</p><p>With AWS API gateway, one can check the official guide here,<br><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html">https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html</a>, or just follow the following steps:</p><ol><li><p>Sign in to the API Gateway console at <a href="https://console.aws.amazon.com/apigateway">https://console.aws.amazon.com/apigateway</a>.</p></li><li><p>In the API Gateway console, choose an API under APIs.</p></li><li><p>Choose a resource under Resources. This will enable CORS for all the methods on the resource. Alternatively, you could choose a method under the resource to enable CORS for just this method.</p></li><li><p>Choose Enable CORS from the Actions drop-down menu.<br>and Choose Enable CORS</p></li><li><p>In the Enable CORS form, don’t need to change anyting, just use the default suggestions, basicaly they are:</p><ol><li><p>In the Access-Control-Allow-Headers input field, type a static string of a comma-separated list of headers that the client must submit in the actual request of the resource. Use the console-provided header list of Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token or specify your own headers.</p></li><li><p>Use the console-provided value of ‘*’ as the Access-Control-Allow-Origin header value to allow access requests from all domains, or specify a named domain to all access requests from the specified domain.</p></li></ol><p> Choose Enable CORS and replace existing CORS headers.</p></li><li><p>Last but not least, remember to deploy the API again, otherwise it might not take effect.</p></li></ol><p>Here is screen shot of what described in the above steps:<br><img src="/content/images/2022-09-03-1.png"></p><p>We can check if the CORS setting is working by calling the API using requests library in python, and print out the headers from response:<br><img src="/content/images/2022-09-03-2.png"></p><h2 id="Calling-API-using-javascript-fetch"><a href="#Calling-API-using-javascript-fetch" class="headerlink" title="Calling API using javascript fetch"></a>Calling API using javascript fetch</h2><p>After verifing the header has the “Access-Control-Allow-Origin” key and value from the response header, we are sure the CORS is all set up on the server side.<br>To call the endpoint on the frontend, we don’t need to much work, just find the method that you like. </p><p>Here is an example of calling the POST endpoint using fetch in javascript:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function CORSexample(input) &#123;</span><br><span class="line"> </span><br><span class="line">    // call api</span><br><span class="line">    // POST request using fetch()</span><br><span class="line">fetch(&quot;https://xxx.execute-api.us-east-1.amazonaws.com/prod/&quot;, &#123;</span><br><span class="line">method: &quot;POST&quot;,</span><br><span class="line">// Adding body or contents to send</span><br><span class="line">body: JSON.stringify(&#123;</span><br><span class="line">&quot;data&quot;:&#123;&quot;query&quot;:input&#125;</span><br><span class="line">&#125;),</span><br><span class="line"> </span><br><span class="line">// Adding headers to the request if necessary</span><br><span class="line">headers: &#123;</span><br><span class="line">&quot;Content-type&quot;: &quot;application/json; charset=UTF-8&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line"> </span><br><span class="line">// Converting result to JSON</span><br><span class="line">.then(response =&gt; response.json())</span><br><span class="line"> </span><br><span class="line">.then(function(result)</span><br><span class="line">  &#123;</span><br><span class="line">   console.log(result)</span><br><span class="line">   // in some older jquery version, one has to parse the json to be object</span><br><span class="line">   // it&#x27;s not necessary in new versions, just try it or not</span><br><span class="line">   //var result = $.parseJSON(result)</span><br><span class="line">  </span><br><span class="line">   // continue other custome stuff you have </span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">&#125;).catch(error =&gt; console.error(&#x27;Error:&#x27;, error)); </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> CORS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Be an AWS lambda expert No.2 - How to expose lambda function as API endpoint using API Gateway service</title>
      <link href="2022/09/02/2022-09-02-1/"/>
      <url>2022/09/02/2022-09-02-1/</url>
      
        <content type="html"><![CDATA[<p>We have created a lambda function using custom layer in the previous blog:<br><a href="https://www.datasciencebyexample.com/2022/09/01/2022-09-01-1/">https://www.datasciencebyexample.com/2022/09/01/2022-09-01-1/</a></p><p>In order to use it, we have to expose it as an API endpoint using the API Gateway service.<br>First search the “API Gateway” in your AWS console like this:<br><img src="/content/images/2022-09-02-1.png"></p><p>Then click the “Create API” button like this:<br><img src="/content/images/2022-09-02-2.png"></p><p>Of the list of options, we can choose to build a REST API:<br><img src="/content/images/2022-09-02-3.png"></p><p>For “choose the protocal”, give the API a name and some description, and all the other options can be default:<br><img src="/content/images/2022-09-02-4.png"></p><p>Now we are ready to create a method as the following:<br><img src="/content/images/2022-09-02-5.png"></p><p>and we will choose to create a “POST” method as an example like this:<br><img src="/content/images/2022-09-02-6.png"></p><p>Now we are ready to integrate the lambda function we set up in the previous blog named as “gpt3_lambda” with this POST method as the following,<br>where we begin to type in the “Lambda Function” black space, and would see the options to choose the lambda function list:<br><img src="/content/images/2022-09-02-7.png"></p><p>As a last step, we should click “Actions” and choose the “Deploy API” from the drop down list:<br><img src="/content/images/2022-09-02-8.png"></p><p>Choose “[new state]” for the Deployment Stage, and give a name to that stage, such as “prod”, then hit the deploy button:<br><img src="/content/images/2022-09-02-9.png"></p><p>Now we will be successful, and just copy the url form the following screen shot, and use it somewhere!<br><img src="/content/images/2022-09-02-10.png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> lambda function </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Be an AWS lambda expert No.1 - How to install python packages by adding custom layer to lambda function easliy</title>
      <link href="2022/09/01/2022-09-01-1/"/>
      <url>2022/09/01/2022-09-01-1/</url>
      
        <content type="html"><![CDATA[<p>AWS lambda function is an agile way to implement serverless API endpoint; It is also quite easy to spin up some python models as long as the model is<br>not very complex. </p><h2 id="1-Try-adding-existing-AWS-layers-to-see-if-it-satisfies-your-needs"><a href="#1-Try-adding-existing-AWS-layers-to-see-if-it-satisfies-your-needs" class="headerlink" title="1. Try adding existing AWS layers to see if it satisfies your needs"></a>1. Try adding existing AWS layers to see if it satisfies your needs</h2><p>To include some very common pythons packages, such as pandas, numpy and requests,<br>you can add the aws layer called “AWSDataWranger”.</p><p>The following screen shows how to add it after you create the lambda function, here we are using the python3.9 environment.</p><p><img src="/content/images/2022-09-01-1.png"></p><p>Most of the time, we may want to more custom python packages to be installed, so we have to create a custom layer to have those packages specifically installed.<br>Notice that, there is a 250M size limit for each layer, so this means we usually can only install one or two packages in each layer. And those packages cann’t<br>be too large.</p><p>The easiest way to create a custom layer and ship it to AWS, such that you can choose to add it in your lambda fuctions, is by using The AWS Command Line Interface (AWS CLI).</p><h2 id="2-Install-AWS-CLI"><a href="#2-Install-AWS-CLI" class="headerlink" title="2. Install AWS CLI"></a>2. Install AWS CLI</h2><p>AWS CLI provides direct access to the Amazon Web Services public API. So it’s likely you already have aws cli set up.<br>If not, you can follow the offical instructions to install it on different platforms.<br>Here we take the Unbuntu linux as an example.</p><p>There are couples of ways to install AWS CLI, one way is to install AWS CLI is by using pip:<br>Step 1: Install pip (on Ubuntu OS), if you don’t have it already<br>$ sudo apt install python3-pip</p><p>Step 2: Install CLI<br>$ pip install awscli –upgrade –user</p><p>Step 3: Check installation<br>$ aws –version</p><p>Step 4: Configure AWS CLI to link your own credentials<br>$ aws configure</p><p>As a result of the above command, the AWS CLI will prompt you for four pieces of information.<br>The first two are your AWS Access Key ID and AWS Secret Access Key, which serve as your account credentials.<br><img src="/content/images/2022-09-01-2.png"></p><p>The passkey ID and a secret passkey ID can be created from AWS Management Console.<br>For the region name, it is something like us-west-2 in this example.<br>We also need to write our default output format. We can choose between the default value, in which case we will only have to press Enter.<br>Or we can also select the JSON format (JavaScript Object Notation), in which case we’ll type json and hit Enter.</p><p>The AWS CLI configuration is stored in ~ /.aws / config and ~ /.aws / credentials, as you can see in the following screenshot.<br><img src="/content/images/2022-09-01-3.png"></p><h2 id="3-Create-a-virtual-python-environment"><a href="#3-Create-a-virtual-python-environment" class="headerlink" title="3. Create a virtual python environment"></a>3. Create a virtual python environment</h2><p>Taking python 3.9 as an example, we first need to install the latest version of Python 3.9 and the development libraries:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install python3.9</span><br><span class="line">sudo  apt-get install python3.9-dev python3.9-venv</span><br></pre></td></tr></table></figure><p>Now we can create a Python 3.9 virtual environment called sandbox or any name you like using the following command.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python3.9 -m venv sandbox</span><br></pre></td></tr></table></figure><p>and activate the virtual environment:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source sandbox/bin/activate</span><br></pre></td></tr></table></figure><p>Now we have the sandbox virtual environment turned on, we are ready to install python packages that we want to use in lambda functions.</p><h2 id="4-Install-python-packages-and-zip-it-and-upload-to-AWS"><a href="#4-Install-python-packages-and-zip-it-and-upload-to-AWS" class="headerlink" title="4. Install python packages and zip it and upload to AWS"></a>4. Install python packages and zip it and upload to AWS</h2><p>Here we take installing openai package as an example, with the sandbox virtual environment, we install it using pip:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install openai</span><br></pre></td></tr></table></figure><p>after the openai is successfully installed in the sandbox virtual environment, we deactivate and environment by typing:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure><p>Now, we make a new folder called ‘python’, copy the sandbox virtual environment packages into this directory, and then zip it:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir python</span><br><span class="line">cd python</span><br><span class="line">cp -r ../sandbox/lib64/python3.9/site-packages/* .</span><br><span class="line">cd ..</span><br><span class="line">zip -r openai_layer.zip python</span><br></pre></td></tr></table></figure><p>Now, we should be able to use the aws cli command to upload the zip file as a custom layer with name “openai” like this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">aws lambda publish-layer-version --layer-name openai --zip-file fileb://openai_layer.zip --compatible-runtimes python3.9</span><br></pre></td></tr></table></figure><p>Notice that, “fileb://“ is necessary to make it work in the above command.<br>with successful upload, the command will output info about relevant messages telling your layer name and version.</p><h2 id="5-Choose-the-custom-layer-for-lambda-function"><a href="#5-Choose-the-custom-layer-for-lambda-function" class="headerlink" title="5. Choose the custom layer for lambda function"></a>5. Choose the custom layer for lambda function</h2><p>If we go back the layer adding part of the lambda function, after refreshing, we should be able to see the custom layer called openai and its version at 1.<br>Just choose it and add it. Now we are ready to import it in the code!<br><img src="/content/images/2022-09-01-4.png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> lambda function </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Understand the NaN and None difference in Pandas once for all</title>
      <link href="2022/08/24/2022-08-24-1/"/>
      <url>2022/08/24/2022-08-24-1/</url>
      
        <content type="html"><![CDATA[<p>Pandas and Numpy are widely used formats for data mining and data sciences, but sometimes people get confused by None and NaN, which are very similar but slightly different data types. Here we figure it out once for all with some examples. </p><h2 id="main-difference"><a href="#main-difference" class="headerlink" title="main difference"></a>main difference</h2><p>The distinction between None and NaN in Pandas can be summarized as:</p><ol><li>None represents a missing entry, but its type is not numeric. So any column (ad Pandas Series) that contains a None value is definately not a numeric type, such as int or float.</li><li>NaN which stands for not-a-number, is on the other hand a numeric type. This means that NaN can be found in a numeric column of int or float type.</li></ol><h2 id="tests-in-action"><a href="#tests-in-action" class="headerlink" title="tests in action"></a>tests in action</h2><p>in the following test, a None value is automatically transferred as a NaN value, because Pandas automatically converted None to NaN<br>given that the other value in the series is a numeric. The will make the series a numeric type and will be much easier for many<br>following operations.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.Series([<span class="number">1</span>,<span class="literal">None</span>])</span><br></pre></td></tr></table></figure><pre><code>0    1.01    NaNdtype: float64</code></pre><p>in the following test, the other value in the series is a string, so the None value stay as None value. This make the whole<br>series an object type.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.Series([<span class="string">&quot;1&quot;</span>,<span class="literal">None</span>])</span><br></pre></td></tr></table></figure><pre><code>0       11    Nonedtype: object</code></pre><h2 id="None-type-can-lead-to-more-arithmetic-errors"><a href="#None-type-can-lead-to-more-arithmetic-errors" class="headerlink" title="None type can lead to more arithmetic errors"></a>None type can lead to more arithmetic errors</h2><p>Why did we claim with NaN type, it will be much easier for many other operations useful to data science?<br>It just gives less error for many arithmetic operations. For example, the following operation will give an error:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="literal">None</span> + <span class="number">1</span></span><br></pre></td></tr></table></figure><pre><code>---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-8-3fd8740bf8ab&gt; in &lt;module&gt;----&gt; 1 None + 1TypeError: unsupported operand type(s) for +: &#39;NoneType&#39; and &#39;int&#39;</code></pre><p>while the following operations with NaN type is fine, we just get another NaN type, but no error.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.nan + <span class="number">1</span></span><br></pre></td></tr></table></figure><pre><code>nan</code></pre><h2 id="How-to-check-the-None-and-NaN-type"><a href="#How-to-check-the-None-and-NaN-type" class="headerlink" title="How to check the None and NaN type"></a>How to check the None and NaN type</h2><p>There are several different ways to check if a data type is None or NaN values;<br>First using numpy, the function np.isnan() can check if a value is a NaN value, but it won’t work with None values.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.isnan(np.nan)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p>in Pandas, there are functions that are isnull() and isna(), which are literally does the same things. isnull() is just an alias of the isna() method; Basically isnull() detects missing values, so both nan or None will be True.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.isnull(np.nan)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.isnull(<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maximize your credit cards cashback using AI optimization</title>
      <link href="2022/08/21/2022-08-21-1/"/>
      <url>2022/08/21/2022-08-21-1/</url>
      
        <content type="html"><![CDATA[<p>In general, there are many credit cards that offer good cash back rates for certain spending categories ranging from 1% to 5%. </p><p>The main spending categories include gas, dining, grocery, online shopping (not including amazon, target, walmart etc), and amazon shopping. There are other smaller and more specific categories, but the above categories are the main stream ones and matter to most of us.</p><p>One conventional wisdom of choosing the credit cards is trying to think about your biggest spending category, and then choose the credit cards that offers maximum cashback percentage on that category. </p><p>With optimization algorithms in AI, we could do it better. First, we estimate our annual spending in different spending categories. Then, the algorithm will figure out the best spending strategy for us using different credit cards.</p><p>The default list of credit cards are chosen with the following conditions:</p><ol><li>no annual fee, to save you money</li><li>it offers the best cash back in certain main spending categories</li><li>one of the credit cards is for Amazon shopping only, and it has 3% cashback rate; however, if you happend to have the paid Amazon prime membership, the rate is 5%. In our optimization algorithm, we use the 3% for calculation, but keep in mind, you might get more than that if you have the membership.</li><li>Some cards offer very good cashback but with a spending cap, so if your spending in that category is higher than the cap, say 500 per month or 6000 per year, the algorithm will tell you how to allocate some percentage of your spending using another credit card.</li></ol><p>With this AI based optimization algorithm, your cashback rate is usually higher than 3%!</p><p>One thing to notice is that, the best cashback outcome comes from having all the listed credit cards; however, you can also specify a subset of the credit cards, for example, you only have 2 or 3 cards, you can checkbox them, and run the algorithm. The algorithm will tell you the best scenario using the credit cards you pick.</p><p>Now try your luck!</p><h2 id="cashback-optimizer-demo"><a href="#cashback-optimizer-demo" class="headerlink" title="cashback optimizer demo"></a>cashback optimizer demo</h2><p>or go to the direct link <a href="https://www.datasciencebyexample.com/scripts/cashback-optimizer/cashback-optimizer.html">cashback optimizer</a><br> <iframe src="/scripts/cashback-optimizer/cashback-optimizer.html" width="100%" height="2000" style="border:1px solid black;"></p></iframe>]]></content>
      
      
      <categories>
          
          <category> optimization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> credit card </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Common python errors and how to fix them</title>
      <link href="2022/08/15/2022-08-15-1/"/>
      <url>2022/08/15/2022-08-15-1/</url>
      
        <content type="html"><![CDATA[<p>The following is a list of common errors in Python, and knowing how to fix them will save your day.</p><h2 id="1-IndentationError"><a href="#1-IndentationError" class="headerlink" title="1. IndentationError"></a>1. IndentationError</h2><p>In Python, all code is lined up with correct spaces. So, whether there are extra spaces or missing spaces, the entire code doesn’t run and just returns an error function.</p><p>Python code follows the PEP8 whitespace specification, using 4 spaces for each level of indentation.<br>example:<br><img src="/content/images/2022-08-15-1.png"><br>how to fix:<br><img src="/content/images/2022-08-15-2.png"></p><h2 id="2-Mixing-Tab-and-Space-TabError"><a href="#2-Mixing-Tab-and-Space-TabError" class="headerlink" title="2. Mixing Tab and Space (TabError)"></a>2. Mixing Tab and Space (TabError)</h2><p>This type of error is caused by using both tabs and spaces for encoding. The tab key is essentially a tab, not an indent. Spaces are recommended due to the varying width of spaces represented by tabs in different text editors.</p><h2 id="3-SyntaxError"><a href="#3-SyntaxError" class="headerlink" title="3. SyntaxError"></a>3. SyntaxError</h2><p>There are three reasons for syntax errors:</p><ol><li>invalid syntax</li></ol><p>Missing punctuation, mixed use of Chinese and English symbols, misspelling, variable name or function name using keywords.</p><ol start="2"><li>Invalid character in identifier</li></ol><p>Unrecognized characters appear in the code, check for extra characters or Chinese characters.</p><ol start="3"><li><p>Incomplete string detected (EOL while scanning string literal)</p><p> In many cases, it is due to inconsistent quotation marks around the string.</p></li></ol><p>some examples:<br><img src="/content/images/2022-08-15-3.png"><br>Error reason: the comma is a Chinese comma<br>Error message: SyntaxError: invalid character in identifier</p><p><img src="/content/images/2022-08-15-4.png"><br>Error reason: parentheses are not paired</p><p>Error message: SyntaxError:unexpected EOF while parsing</p><p><img src="/content/images/2022-08-15-5.png"><br>Cause of error: Forgot to add a colon at the end of statements such as if/elif/else/while/for/def/class</p><p>Error message: SyntaxError: invalid syntax</p><h2 id="4-NameError"><a href="#4-NameError" class="headerlink" title="4. NameError"></a>4. NameError</h2><p>Variable name error is the most common and most commonly encountered built-in error type. It often occurs in Python variable naming. If the variable cannot be found, a NameError will be raised. There are a few things to keep in mind about the rules for variable names:</p><ol><li>The variable name can only contain letters, numbers and underscores, and cannot start with numbers;</li><li>Variable names cannot contain spaces, but underscores can be used to separate words within them;</li><li>Do not use Python keywords and function names as variable names, such as print;</li><li>Variable names should be short and descriptive;</li><li>Use lowercase l and uppercase O with caution, because it is easy to be mistaken for numbers 1 and 0.</li></ol><p>If there is a variable name error, you can check whether the variable is assigned a value, whether there is a case of inconsistent capitalization or a wrong variable name, and correct it after finding it.</p><h2 id="5-IndexError"><a href="#5-IndexError" class="headerlink" title="5. IndexError"></a>5. IndexError</h2><p>An index is the position of an item in an array or list, this exception occurs when we try to access an element from a list or a tuple from an index that does not exist in the list.</p><p>For example, if you have a list of 10 elements with indices between 0 and 9, if you try to access an element at index 10 or 11 or more, an IndexError will be raised.</p><h2 id="6-KeyError"><a href="#6-KeyError" class="headerlink" title="6. KeyError"></a>6. KeyError</h2><p>When reading the key and value in the dictionary, if the key does not exist, a KeyError will be triggered.</p><h2 id="7-TypeError"><a href="#7-TypeError" class="headerlink" title="7. TypeError"></a>7. TypeError</h2><p>This error is raised when an incorrect or unsupported object type is used in a program. This error is also raised if you try to call a non-callable object or iterate through a non-iterable identifier.</p><p>example<br><img src="/content/images/2022-08-15-6.png"><br>Reason for error: When using “+” for splicing, you must use a string, or use the str() function to convert the number into a string<br>Error message: TypeError: can only concatenate str(not “int”) to str</p><h2 id="8-AttributeError"><a href="#8-AttributeError" class="headerlink" title="8. AttributeError"></a>8. AttributeError</h2><p>Property errors are raised when attribute references and assignments fail.<br>The cause of such errors is an attempt to access an unknown object property, in other words the property of the corresponding object cannot be found. You can check whether the constructor <strong>init</strong>() in the class is written correctly, with two underscores on the left and right sides.</p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What are the risks when more people start to use AI writers such as GPT3 to produce articles?</title>
      <link href="2022/08/11/2022-08-11-1/"/>
      <url>2022/08/11/2022-08-11-1/</url>
      
        <content type="html"><![CDATA[<p><img src="/content/images/2022-08-11-1.png" alt="AI writting GPT3"></p><p>GPT3 is currently arguably the best AI tool for text generation, a machine learning model that uses deep learning to produce human-like text.</p><p>As more and more people are using AI assisted tool to generate contents, there are some potential risks that could arise.</p><h2 id="Risk-1"><a href="#Risk-1" class="headerlink" title="Risk 1"></a>Risk 1</h2><p>The first one is that over-reliance on AI tools could lead to contents that are not original and lack creativity. </p><p>If people become too reliant on AI tools to generate content, the originality and creativity of that content may suffer. This is because AI tools often lack the ability to generate truly original ideas, and instead simply regurgitate information that they have been fed. As a result, the content that is produced may be dull and uninspired. Additionally, if people rely too heavily on AI tools to generate content, they may begin to lose their own ability to generate original ideas. This could have a negative impact on their own creativity and originality, as well as on the quality of the content that they produce. </p><p>Additionally, contents generated by AI tools may not be able to pass plagiarism detection software. This is because AI tools often simply rearrange or paraphrase existing information, rather than generate truly original content. As a result, the content they produce may be flagged as plagiarized by software designed to detect plagiarism. This could lead to the content being rejected or removed, which would be a waste of time and effort.</p><h2 id="Risk-2"><a href="#Risk-2" class="headerlink" title="Risk 2"></a>Risk 2</h2><p>The second potential risk of using AI to generate content is that the content may be inaccurate or misleading. </p><p>This is because AI tools often do not have the same level of understanding of the topic as a human would. As a result, they may inadvertently include inaccurate information in the content they generate. This could lead to people being misinformed or misled by the content. Additionally, if the AI tool is not configured properly, it may generate content that is biased or discriminatory. For example, if a tool is trained on data that is biased against a certain group of people, it may produce content that is similarly biased. This could lead to the further marginalization of already marginalized groups.</p><h2 id="Risk-3"><a href="#Risk-3" class="headerlink" title="Risk 3"></a>Risk 3</h2><p>The third one is that the use of AI tools could lead to job losses for content creators.</p><p>If people begin to rely too heavily on AI tools to generate content, it could lead to job losses for content creators. This is because AI tools can often do the same job as a human content creator, but at a fraction of the cost. As a result, companies may begin to prefer to use AI tools rather than human content creators, in order to save money. This could lead to content creators losing their jobs, as well as to a decline in the quality of content, as AI tools are not yet able to match humans in terms of creativity and originality.</p><h2 id="Risk-4"><a href="#Risk-4" class="headerlink" title="Risk 4"></a>Risk 4</h2><p>The fourth potential risk is that the AI tool could be used to create contents that are offensive or hateful in nature.</p><p>If an AI tool is not configured properly, it may generate content that is offensive or hateful in nature. This is because AI tools often simply regurgitate information that they have been fed. As a result, if the AI tool is fed offensive or hateful information, it may generate content that is similarly offensive or hateful. This could lead to people being offended or hurt by the content and could potentially cause social unrest. Additionally, if the AI tool is used to genera a large amount of content, the offensive or hateful content could be spread widely, potentially causing harm to many people. </p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>As we can see, there could be some potential risks associated with using AI to generate content. However, on the other hand, these risks might be mitigated by ensuring that the AI tool is configured properly and used in conjunction with human input.</p>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gpt3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Best tips for data scientists, most common option setup in python pandas</title>
      <link href="2022/08/06/2022-08-06-1/"/>
      <url>2022/08/06/2022-08-06-1/</url>
      
        <content type="html"><![CDATA[<p>The most commonly used data table tool for data scientists is pandas; through pandas tables, tables (dataframes) and analysis tables can be easily displayed. The formatting of the table is not good, which will affect the analysis efficiency.</p><p>If a worker wants to do well, he must first sharpen his tools. Here are some commonly used setting methods:</p><ol><li>Show more lines</li><li>Show more columns</li><li>Change the column width</li><li>Set the precision of the float column</li><li>Number formatted display</li><li>Change the drawing method</li><li>Configure the output of info()</li><li>Print out current settings and reset all options</li></ol><h2 id="1-show-more-rows"><a href="#1-show-more-rows" class="headerlink" title="1. show more rows"></a>1. show more rows</h2><p>By default, pandas does not exceed the display range of the screen. If there are many rows in the table, it will truncate the middle row and display only part of it. Sometimes, if the total number of rows of data to be viewed is not many, you can control the maximum number of rows displayed by setting display.max_rows, for example, setting the display of 200 rows of data to view the data at one time:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">pd.set_option(&#x27;display.max_rows&#x27;, 200)</span><br><span class="line"># or set like this</span><br><span class="line"># pd.options.display.max_rows = 200</span><br></pre></td></tr></table></figure><p>But when the number of rows of data exceeds display.max_rows, then display.min_rows will determine how many rows are in the displayed part. Because the default number of rows in display.min_rows is 10, the data is generally displayed as the first 5 rows of data and the last 5 rows of data.</p><p>In the same way, you can also display the number of rows that can be displayed according to your own habits, such as 20</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.min_rows&#x27;, 20)</span><br><span class="line"># pd.options.display.min_rows = 20</span><br></pre></td></tr></table></figure><p>If you need to restore the default settings, you can reset to default conditions like this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># reset</span><br><span class="line">pd.reset_option(&#x27;display.max_rows&#x27;)</span><br></pre></td></tr></table></figure><h2 id="2-Show-more-columns"><a href="#2-Show-more-columns" class="headerlink" title="2. Show more columns"></a>2. Show more columns</h2><p>The row can be set, the same column can be set, display.max_columns controls the number of columns that can be displayed, the default value is 20.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.get_option(&#x27;display.max_columns&#x27;)</span><br><span class="line"># pd.options.display.max_columns</span><br><span class="line">20</span><br></pre></td></tr></table></figure><h2 id="3-Change-column-width"><a href="#3-Change-column-width" class="headerlink" title="3. Change column width"></a>3. Change column width</h2><p>pandas has some limits on the number of characters displayed in a column, the default is 50 characters. Therefore, if some value characters are too long, an ellipsis will be displayed. If you want to display all, you can set display.max_colwidth, for example, set it to 500.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.max_colwidth&#x27;,500)</span><br><span class="line"># pd.options.display.max_colwidth = 500</span><br></pre></td></tr></table></figure><h2 id="4-Set-the-precision-of-the-float-column"><a href="#4-Set-the-precision-of-the-float-column" class="headerlink" title="4. Set the precision of the float column"></a>4. Set the precision of the float column</h2><p>For float data, pandas displays only 6 decimal places by default. We can set display.precision in advance to display only 2 digits to avoid repeated operations later.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.precision&#x27;,2)</span><br><span class="line"># pd.options.display.precision = 2</span><br></pre></td></tr></table></figure><p>This setting does not affect the underlying data, it only affects the display of floating columns.</p><h2 id="5-Format-the-numbers"><a href="#5-Format-the-numbers" class="headerlink" title="5. Format the numbers"></a>5. Format the numbers</h2><p>There is an option display.float_formatoption in pandas which can be used to format any float column. This only applies to floating point columns, for other data types, they must be converted to floating point numbers.</p><h4 id="Format-large-value-numbers-with-commas"><a href="#Format-large-value-numbers-with-commas" class="headerlink" title="Format large value numbers with commas"></a>Format large value numbers with commas</h4><p>Large numbers like 1200000 seem inconvenient, so we separate them with commas.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.float_format&#x27;,&#x27;&#123;:,&#125;&#x27;.format)</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-08-06-1.png" alt="pandas display format example"></p><h4 id="set-number-precision"><a href="#set-number-precision" class="headerlink" title="set number precision"></a>set number precision</h4><p>Similar to display.precision above, if we only care about 2 digits after the decimal point, we can format it like this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.float_format&#x27;, &#x27;&#123;:,.2f&#125;&#x27;.format)</span><br></pre></td></tr></table></figure><h4 id="percentage-sign-formatting"><a href="#percentage-sign-formatting" class="headerlink" title="percentage sign formatting"></a>percentage sign formatting</h4><p>If we want to display a percentage column, we can set it like this.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.float_format&#x27;, &#x27;&#123;:.2f&#125;%&#x27;.format)</span><br></pre></td></tr></table></figure><h2 id="6-Change-the-drawing-method"><a href="#6-Change-the-drawing-method" class="headerlink" title="6. Change the drawing method"></a>6. Change the drawing method</h2><p>By default, pandas uses matplotlib as the plotting backend. Starting from version 0.25, pandas provides options for using different backends, such as plotly, bokeh and other third-party libraries, but the premise is that you need to install them first.</p><p>The setup is very simple, as long as the third-party library is installed, it also only needs one line.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">pd.set_option(&#x27;plotting.backend&#x27;, &#x27;altair&#x27;)</span><br><span class="line">data = pd.Series(np.random.randn(100).cumsum())</span><br><span class="line">data.plot()</span><br></pre></td></tr></table></figure><h2 id="7-Configure-the-output-of-info"><a href="#7-Configure-the-output-of-info" class="headerlink" title="7. Configure the output of info()"></a>7. Configure the output of info()</h2><p>In pandas, we often use info() to quickly view the data of the DataFrame. However, the info method has a default limit on the maximum number of columns to analyze, and if there are nulls in the dataset, it will be very slow when counting statistics on large datasets.</p><p>pandas provides two options:</p><p>display.max_info_columns: Set the maximum number of columns to analyze, the default is 100.<br>display.max_info_rows: Set the threshold when the count is null, the default is 1690785.</p><p>For example, when analyzing a dataset with 150 features, we can set display.max_info_columns to a value that covers all columns, such as setting it to 200:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.max_info_columns&#x27;, 200)</span><br></pre></td></tr></table></figure><p>When analyzing large datasets, df.info() is slow due to calculating all nulls. So we can simply set display.max_info_rows to a small value to avoid counting, e.g. only count null if the number of rows does not exceed 5:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.max_info_rows&#x27;, 5)</span><br></pre></td></tr></table></figure><h2 id="8-Print-out-current-settings-and-reset-all-options"><a href="#8-Print-out-current-settings-and-reset-all-options" class="headerlink" title="8. Print out current settings and reset all options"></a>8. Print out current settings and reset all options</h2><p>pd.describe_option() will print out the description of the setting and its current value.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.describe_option()</span><br></pre></td></tr></table></figure><p>You can also print certain options, such as line display.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># specific search</span><br><span class="line">pd.describe_option(&#x27;rows&#x27;)</span><br></pre></td></tr></table></figure><p>Finally, we can also reset all directly.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.reset_option(&#x27;all&#x27;)</span><br></pre></td></tr></table></figure><h2 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h2><p>The above is the use of commonly used set_option, you can set it as follows at one time:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pd.set_option(&#x27;display.max_rows&#x27;,xxx) # maximum number of rows</span><br><span class="line">pd.set_option(&#x27;display.min_rows&#x27;,xxx) # Minimum display rows</span><br><span class="line">pd.set_option(&#x27;display.max_columns&#x27;,xxx) # Maximum number of display columns</span><br><span class="line">pd.set_option (&#x27;display.max_colwidth&#x27;,xxx) #Maximum column characters</span><br><span class="line">pd.set_option( &#x27;display.precision&#x27;,2) # floating point precision</span><br><span class="line">pd.set_option(&#x27;display.float_format&#x27;,&#x27;&#123;:,&#125;&#x27;.format) #Comma-separated numbers</span><br><span class="line">pd.set_option(&#x27;display.float_format&#x27;, &#x27;&#123;:,.2f&#125;&#x27;.format) #Set floating point precision</span><br><span class="line">pd.set_option(&#x27;display.float_format&#x27;, &#x27;&#123;:.2f&#125;%&#x27;.format) #Percent sign formatting</span><br><span class="line">pd.set_option(&#x27;plotting.backend&#x27;, &#x27;altair&#x27;) # Change the backend drawing method</span><br><span class="line">pd.set_option(&#x27;display.max_info_columns&#x27;, 200) # info output maximum number of columns</span><br><span class="line">pd.set_option(&#x27;display.max_info_rows&#x27;, 5) # info count threshold when null</span><br><span class="line">pd.describe_option() #Show all settings and descriptions</span><br><span class="line">pd.reset_option(&#x27;all&#x27;) #Reset all setting options</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>StagingBucket already exists error during cdk Bootstrap</title>
      <link href="2022/07/28/2022-07-28-1/"/>
      <url>2022/07/28/2022-07-28-1/</url>
      
        <content type="html"><![CDATA[<p>During my practice of fllowing the AWS Cloud Development Kit (AWS CDK) script that automatically provisions container<br>image-based Lambda functions that perform ML inference using pre-trained Hugging Face modelsWhen using the aws cdk stack deployment,<br>I got some error like this:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>:<span class="number">45</span>:<span class="number">26</span> AM CREATE_FAILED        | AWS::S3::Bucket       | StagingBucket</span><br><span class="line">cdk-hnb659fds-assets-xxxxxxxxxxx-us-east-<span class="number">1</span> already exists</span><br><span class="line"></span><br><span class="line">Environment aws://xxxxxxxxx/us-east-<span class="number">1</span> failed bootstrapping: Error: </span><br><span class="line">The stack named CDKToolkit failed creation, it may need to be manually deleted <span class="keyword">from</span> the AWS console: ROLLBACK_COMPLETE: </span><br><span class="line">cdk-hnb659fds-assets-xxxxxxx-us-east-<span class="number">1</span> already exists</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>As a reminder, here are the steps I was doing:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cdk bootstrap</span><br><span class="line">cdk deploy</span><br></pre></td></tr></table></figure><p>When I reach the cdk bootstrap I get the above error:</p><p>The error happens probably because I previously mannually removed some images on the aws ECR.<br>So to fix that error, first I go to the aws console and find the CloudFormation dashboard, and delete the stack called “CDKToolkit”,<br>shown as below</p><p><img src="/content/images/2022-07-28-1.png" alt="lift plot"></p><p>Then I went to S3 buckets in aws console, and delete the bucket named as “cdk-hnb659fds-assets-xxxxxxxxxxx-us-east-1”, as shown below:</p><p><img src="/content/images/2022-07-28-2.png" alt="lift plot"></p><p>After it’s done, I rerun cdk bootstrap, it works.</p>]]></content>
      
      
      <categories>
          
          <category> stack overflow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aws </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reveal secrets of early Universe, three questions to understand the James Webb telescope</title>
      <link href="2022/07/17/2022-07-17-1/"/>
      <url>2022/07/17/2022-07-17-1/</url>
      
        <content type="html"><![CDATA[<p><img src="/content/images/2022-07-17-1.png" alt="James Webb telescope"></p><h2 id="1-Why-does-the-Webb-Telescope-fly-so-far"><a href="#1-Why-does-the-Webb-Telescope-fly-so-far" class="headerlink" title="1. Why does the Webb Telescope fly so far?"></a>1. Why does the Webb Telescope fly so far?</h2><p>The Webb telescope has been launched into space 1.5 million kilometers from Earth, a place known as the “Earth-Sun Lagrange L2 point”. The average distance between the moon and the earth is 380,000 kilometers, which is 4 times farther than the Webb telescope!</p><p>Hubble is a visible light telescope, basically what we see with the human eye is what the telescope captures; Webb is an infrared telescope, it mainly accepts light in infrared wavelengths - redder than red, a kind of invisible to our eyes” red”.</p><p>According to the theory of physics, all matter in the universe has a temperature and emits photons outward. Only objects that are hot enough to emit visible light outwards allow our eyes to see these photons. More objects emit infrared light, and we need infrared sensors to detect them.</p><p>The James Webb Telescope is a device used to detect cosmic infrared light. The sensors on it are extremely sensitive and can distinguish extremely small temperature changes, thereby detecting faint light from tens of billions of light-years away.</p><p>Just as we can’t see stars during the day, it’s not that the star isn’t there, but that the sun’s rays are so strong that its photons scatter in the atmosphere, drowning out the dim starlight. The Earth and Moon also emit infrared light, and the closer you get to Earth, the more it interferes with the Webb telescope. How to do it? Scientists should keep the telescope as far away from the Earth and the moon as possible, and block the sunlight with a heat shield to minimize the interference of thermal radiation.</p><p>So, is the Webb telescope sent to the L2 point of the Earth’s Lagrange because it is cold enough there? Not really.</p><p>Compared with the distance from the sun, the temperature difference caused by 1.5 million kilometers is almost negligible. On the one hand, the L2 point is selected because it can avoid the interference of the thermal radiation of the earth and the moon, and another important reason is that it is in a stable area between the sun and the earth. , the spacecraft can “float” here for a long time without consuming much fuel. Weber orbits the L2 point under the gravitational force of the earth and the sun.</p><h2 id="2-Why-does-the-telescope-need-to-work-in-the-infrared-range"><a href="#2-Why-does-the-telescope-need-to-work-in-the-infrared-range" class="headerlink" title="2. Why does the telescope need to work in the infrared range?"></a>2. Why does the telescope need to work in the infrared range?</h2><p>Launched in April 1990, the Hubble Space Telescope is a groundbreaking generation of space telescopes.</p><p>In the past 30 years, the Hubble Space Telescope has provided us with the most important images of the universe, such as the famous Pillar of Creations and the nearly 10,000 objects known as the Hubble Ultra Deep Field. Image of galaxies.</p><p>The Webb telescope is designed to look beyond Hubble to see deeper into the universe.</p><p>Although Hubble is expected to continue working for another decade or two, Webb, with its more sophisticated equipment and design, is seen as a future successor to the mission of exploring space.</p><p>The main differences between Hubble and Webb are:</p><p>Hubble was designed to collect visible and ultraviolet light, with only limited infrared capabilities. The Webb telescope collects infrared light (IR);<br>The Hubble telescope is 2.4 meters in diameter, and the Webb telescope is 6.5 meters in diameter, and has a larger light collection area, which means that Webb can see deeper, farther and earlier than Hubble;<br>Hubble is orbiting very close to Earth, while Webb will be 1.5 million kilometers away. That’s four times the distance from Earth to the Moon.</p><p>The figure below shows that the same picture, infrared light can see more details.<br><img src="/content/images/2022-07-17-2.png" alt="more details with infrared lights on the right"></p><h2 id="3-Could-infrared-light-allow-us-to-see-the-beginning-of-the-universe"><a href="#3-Could-infrared-light-allow-us-to-see-the-beginning-of-the-universe" class="headerlink" title="3. Could infrared light allow us to see the beginning of the universe?"></a>3. Could infrared light allow us to see the beginning of the universe?</h2><p><img src="/content/images/2022-07-17-3.png" alt="timeline of universe"></p><p>Hawking said the universe exploded from a point much smaller than an atom, and it took about 13.8 billion years of evolution to become what we see today.</p><p>Astronomers say Webb will examine the entire multibillion-year history of the universe – from the first stars to life in our solar system. NASA Administrator Bill Nelson called the telescope a “keyhole to the past.”</p><p>The Webb Space Telescope has a light-receiving area five times that of Hubble, and can work in the near-infrared range, with an observable spectral wavelength of up to 30 microns. This means that Webb can not only see the older galaxies, that is, the scene when the universe was 200 million years old, but also penetrate through the dust of the universe and see the mysteries behind it.</p><p>But why can see the past? Can time be turned back?<br>Simply put, because the universe is constantly expanding, and the speed of light has a limit, the light we see now from far away is actually the light emitted in the past. The distance that light travels in 1 year, called a light-year, is the unit of distance in the universe, and 1 light-year is nearly 10 trillion kilometers.</p><p>For example, the light emitted from the birth of a celestial body 10 billion light-years away from Earth will only be seen this year. Conversely, if the light we capture comes from an object 10 billion light-years away, it is an event that happened 10 billion years ago. The life of the universe is probably more than 13 billion years old, so if we can observe the light emitted by objects far enough away, we can see exactly what happened in the beginning of the universe.</p><p>The oldest known light in the universe is from the galaxy GN-z11. According to calculations, the galaxy is 13.4 billion light-years away from Earth.<br><img src="/content/images/2022-07-17-4.png" alt="galaxy GN-z11"></p><p>The question is how do we know how far away the light we’re receiving comes from?<br>The answer is spectroscopic analysis! When we observe celestial objects, the spectral lines of the light they emit are not at standard wavelengths. The slope lengths of all spectral lines are lengthened, that is to say, the spectral lines move toward the red end. This phenomenon is called spectral line redshift, and it is caused by the Doppler effect.</p><p>As light changes over time and distance, its wavelength, or color, also changes. And this change is regular. When you see a train coming towards you, its color tends to be blue. Of course, this change is very small, and the human eye cannot distinguish it. This is called blue shift. If you see a train moving away from you, its color is more red, which is called a redshift. When scientists observe the universe, they find that almost all celestial bodies have red shifts, which is why they have the theory of the Big Bang. When you detect a beam of light, record its spectrum, measure its spectrum after a period of time, and know how far it comes from according to its changes.</p>]]></content>
      
      
      <categories>
          
          <category> physics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cosmology </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A great columnTransformer example to preprocess data for online article SOV prediction</title>
      <link href="2022/07/16/2022-07-16-1/"/>
      <url>2022/07/16/2022-07-16-1/</url>
      
        <content type="html"><![CDATA[<p>ColumnTransformer is one of the most useful data transforming tools for data science projects. Here we show a complete example of applying columnTransformer as the preprocessing tools, and then apply RandomForrest Regression models to predict share of voice (SOV) for online articles. </p><h2 id="data-introduction"><a href="#data-introduction" class="headerlink" title="data introduction"></a>data introduction</h2><p>The original link of data is here: <a href="https://archive-beta.ics.uci.edu/ml/datasets/online+news+popularity">https://archive-beta.ics.uci.edu/ml/datasets/online+news+popularity</a><br>Features are already created, but checking the feature names alone would help us greatly to undrstand what would influence the online article ranking.</p><p>What do the instances that comprise the dataset represent?</p><p>Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)</p><p>Attribute Information:<br>     0. url:                           URL of the article (non-predictive)<br>     1. timedelta:                     Days between the article publication and the dataset acquisition (non-predictive)<br>     2. n_tokens_title:                Number of words in the title<br>     3. n_tokens_content:              Number of words in the content<br>     4. n_unique_tokens:               Rate of unique words in the content<br>     5. n_non_stop_words:              Rate of non-stop words in the content<br>     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the content<br>     7. num_hrefs:                     Number of links<br>     8. num_self_hrefs:                Number of links to other articles published by Mashable<br>     9. num_imgs:                      Number of images<br>    10. num_videos:                    Number of videos<br>    11. average_token_length:          Average length of the words in the content<br>    12. num_keywords:                  Number of keywords in the metadata<br>    13. data_channel_is_lifestyle:     Is data channel ‘Lifestyle’?<br>    14. data_channel_is_entertainment: Is data channel ‘Entertainment’?<br>    15. data_channel_is_bus:           Is data channel ‘Business’?<br>    16. data_channel_is_socmed:        Is data channel ‘Social Media’?<br>    17. data_channel_is_tech:          Is data channel ‘Tech’?<br>    18. data_channel_is_world:         Is data channel ‘World’?<br>    19. kw_min_min:                    Worst keyword (min. shares)<br>    20. kw_max_min:                    Worst keyword (max. shares)<br>    21. kw_avg_min:                    Worst keyword (avg. shares)<br>    22. kw_min_max:                    Best keyword (min. shares)<br>    23. kw_max_max:                    Best keyword (max. shares)<br>    24. kw_avg_max:                    Best keyword (avg. shares)<br>    25. kw_min_avg:                    Avg. keyword (min. shares)<br>    26. kw_max_avg:                    Avg. keyword (max. shares)<br>    27. kw_avg_avg:                    Avg. keyword (avg. shares)<br>    28. self_reference_min_shares:     Min. shares of referenced articles in Mashable<br>    29. self_reference_max_shares:     Max. shares of referenced articles in Mashable<br>    30. self_reference_avg_sharess:    Avg. shares of referenced articles in Mashable<br>    31. weekday_is_monday:             Was the article published on a Monday?<br>    32. weekday_is_tuesday:            Was the article published on a Tuesday?<br>    33. weekday_is_wednesday:          Was the article published on a Wednesday?<br>    34. weekday_is_thursday:           Was the article published on a Thursday?<br>    35. weekday_is_friday:             Was the article published on a Friday?<br>    36. weekday_is_saturday:           Was the article published on a Saturday?<br>    37. weekday_is_sunday:             Was the article published on a Sunday?<br>    38. is_weekend:                    Was the article published on the weekend?<br>    39. LDA_00:                        Closeness to LDA topic 0<br>    40. LDA_01:                        Closeness to LDA topic 1<br>    41. LDA_02:                        Closeness to LDA topic 2<br>    42. LDA_03:                        Closeness to LDA topic 3<br>    43. LDA_04:                        Closeness to LDA topic 4<br>    44. global_subjectivity:           Text subjectivity<br>    45. global_sentiment_polarity:     Text sentiment polarity<br>    46. global_rate_positive_words:    Rate of positive words in the content<br>    47. global_rate_negative_words:    Rate of negative words in the content<br>    48. rate_positive_words:           Rate of positive words among non-neutral tokens<br>    49. rate_negative_words:           Rate of negative words among non-neutral tokens<br>    50. avg_positive_polarity:         Avg. polarity of positive words<br>    51. min_positive_polarity:         Min. polarity of positive words<br>    52. max_positive_polarity:         Max. polarity of positive words<br>    53. avg_negative_polarity:         Avg. polarity of negative  words<br>    54. min_negative_polarity:         Min. polarity of negative  words<br>    55. max_negative_polarity:         Max. polarity of negative  words<br>    56. title_subjectivity:            Title subjectivity<br>    57. title_sentiment_polarity:      Title polarity<br>    58. abs_title_subjectivity:        Absolute subjectivity level<br>    59. abs_title_sentiment_polarity:  Absolute polarity level<br>    60. shares:                        Number of shares (target)</p><p>Additional Information</p><ul><li>The articles were published by Mashable (<a href="http://www.mashable.com/">www.mashable.com</a>) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.</li><li>Acquisition date: January 8, 2015</li><li>The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method.  See their article for more details on how the relative performance values were set.</li></ul><h2 id="load-libraires"><a href="#load-libraires" class="headerlink" title="load libraires"></a>load libraires</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> KBinsDiscretizer</span><br><span class="line"><span class="keyword">from</span> sklearn.inspection <span class="keyword">import</span> permutation_importance</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="import-data"><a href="#import-data" class="headerlink" title="import data"></a>import data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;data/OnlineNewsPopularity.csv&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>url</th>      <th>timedelta</th>      <th>n_tokens_title</th>      <th>n_tokens_content</th>      <th>n_unique_tokens</th>      <th>n_non_stop_words</th>      <th>n_non_stop_unique_tokens</th>      <th>num_hrefs</th>      <th>num_self_hrefs</th>      <th>num_imgs</th>      <th>...</th>      <th>min_positive_polarity</th>      <th>max_positive_polarity</th>      <th>avg_negative_polarity</th>      <th>min_negative_polarity</th>      <th>max_negative_polarity</th>      <th>title_subjectivity</th>      <th>title_sentiment_polarity</th>      <th>abs_title_subjectivity</th>      <th>abs_title_sentiment_polarity</th>      <th>shares</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>      <td>731.0</td>      <td>12.0</td>      <td>219.0</td>      <td>0.663594</td>      <td>1.0</td>      <td>0.815385</td>      <td>4.0</td>      <td>2.0</td>      <td>1.0</td>      <td>...</td>      <td>0.100000</td>      <td>0.70</td>      <td>-0.350000</td>      <td>-0.600</td>      <td>-0.200000</td>      <td>0.500000</td>      <td>-0.187500</td>      <td>0.000000</td>      <td>0.187500</td>      <td>593</td>    </tr>    <tr>      <th>1</th>      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>      <td>731.0</td>      <td>9.0</td>      <td>255.0</td>      <td>0.604743</td>      <td>1.0</td>      <td>0.791946</td>      <td>3.0</td>      <td>1.0</td>      <td>1.0</td>      <td>...</td>      <td>0.033333</td>      <td>0.70</td>      <td>-0.118750</td>      <td>-0.125</td>      <td>-0.100000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.500000</td>      <td>0.000000</td>      <td>711</td>    </tr>    <tr>      <th>2</th>      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>      <td>731.0</td>      <td>9.0</td>      <td>211.0</td>      <td>0.575130</td>      <td>1.0</td>      <td>0.663866</td>      <td>3.0</td>      <td>1.0</td>      <td>1.0</td>      <td>...</td>      <td>0.100000</td>      <td>1.00</td>      <td>-0.466667</td>      <td>-0.800</td>      <td>-0.133333</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.500000</td>      <td>0.000000</td>      <td>1500</td>    </tr>    <tr>      <th>3</th>      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>      <td>731.0</td>      <td>9.0</td>      <td>531.0</td>      <td>0.503788</td>      <td>1.0</td>      <td>0.665635</td>      <td>9.0</td>      <td>0.0</td>      <td>1.0</td>      <td>...</td>      <td>0.136364</td>      <td>0.80</td>      <td>-0.369697</td>      <td>-0.600</td>      <td>-0.166667</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.500000</td>      <td>0.000000</td>      <td>1200</td>    </tr>    <tr>      <th>4</th>      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>      <td>731.0</td>      <td>13.0</td>      <td>1072.0</td>      <td>0.415646</td>      <td>1.0</td>      <td>0.540890</td>      <td>19.0</td>      <td>19.0</td>      <td>20.0</td>      <td>...</td>      <td>0.033333</td>      <td>1.00</td>      <td>-0.220192</td>      <td>-0.500</td>      <td>-0.050000</td>      <td>0.454545</td>      <td>0.136364</td>      <td>0.045455</td>      <td>0.136364</td>      <td>505</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>39639</th>      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>      <td>8.0</td>      <td>11.0</td>      <td>346.0</td>      <td>0.529052</td>      <td>1.0</td>      <td>0.684783</td>      <td>9.0</td>      <td>7.0</td>      <td>1.0</td>      <td>...</td>      <td>0.100000</td>      <td>0.75</td>      <td>-0.260000</td>      <td>-0.500</td>      <td>-0.125000</td>      <td>0.100000</td>      <td>0.000000</td>      <td>0.400000</td>      <td>0.000000</td>      <td>1800</td>    </tr>    <tr>      <th>39640</th>      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>      <td>8.0</td>      <td>12.0</td>      <td>328.0</td>      <td>0.696296</td>      <td>1.0</td>      <td>0.885057</td>      <td>9.0</td>      <td>7.0</td>      <td>3.0</td>      <td>...</td>      <td>0.136364</td>      <td>0.70</td>      <td>-0.211111</td>      <td>-0.400</td>      <td>-0.100000</td>      <td>0.300000</td>      <td>1.000000</td>      <td>0.200000</td>      <td>1.000000</td>      <td>1900</td>    </tr>    <tr>      <th>39641</th>      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>      <td>8.0</td>      <td>10.0</td>      <td>442.0</td>      <td>0.516355</td>      <td>1.0</td>      <td>0.644128</td>      <td>24.0</td>      <td>1.0</td>      <td>12.0</td>      <td>...</td>      <td>0.136364</td>      <td>0.50</td>      <td>-0.356439</td>      <td>-0.800</td>      <td>-0.166667</td>      <td>0.454545</td>      <td>0.136364</td>      <td>0.045455</td>      <td>0.136364</td>      <td>1900</td>    </tr>    <tr>      <th>39642</th>      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>      <td>8.0</td>      <td>6.0</td>      <td>682.0</td>      <td>0.539493</td>      <td>1.0</td>      <td>0.692661</td>      <td>10.0</td>      <td>1.0</td>      <td>1.0</td>      <td>...</td>      <td>0.062500</td>      <td>0.50</td>      <td>-0.205246</td>      <td>-0.500</td>      <td>-0.012500</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.500000</td>      <td>0.000000</td>      <td>1100</td>    </tr>    <tr>      <th>39643</th>      <td>http://mashable.com/2014/12/27/youtube-channel...</td>      <td>8.0</td>      <td>10.0</td>      <td>157.0</td>      <td>0.701987</td>      <td>1.0</td>      <td>0.846154</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>...</td>      <td>0.100000</td>      <td>0.50</td>      <td>-0.200000</td>      <td>-0.200</td>      <td>-0.200000</td>      <td>0.333333</td>      <td>0.250000</td>      <td>0.166667</td>      <td>0.250000</td>      <td>1300</td>    </tr>  </tbody></table><p>39644 rows × 61 columns</p></div><h2 id="define-features-and-targets"><a href="#define-features-and-targets" class="headerlink" title="define features and targets"></a>define features and targets</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># be careful the features has a prefix of white space</span></span><br><span class="line">numeric_features = [<span class="string">&#x27; n_tokens_title&#x27;</span>, <span class="string">&#x27; n_tokens_content&#x27;</span>, <span class="string">&#x27; n_unique_tokens&#x27;</span>, <span class="string">&#x27; n_non_stop_words&#x27;</span>, <span class="string">&#x27; n_non_stop_unique_tokens&#x27;</span>, <span class="string">&#x27; num_hrefs&#x27;</span>, <span class="string">&#x27; num_self_hrefs&#x27;</span>, <span class="string">&#x27; num_imgs&#x27;</span>, <span class="string">&#x27; num_videos&#x27;</span>, <span class="string">&#x27; average_token_length&#x27;</span>, <span class="string">&#x27; num_keywords&#x27;</span>, <span class="string">&#x27; data_channel_is_lifestyle&#x27;</span>, <span class="string">&#x27; data_channel_is_entertainment&#x27;</span>, <span class="string">&#x27; data_channel_is_bus&#x27;</span>, <span class="string">&#x27; data_channel_is_socmed&#x27;</span>, <span class="string">&#x27; data_channel_is_tech&#x27;</span>, <span class="string">&#x27; data_channel_is_world&#x27;</span>, <span class="string">&#x27; kw_min_min&#x27;</span>, <span class="string">&#x27; kw_max_min&#x27;</span>, <span class="string">&#x27; kw_avg_min&#x27;</span>, <span class="string">&#x27; kw_min_max&#x27;</span>, <span class="string">&#x27; kw_max_max&#x27;</span>, <span class="string">&#x27; kw_avg_max&#x27;</span>, <span class="string">&#x27; kw_min_avg&#x27;</span>, <span class="string">&#x27; kw_max_avg&#x27;</span>, <span class="string">&#x27; kw_avg_avg&#x27;</span>, <span class="string">&#x27; self_reference_min_shares&#x27;</span>, <span class="string">&#x27; self_reference_max_shares&#x27;</span>, <span class="string">&#x27; self_reference_avg_sharess&#x27;</span>, <span class="string">&#x27; weekday_is_monday&#x27;</span>, <span class="string">&#x27; weekday_is_tuesday&#x27;</span>, <span class="string">&#x27; weekday_is_wednesday&#x27;</span>, <span class="string">&#x27; weekday_is_thursday&#x27;</span>, <span class="string">&#x27; weekday_is_friday&#x27;</span>, <span class="string">&#x27; weekday_is_saturday&#x27;</span>, <span class="string">&#x27; weekday_is_sunday&#x27;</span>, <span class="string">&#x27; is_weekend&#x27;</span>, <span class="string">&#x27; LDA_00&#x27;</span>, <span class="string">&#x27; LDA_01&#x27;</span>, <span class="string">&#x27; LDA_02&#x27;</span>, <span class="string">&#x27; LDA_03&#x27;</span>, <span class="string">&#x27; LDA_04&#x27;</span>, <span class="string">&#x27; global_subjectivity&#x27;</span>, <span class="string">&#x27; global_sentiment_polarity&#x27;</span>, <span class="string">&#x27; global_rate_positive_words&#x27;</span>, <span class="string">&#x27; global_rate_negative_words&#x27;</span>, <span class="string">&#x27; rate_positive_words&#x27;</span>, <span class="string">&#x27; rate_negative_words&#x27;</span>, <span class="string">&#x27; avg_positive_polarity&#x27;</span>, <span class="string">&#x27; min_positive_polarity&#x27;</span>, <span class="string">&#x27; max_positive_polarity&#x27;</span>, <span class="string">&#x27; avg_negative_polarity&#x27;</span>, <span class="string">&#x27; min_negative_polarity&#x27;</span>, <span class="string">&#x27; max_negative_polarity&#x27;</span>, <span class="string">&#x27; title_subjectivity&#x27;</span>, <span class="string">&#x27; title_sentiment_polarity&#x27;</span>, <span class="string">&#x27; abs_title_subjectivity&#x27;</span>, <span class="string">&#x27; abs_title_sentiment_polarity&#x27;</span>]</span><br><span class="line">categorical_features =[]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">target = <span class="string">&#x27; shares&#x27;</span></span><br><span class="line"></span><br><span class="line">X = df.drop(target,axis=<span class="number">1</span>)</span><br><span class="line">y = df[target]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="training-and-test-data-split"><a href="#training-and-test-data-split" class="headerlink" title="training and test data split"></a>training and test data split</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><h2 id="define-transformers"><a href="#define-transformers" class="headerlink" title="define transformers"></a>define transformers</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># steps to handle numeric features</span></span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">        (<span class="string">&#x27;num_imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;mean&#x27;</span>)),</span><br><span class="line">        (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># steps to handel categorical features</span></span><br><span class="line">categorical_transformer = Pipeline(steps = [        </span><br><span class="line">      (<span class="string">&quot;cat_imputer&quot;</span>, SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>, fill_value = <span class="string">&quot;missing&quot;</span>)),</span><br><span class="line">      (<span class="string">&quot;encoder&quot;</span>, OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># TFIDF vectorizer to handel the url only</span></span><br><span class="line">tfidfvectorizer = TfidfVectorizer(max_features = <span class="number">100</span>, stop_words=<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a customize transformer to be used in the  ColumnTransformer</span></span><br><span class="line"><span class="comment"># which takes a list of one or string features, and return the word counts for the list of features</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, _X</span>):</span></span><br><span class="line">        X = pd.DataFrame(_X)</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> X.columns:</span><br><span class="line">            X[col]= X[col].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x.split(<span class="string">&#x27;-&#x27;</span>)))</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">counter = Counter()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># integrate a preprocessor to handel different types of features</span></span><br><span class="line"><span class="comment"># notice in the transformer list of the ColumnTransformer,the parameter is &#x27;url&#x27;, a string type</span></span><br><span class="line"><span class="comment"># while parameters for other transformers are list type</span></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;url&#x27;</span>, tfidfvectorizer, <span class="string">&#x27;url&#x27;</span>),</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numeric_transformer, numeric_features),</span><br><span class="line">        (<span class="string">&#x27;count&#x27;</span>, counter, [<span class="string">&#x27;url&#x27;</span>]),</span><br><span class="line">        <span class="comment">#(&#x27;cat&#x27;, categorical_transformer, categorical_features)</span></span><br><span class="line">    ])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check the format of the training data after preprocessing steps</span></span><br><span class="line"><span class="comment"># preprocessor.fit_transform(X_train)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="define-a-whole-piple-to-include-model"><a href="#define-a-whole-piple-to-include-model" class="headerlink" title="define a whole piple to include model"></a>define a whole piple to include model</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pipeline = Pipeline(</span><br><span class="line">    steps =[</span><br><span class="line">        (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),                            </span><br><span class="line">        (<span class="string">&#x27;model&#x27;</span>,RandomForestRegressor(verbose=<span class="number">0</span>, n_jobs=-<span class="number">1</span>))</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pipeline.fit(X_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>Pipeline(steps=[(&#39;preprocessor&#39;,                 ColumnTransformer(transformers=[(&#39;url&#39;,                                                  TfidfVectorizer(max_features=100,                                                                  stop_words=&#39;english&#39;),                                                  &#39;url&#39;),                                                 (&#39;num&#39;,                                                  Pipeline(steps=[(&#39;num_imputer&#39;,                                                                   SimpleImputer()),                                                                  (&#39;scaler&#39;,                                                                   StandardScaler())]),                                                  [&#39; n_tokens_title&#39;,                                                   &#39; n_tokens_content&#39;,                                                   &#39; n_unique_tokens&#39;,                                                   &#39; n_non_stop_words&#39;,                                                   &#39; n_non_stop_unique_tokens&#39;,                                                   &#39; num_hrefs&#39;,                                                   &#39; num_self_hrefs&#39;,                                                   &#39; n...                                                   &#39; data_channel_is_tech&#39;,                                                   &#39; data_channel_is_world&#39;,                                                   &#39; kw_min_min&#39;, &#39; kw_max_min&#39;,                                                   &#39; kw_avg_min&#39;, &#39; kw_min_max&#39;,                                                   &#39; kw_max_max&#39;, &#39; kw_avg_max&#39;,                                                   &#39; kw_min_avg&#39;, &#39; kw_max_avg&#39;,                                                   &#39; kw_avg_avg&#39;,                                                   &#39; self_reference_min_shares&#39;,                                                   &#39; self_reference_max_shares&#39;,                                                   &#39; &#39;                                                   &#39;self_reference_avg_sharess&#39;,                                                   &#39; weekday_is_monday&#39;, ...]),                                                 (&#39;count&#39;, Counter(),                                                  [&#39;url&#39;])])),                (&#39;model&#39;, RandomForestRegressor(n_jobs=-1))])</code></pre><h2 id="plot-the-lift-chart"><a href="#plot-the-lift-chart" class="headerlink" title="plot the lift chart"></a>plot the lift chart</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_predicted_vs_actuals</span>(<span class="params">y_true, y_predicted, title = <span class="string">&quot;Pred Vs Actual&quot;</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    rmse= mean_squared_error(y_true= y_true, y_pred=y_predicted,squared=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;RMSE:&quot;</span>, rmse)</span><br><span class="line">   </span><br><span class="line">    predVsActual = pd.DataFrame( &#123;<span class="string">&#x27;y_true&#x27;</span>: y_true,<span class="string">&#x27;y_pred&#x27;</span>: y_predicted&#125;)</span><br><span class="line">    predVsActual[<span class="string">&quot;pred_deciles&quot;</span>] = pd.qcut(predVsActual[<span class="string">&quot;y_pred&quot;</span>],q=<span class="number">10</span> ,labels=<span class="literal">False</span>, duplicates = <span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line">   </span><br><span class="line">    aggregations = &#123;</span><br><span class="line">        <span class="string">&#x27;y_true&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;y_pred&#x27;</span>: <span class="string">&#x27;mean&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    counts = predVsActual.groupby(<span class="string">&quot;pred_deciles&quot;</span>).count()[<span class="string">&quot;y_pred&quot;</span>]</span><br><span class="line"> </span><br><span class="line">    predVsActual= predVsActual.groupby(<span class="string">&quot;pred_deciles&quot;</span>).agg(aggregations)</span><br><span class="line">    predVsActual[<span class="string">&quot;counts&quot;</span>] = counts</span><br><span class="line">    predVsActual[[<span class="string">&quot;y_true&quot;</span>,<span class="string">&quot;y_pred&quot;</span>]].plot(title=title)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(predVsActual)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">test_preds = pipeline.predict(X_test)</span><br><span class="line">plot_predicted_vs_actuals(y_test, test_preds)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>RMSE: 11240.043547942365</code></pre><p><img src="/content/images/2022-07-16-1.png" alt="lift plot"></p><pre><code>                   y_true        y_pred  countspred_deciles                                   0             1410.976040   1226.474250     7931             2334.482976   1623.177175     7932             2066.532156   1958.356570     7933             2311.552333   2279.694124     7934             2859.727617   2645.796381     7935             2926.430556   3046.564318     7926             3554.585120   3543.738184     7937             4165.051702   4249.105233     7938             4935.030265   5450.838789     7939             6709.374527  11123.519130     793</code></pre><h2 id="code-and-data-link"><a href="#code-and-data-link" class="headerlink" title="code and data link"></a>code and data link</h2><p>please check out this github link: <a href="https://github.com/robotlearner001/blog/tree/main/ColumnTransformer-Example">https://github.com/robotlearner001/blog/tree/main/ColumnTransformer-Example</a></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>An simple but useful example of online calculator using javascript</title>
      <link href="2022/07/05/2022-07-05-1/"/>
      <url>2022/07/05/2022-07-05-1/</url>
      
        <content type="html"><![CDATA[<h2 id="code-link"><a href="#code-link" class="headerlink" title="code link"></a>code link</h2><p><a href="https://github.com/robotlearner001/blog/tree/main/online-calculator-javascript">github link</a></p><h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2> <iframe src="/scripts/calculator/calculator.html" width="100%" height="1000" style="border:1px solid black;"></iframe>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scripts </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hyperparameter tuning using Optuna with RandomForestClassifier Example (Python code)</title>
      <link href="2022/07/02/2022-07-02-1/"/>
      <url>2022/07/02/2022-07-02-1/</url>
      
        <content type="html"><![CDATA[<p>For some popular machine learning algorithms, how to set the hyper parameters could affect machine learning algorithm performance greatly.</p><p>One naive way is to loop though different combinations of the hyper parameter space and choose the best configuration. This is called grid search strategy. But this method could be very slow.</p><p>A better way is to use some kind of optimization method to optimize our optimization. Tools such as Optuna and Hyperopt play roles here.</p><p>In the following, we will use the Optuna as example, and apply it on a Random Forrest Classifier.</p><h2 id="1-Import-libraries-and-get-the-newsgroup-data"><a href="#1-Import-libraries-and-get-the-newsgroup-data" class="headerlink" title="1. Import libraries and get the newsgroup data"></a>1. Import libraries and get the newsgroup data</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">from sklearn.datasets import fetch_20newsgroups</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.metrics import f1_score</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">import joblib</span><br><span class="line">from lightgbm import LGBMClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line">import optuna</span><br><span class="line"></span><br><span class="line">data = fetch_20newsgroups()</span><br><span class="line"></span><br><span class="line">X = data[&#x27;data&#x27;][:5000]</span><br><span class="line">y = data[&#x27;target&#x27;][:5000]</span><br></pre></td></tr></table></figure><h2 id="2-Define-a-machine-leaning-pipeline-with-TfidfVectorizer-and-RandomForestClassifie"><a href="#2-Define-a-machine-leaning-pipeline-with-TfidfVectorizer-and-RandomForestClassifie" class="headerlink" title="2. Define a machine leaning pipeline with TfidfVectorizer and RandomForestClassifie"></a>2. Define a machine leaning pipeline with TfidfVectorizer and RandomForestClassifie</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model = Pipeline([</span><br><span class="line">    (&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),   </span><br><span class="line">    (&#x27;rf&#x27;, RandomForestClassifier())</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h2 id="3-Define-hyper-parameter-space-and-Optuna-objective-to-optimize"><a href="#3-Define-hyper-parameter-space-and-Optuna-objective-to-optimize" class="headerlink" title="3. Define hyper parameter space and Optuna objective to optimize"></a>3. Define hyper parameter space and Optuna objective to optimize</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def objective(trial):    </span><br><span class="line">    </span><br><span class="line">    joblib.dump(study, &#x27;study.pkl&#x27;)</span><br><span class="line">    </span><br><span class="line">    tfidf__analyzer = trial.suggest_categorical(&#x27;tfidf__analyzer&#x27;, [&#x27;word&#x27;, &#x27;char&#x27;, &#x27;char_wb&#x27;]) </span><br><span class="line">    tfidf__lowercase = trial.suggest_categorical(&#x27;tfidf__lowercase&#x27;, [False, True]) </span><br><span class="line">    tfidf__max_features = trial.suggest_int(&#x27;tfidf__max_features&#x27;, 500, 10_000) </span><br><span class="line">    rf__n_estimators = trial.suggest_int(&#x27;rf__num_estimators&#x27;, 300, 500) </span><br><span class="line">    rf__max_depth = trial.suggest_int(&#x27;rf__max_depth&#x27;, 5, 15) </span><br><span class="line">    rf__min_samples_split = trial.suggest_int(&#x27;rf__min_samples_split&#x27;, 10, 30) </span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    params = &#123;</span><br><span class="line">        &#x27;tfidf__analyzer&#x27;: tfidf__analyzer,</span><br><span class="line">        &#x27;tfidf__lowercase&#x27;: tfidf__lowercase,</span><br><span class="line">        &#x27;tfidf__max_features&#x27;: tfidf__max_features,</span><br><span class="line">        &#x27;rf__n_estimators&#x27;: rf__n_estimators,</span><br><span class="line">        &#x27;rf__max_depth&#x27;: rf__max_depth,</span><br><span class="line">        &#x27;rf__min_samples_split&#x27;: rf__min_samples_split,</span><br><span class="line">       </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    model.set_params(**params)</span><br><span class="line"></span><br><span class="line">    return  -np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,scoring=&#x27;neg_log_loss&#x27;))</span><br></pre></td></tr></table></figure><p>Notice that, by default Optuna tries to minimize the objective function, since we use native log loss function to maximize the Random Forrest Classifier, we add another negative sign in in front of the cross-validation scores.</p><h2 id="4-Run-the-Optuna-trials-to-find-the-best-hyper-parameter-configuration"><a href="#4-Run-the-Optuna-trials-to-find-the-best-hyper-parameter-configuration" class="headerlink" title="4. Run the Optuna trials to find the best hyper parameter configuration"></a>4. Run the Optuna trials to find the best hyper parameter configuration</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># by default, the direction is to minimizae, but can set it to maximize too</span><br><span class="line">#study = optuna.create_study(direction=&#x27;minimize&#x27;)</span><br><span class="line">study = optuna.create_study()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#study.optimize(objective, timeout=3600)</span><br><span class="line">study.optimize(objective, n_trials=20)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># to record the value for the last time</span><br><span class="line">joblib.dump(study, &#x27;study.pkl&#x27;)</span><br></pre></td></tr></table></figure><p>Notice that, we are saving the hyper parameter optimization process into a local pickle file, which means we can monitor the process in the middle or at the end by opening another notebook.</p><h2 id="5-how-to-visualize-the-results"><a href="#5-how-to-visualize-the-results" class="headerlink" title="5. how to visualize the results"></a>5. how to visualize the results</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">import joblib</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import optuna</span><br><span class="line"></span><br><span class="line">data = joblib.load(&#x27;study.pkl&#x27;)</span><br><span class="line"></span><br><span class="line">df = data.trials_dataframe()</span><br><span class="line">df.dropna(inplace=True)</span><br><span class="line">df.reset_index(inplace=True)</span><br><span class="line"></span><br><span class="line">df[&#x27;time&#x27;] = (df.datetime_complete - df.datetime_start).dt.total_seconds()</span><br><span class="line">df = df[df.time&gt;=0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(&#x27;best val:&#x27;,  round(df.value.min(),4))</span><br><span class="line">print(&#x27;best params:&#x27;,  data.best_params)</span><br><span class="line"></span><br><span class="line">a = sns.lineplot(x=df.index, y=df.value.cummin())</span><br><span class="line">a.set_xlabel(&#x27;trial number&#x27;)</span><br><span class="line">sns.scatterplot(x=df.index, y=df.value, color=&#x27;red&#x27;)</span><br><span class="line">a.set_ylabel(&#x27;log loss&#x27;)</span><br><span class="line">a.legend([&#x27;best value&#x27;, &quot;trial&#x27;s value&quot;]);</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-07-02-1.png" alt="Optuna tuning results with trails"></p><h2 id="6-download-the-whole-code-notebook"><a href="#6-download-the-whole-code-notebook" class="headerlink" title="6. download the whole code notebook"></a>6. download the whole code notebook</h2><p><a href="https://github.com/robotlearner001/blog/tree/main/hyper-parameter-tunning">github link</a></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hyperparameter tuning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to insert images in DataBricks notebook</title>
      <link href="2022/06/22/2022-06-22-1/"/>
      <url>2022/06/22/2022-06-22-1/</url>
      
        <content type="html"><![CDATA[<p>Following steps show how to upload images to databricks filestore, and insert that path in the notebook cell.</p><h2 id="upload-the-image-to-databricks"><a href="#upload-the-image-to-databricks" class="headerlink" title="upload the image to databricks"></a>upload the image to databricks</h2><p>As shown in the following, in the homepage of your databricks account, click the import and explore data part.</p><p><img src="/content/images/2022-06-22-1.png" alt="step1"></p><p>after the this, in the upload file menu, further click the drop file place to choose image file from your local computer.</p><p><img src="/content/images/2022-06-22-2.png" alt="step2"></p><p>with this being successful, you will see the path of the image you just uploaded, here our file name is called dbx_test.png,<br>as shown in the following:</p><p><img src="/content/images/2022-06-22-3.png" alt="step3"></p><h2 id="insert-the-image-path-using-markdown-in-notebook"><a href="#insert-the-image-path-using-markdown-in-notebook" class="headerlink" title="insert the image path using markdown in notebook"></a>insert the image path using markdown in notebook</h2><p>Notice that, the path begins with /FileStore/, but we need replace with file/, as shown in the following:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">%md</span><br><span class="line">![test image](files/tables/dbx_test.png)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>in the above code, “test image” is just some description you can name whatever you want to.</p><p>As the result, after your run the cell, you will see the image shown up like this:</p><p><img src="/content/images/2022-06-22-4.png" alt="step4"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> databricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to plot mulitiple subplots of barplots using seaborn</title>
      <link href="2022/05/15/2022-05-15-1/"/>
      <url>2022/05/15/2022-05-15-1/</url>
      
        <content type="html"><![CDATA[<p>Sometimes we want to plot multiple barplots in subplots, this examples shows a nice way to do it.</p><h2 id="load-sample-data"><a href="#load-sample-data" class="headerlink" title="load sample data"></a>load sample data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set_theme(style=<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tips.head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>total_bill</th>      <th>tip</th>      <th>sex</th>      <th>smoker</th>      <th>day</th>      <th>time</th>      <th>size</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>16.99</td>      <td>1.01</td>      <td>Female</td>      <td>No</td>      <td>Sun</td>      <td>Dinner</td>      <td>2</td>    </tr>    <tr>      <th>1</th>      <td>10.34</td>      <td>1.66</td>      <td>Male</td>      <td>No</td>      <td>Sun</td>      <td>Dinner</td>      <td>3</td>    </tr>  </tbody></table></div><h2 id="aggregate-the-data-by-day-and-sex-and-sum-tips-for-each-dimension"><a href="#aggregate-the-data-by-day-and-sex-and-sum-tips-for-each-dimension" class="headerlink" title="aggregate the data by day and sex, and sum tips for each dimension"></a>aggregate the data by day and sex, and sum tips for each dimension</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tips_agg = tips.groupby([<span class="string">&#x27;day&#x27;</span>,<span class="string">&#x27;sex&#x27;</span>])[<span class="string">&#x27;tip&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line">tips_agg</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>day</th>      <th>sex</th>      <th>tip</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Thur</td>      <td>Male</td>      <td>89.41</td>    </tr>    <tr>      <th>1</th>      <td>Thur</td>      <td>Female</td>      <td>82.42</td>    </tr>    <tr>      <th>2</th>      <td>Fri</td>      <td>Male</td>      <td>26.93</td>    </tr>    <tr>      <th>3</th>      <td>Fri</td>      <td>Female</td>      <td>25.03</td>    </tr>    <tr>      <th>4</th>      <td>Sat</td>      <td>Male</td>      <td>181.95</td>    </tr>    <tr>      <th>5</th>      <td>Sat</td>      <td>Female</td>      <td>78.45</td>    </tr>    <tr>      <th>6</th>      <td>Sun</td>      <td>Male</td>      <td>186.78</td>    </tr>    <tr>      <th>7</th>      <td>Sun</td>      <td>Female</td>      <td>60.61</td>    </tr>  </tbody></table></div><h2 id="install-the-latest-seaborn-package-if-not-installed"><a href="#install-the-latest-seaborn-package-if-not-installed" class="headerlink" title="install the latest seaborn package if not installed"></a>install the latest seaborn package if not installed</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install seaborn==<span class="number">0.11</span><span class="number">.2</span></span><br></pre></td></tr></table></figure><h2 id="visualize-the-total-tips-of-male-vs-female-for-each-different-weekday-in-the-data"><a href="#visualize-the-total-tips-of-male-vs-female-for-each-different-weekday-in-the-data" class="headerlink" title="visualize the total tips of male vs female, for each different weekday in the data"></a>visualize the total tips of male vs female, for each different weekday in the data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># automatically adjust the rows and colums </span></span><br><span class="line">all_days = <span class="built_in">list</span>(<span class="built_in">set</span>(tips_agg[<span class="string">&#x27;day&#x27;</span>]))</span><br><span class="line">n_cols = <span class="number">3</span></span><br><span class="line">n_rows = math.ceil(<span class="built_in">len</span>(all_days)/n_cols)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># give the figsize</span></span><br><span class="line">fig, axes = plt.subplots( n_rows, n_cols, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_rows):</span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_cols):</span><br><span class="line">    index = i*n_cols+j</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> index &gt;= <span class="built_in">len</span>(all_days):</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    day = all_days[index]</span><br><span class="line">    bp = sns.barplot(ax=axes[i, j], data=tips_agg[tips_agg[<span class="string">&#x27;day&#x27;</span>]==day], x=<span class="string">&#x27;sex&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>)</span><br><span class="line">    bp.<span class="built_in">set</span>(title=day)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> bp.get_xticklabels():</span><br><span class="line">        item.set_rotation(<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if the x axis title is very long, this configuration will be very useful </span></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/content/images/2022-05-15-1.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> seaborn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to use SentenceTransformer, a powerful and simple text embedding method based on transformer methods</title>
      <link href="2022/04/10/2022-04-10-1/"/>
      <url>2022/04/10/2022-04-10-1/</url>
      
        <content type="html"><![CDATA[<p>SentenceTransfomer is a Python framework developed based on Sentence-BERT that can generate high-quality embedding vectors for sentences and short texts.<br>Many languages including English and Chinese are supported.<br>Compared with the BERT model, the sentencetransformer is simpler to use, and the vector can be directly obtained by passing in the text.</p><h2 id="how-to-install"><a href="#how-to-install" class="headerlink" title="how to install"></a>how to install</h2><p>Recommended Python 3.6 or higher, PyTorch 1.6.0 or higher, and transformers v4.6.0 or higher developed by huggingface.<br>Notice that Python 2.7 environment will not work.</p><p>Sometimes, the installation may not be successful, it may be a pip version compatibility problem, you can upgrade the pip package first</p><p>python3 -m pip install –upgrade pip</p><p>then to this:</p><p>pip install -U sentence-transformers</p><h2 id="import-the-package"><a href="#import-the-package" class="headerlink" title="import the package"></a>import the package</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br></pre></td></tr></table></figure><h1 id="English-embedding-example"><a href="#English-embedding-example" class="headerlink" title="English embedding example"></a>English embedding example</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line">model = SentenceTransformer(<span class="string">&#x27;paraphrase-MiniLM-L6-v2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Our sentences we like to encode</span></span><br><span class="line">sentences = [<span class="string">&#x27;This framework generates embeddings for each input sentence&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sentences are passed as a list of string.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;The quick brown fox jumps over the lazy dog.&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Sentences are encoded by calling model.encode()</span></span><br><span class="line">embeddings = model.encode(sentences)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Print the embeddings</span></span><br><span class="line"><span class="keyword">for</span> sentence, embedding <span class="keyword">in</span> <span class="built_in">zip</span>(sentences, embeddings):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Sentence:&quot;</span>, sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Embedding:&quot;</span>, embedding)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Sentence: This framework generates embeddings for each input sentenceEmbedding: [-1.76214531e-01  1.20601252e-01 -2.93624073e-01 -2.29858026e-01 -8.22923928e-02  2.37709522e-01  3.39984864e-01 -7.80964196e-01  1.18127614e-01  1.63373962e-01 -1.37715712e-01  2.40282789e-01  4.25125599e-01  1.72417849e-01  1.05279692e-01  5.18164098e-01  6.22218400e-02  3.99285793e-01 -1.81652278e-01 -5.85578680e-01  4.49722409e-02 -1.72750309e-01 -2.68443495e-01 -1.47386149e-01 -1.89217970e-01  1.92150578e-01 -3.83842468e-01 -3.96007091e-01  4.30648863e-01 -3.15320134e-01  3.65949631e-01  6.05158620e-02  3.57325703e-01  1.59736529e-01 -3.00983816e-01  2.63250291e-01 -3.94311100e-01  1.84855521e-01 -3.99549276e-01 -2.67889529e-01 -5.45117497e-01 -3.13403942e-02 -4.30644333e-01  1.33278117e-01 -1.74793795e-01 -4.35465544e-01 -4.77379113e-01  7.12555572e-02 -7.37001151e-02  5.69137156e-01 -2.82579720e-01  5.24975285e-02 -8.20007861e-01  1.98296756e-01  1.69511825e-01  2.71780342e-01  2.64610827e-01 -2.55737714e-02 -1.74096107e-01  1.63314253e-01 -3.95260930e-01 -3.17556299e-02 -2.62556046e-01  3.52754712e-01  3.01434875e-01 -1.47197291e-01  2.10075796e-01 -1.84010491e-01 -4.12896037e-01  4.14775789e-01 -1.89769492e-01 -1.35482445e-01 -3.79272133e-01 -4.68020439e-02 -3.33601385e-02  9.00394097e-02 -3.30133140e-01 -3.87316942e-02  3.75082314e-01 -1.46996319e-01  4.34959829e-01  5.38325727e-01 -2.65445173e-01  1.64445907e-01  4.17078644e-01 -4.72508594e-02 -7.48731196e-02 -4.26261097e-01 -1.96994558e-01  6.10316209e-02 -4.74262655e-01 -6.48334742e-01  3.71462464e-01  2.50957102e-01  1.22529611e-01  8.88766572e-02 -1.06724210e-01  5.33984490e-02  9.74507183e-02 -3.46660167e-02 -1.02882817e-01  2.32289001e-01 -2.53739536e-01 -5.13112307e-01  1.85216278e-01 -3.04357797e-01 -3.55209075e-02 -1.26975372e-01 -7.71632940e-02 -5.15330076e-01 -2.28071719e-01  2.03343164e-02  7.38175958e-02 -1.52558655e-01 -4.00837570e-01 -2.47749180e-01  3.97470325e-01 -2.60260701e-01  2.50906169e-01  1.68228924e-01  1.33900508e-01 -2.10833233e-02 -4.70035732e-01  4.78850156e-01  2.80345589e-01 -4.64546800e-01  3.21747035e-01  2.34207422e-01  2.45772451e-01 -4.71482307e-01  5.00400960e-01  4.10190076e-01  5.15216827e-01  2.62549460e-01  2.11593546e-02 -3.89687568e-01 -2.41742760e-01 -2.14834630e-01 -8.62650797e-02 -1.65323570e-01 -5.21895029e-02  3.41874868e-01  4.50314462e-01 -3.06973577e-01 -2.02294186e-01  6.85521722e-01 -5.33892572e-01  3.58471543e-01  1.45286605e-01 -7.07056001e-02 -1.50529072e-01 -8.56279582e-02 -7.67851025e-02  1.89544857e-01 -1.04067773e-01  5.33544004e-01 -5.27887225e-01  2.42332090e-02 -2.64348090e-01 -2.23186895e-01 -3.81208718e-01  7.59914368e-02 -4.64485109e-01 -3.36549252e-01  4.21229839e-01  1.07479207e-01  1.90457791e-01  2.89487489e-03 -1.08513705e-01  1.53545350e-01  3.16023648e-01 -2.70840749e-02 -5.40594459e-01  8.97286758e-02 -1.15549676e-01  3.97803992e-01 -4.97683346e-01 -2.84893364e-01  4.99861799e-02  3.61279696e-01  6.90535665e-01  1.46821439e-01  1.73396602e-01 -1.74582347e-01 -3.15702260e-01  6.72999769e-02  2.17250243e-01  9.78535116e-02 -1.29472464e-01 -1.86929435e-01  1.34878129e-01 -1.53885290e-01  7.44715557e-02 -1.85536250e-01 -2.80628383e-01 -1.14144213e-01  4.12249625e-01  6.39491975e-02 -1.45715117e-01 -9.82065052e-02 -1.33081883e-01 -1.88410461e-01 -2.84838937e-02 -3.49510163e-02  3.34258713e-02  6.98896796e-02  1.90354511e-01 -2.96724051e-01  2.64706067e-03  1.09140947e-01  1.70892701e-02  2.60589242e-01  3.29038620e-01 -6.61560148e-02  2.39665717e-01 -2.26194620e-01 -3.36869545e-02  1.49400130e-01 -3.21265638e-01 -2.68577904e-01  5.72632015e-01 -4.92308497e-01  2.00666577e-01 -3.49261820e-01 -2.89886612e-02  6.09010458e-01 -5.72333157e-01  2.35000670e-01  6.47180574e-03 -3.14952508e-02  2.78108083e-02 -3.90340954e-01 -2.08950117e-01 -3.04452837e-01 -7.20199272e-02 -8.29840004e-02  3.73792857e-01  7.38937110e-02 -2.21076086e-02  9.88139287e-02 -1.51426882e-01 -1.40430734e-01  2.26017952e-01  2.76089966e-01 -8.87747630e-02 -1.12816028e-01 -2.66286045e-01  2.77834296e-01 -4.75609973e-02  6.71005547e-02 -2.78584175e-02 -2.39991937e-02  2.51708686e-01  4.68793899e-01 -5.39325476e-01  1.10598475e-01 -3.44947308e-01  4.15990084e-01  7.28483498e-02 -3.19647521e-01  4.90374565e-01 -7.30331149e-03 -2.64252443e-03  9.63711083e-01  3.23884904e-01 -7.79616535e-02 -2.37589255e-01  2.34038591e-01 -3.16053987e-01 -1.65628293e-03 -1.09070671e+00  3.38409364e-01  4.70607281e-02  1.07435413e-01 -2.06672356e-01  4.26446088e-03 -1.38461241e-03 -5.31455636e-01 -2.75648654e-01 -1.64648622e-01 -3.42916757e-01 -4.26118672e-01  6.01811945e-01  4.55971897e-01 -2.72701889e-01 -3.45802940e-02  2.62752354e-01 -6.34185225e-03  2.79631346e-01 -2.53559053e-01 -1.68626338e-01  3.82934660e-02  2.07763135e-01 -4.31525975e-01 -7.24000558e-02 -1.26854450e-01  2.07029749e-02  5.74441731e-01  3.54672432e-01  9.28300545e-02  6.70508668e-02  1.11520678e-01 -1.86510980e-02  4.62352097e-01  2.72504926e-01 -3.60474110e-01  5.29415369e-01 -1.00318261e-03 -8.81360695e-02  1.49975494e-01  5.25862724e-02  4.63517487e-01 -3.96831542e-01  2.42640823e-01 -2.08912537e-01  3.65672290e-01 -4.73500433e-04  5.33963263e-01 -1.97879612e-01  3.11582744e-01 -6.96715057e-01 -4.29500550e-01 -4.49359566e-01 -2.71372199e-02 -6.98710978e-02  2.06174582e-01 -1.57107800e-01  4.43521202e-01 -6.74267337e-02 -3.00924033e-01  5.14859557e-01  3.36029828e-01  6.63376600e-02 -1.15235247e-01 -2.95982286e-02  2.79471755e-01 -3.48201916e-02 -7.29324743e-02 -4.58472408e-02  1.54262856e-01  8.09356570e-01  5.20328224e-01 -4.02114749e-01 -3.23152021e-02 -1.10364027e-01  7.50505254e-02 -1.51098579e-01  8.45740080e-01 -1.80843890e-01  3.22573632e-01  1.04708321e-01  3.19663644e-01 -1.55085236e-01  1.69236735e-01 -2.56996632e-01  2.01208770e-01  1.77393183e-01 -2.74333179e-01 -3.36944580e-01  5.02356887e-01 -1.18357182e-01 -2.01166973e-01 -5.36485910e-01 -7.69810379e-02  1.15382867e-02 -2.36464664e-01 -2.98771430e-02  1.31366640e-01  2.94184387e-01  9.90917012e-02 -5.43897867e-01  1.40812770e-01  3.66998672e-01  5.04861325e-02  1.99122518e-01 -2.80674815e-01  4.34192061e-01 -1.40274823e-01  5.78048944e-01  1.77715778e-01  8.98364484e-02  3.29651892e-01  6.13008775e-02 -3.24933589e-01]Sentence: Sentences are passed as a list of string.Embedding: [ 0.32208762 -0.00123908  0.17937377 -0.36919138 -0.06460274  0.09153692  0.24119096 -0.29494217  0.07728957  0.11577005 -0.04479983  0.17928234  0.1475363   0.21511652  0.36810791  0.20910913  0.27194238  0.34880087 -0.57251936 -0.18253218  0.4448957   0.27452925  0.04266282 -0.07683562  0.18689147  0.4496505  -0.16932622 -0.24896334 -0.20479265  0.40285036 -0.2101927   0.03775701  0.07848521  0.12848447  0.02593089  0.4715598  0.17853785 -0.07379771  0.08130724 -0.23328738 -0.49801245 -0.04135723 -0.12094605  0.17028998 -0.19154078 -0.38459808 -0.77479136 -0.10622733 -0.2304489   0.4024145  -0.8745089   0.23853712 -0.4712986   0.21262182  0.3340935  -0.24154    -0.1483509  -0.14513564 -0.34830925 -0.08349245 -0.69097275 -0.29845262 -0.12230504  0.07482646 -0.18775596 -0.3754651  0.21369492 -0.10096409 -0.12234445  0.31431514 -0.23989926  0.22460794  0.0399599   0.36034834 -0.5663802   0.21883512  0.11020288 -0.10870823  0.07084075 -0.02608179  0.18370324  0.08465949 -0.20478249 -0.24435617 -0.08180565 -0.01903111 -0.03591372  0.02398443 -0.2855857   0.07374766 -0.29744208 -0.87717843  0.47101936 -0.0494047   0.36394492  0.482644  0.01564615  0.03558917 -0.26203    -0.1121847   0.0241104   0.37477782 -0.09897303 -0.09851858  0.15000843  0.00689534 -0.12652436 -0.3159893  0.31449488 -0.2942561  -0.2694104   0.20221162  0.14329888 -0.19584627 -0.3410443  -0.03172762  0.7365027   0.31923506  0.2438129   0.30732602  0.09933245  0.19010943 -0.10694525  0.05178664  0.03233436 -0.10314636  0.2649922   0.31206465  0.43152618 -0.6426122   0.0840958  -0.0432735 -0.04991193 -0.12718563  0.13789187  0.01306224  0.34383258  0.09234294 -0.09922738 -0.52159905  0.25842273 -0.01057126 -0.00478189  0.03938858  0.19086099  0.32933885 -0.24345161 -0.07328319 -0.39280015  0.14541808  0.32839534 -0.04184634  0.07407122 -0.7386053  -0.09076015  0.15802307 -0.09780021 -0.21605958 -0.30027467  0.2323658   0.01072446  0.49570465  0.04974837  0.29931435 -0.05382248  0.35328114  0.3419176   0.49667245 -0.4860523  -0.19098845  0.8154575   0.22962622 -0.32077783 -0.32726687 -0.367717    0.3452114  -0.02620159 -0.14315048  0.10648432 -0.24638046 -0.09366632  0.17198639 -0.08508814  0.20120296 -0.05879208 -0.34020975 -0.19565329  0.2828087   0.20124306 -0.08207255  0.09779122 -0.26375008  0.12176559 -0.01041479 -0.4385985   0.11058219  0.48010394 -0.10981981 -0.6375458   0.29336807 -0.1920764   0.46536973  0.2704201   0.19388463  0.17379023 -0.3007702  -0.0275121  -0.02291276  0.3678463   0.02492153  0.53705496  0.18851233 -0.13344418  0.08917347  0.05542957 -0.24818316 -0.04199777  0.05767386 -0.18278812 -0.41686475  0.16070595 -0.46362543  0.11769217 -0.3770692   0.02960374  0.692561   -0.4830891   0.21128401  0.18214527 -0.18429579  0.0681766  -0.02460879 -0.19073623 -0.06736984 -0.5670072  -0.23929311 -0.08497227  0.03093951  0.31079894  0.1291628  0.05248259 -0.3344983   0.18810134  0.23547177 -0.00183485  0.45361614  0.24885082 -0.05641065 -0.2977458  -0.43511704 -0.07969435 -0.17670156 -0.13347092  0.1938272   0.22002596 -0.11057543  0.26473755 -0.27179065  0.03410878 -0.4771442   0.44719058 -0.05570416  0.39643747  0.27483267  0.33305615 -0.10890252  0.2788817   0.21596934 -0.05252272 -0.35867548 -0.69062907  0.03960182  0.00652785 -0.01095348 -0.10027702  0.04770013 -0.34146932 -0.16714163  0.07136464 -0.1807847  -0.30248472 -0.68428737 -0.09592848 -0.2141112  -0.6552438   0.5675644   0.26946738 -0.00190061  0.8618065   0.16771556  0.03102748 -0.2677305  -0.07830263 -0.48510885 -0.26737222 -0.33354253 -0.5738254   0.35678256  0.08993588 -0.13057196 -0.1513651  -0.06124125 -0.13037089  0.5585606   0.614175   -0.04804054 -0.0638859   0.08390605 -0.25143692 -0.04359839 -0.18525787  0.04693348 -0.34380865 -0.09738468  0.1683365   0.0752685   0.1769452   0.17727177 -0.03423442  0.14993554 -0.13773166 -0.20949684 -0.6127283   0.3781397  0.3901828  -0.08359346  0.03152128  0.13122386  0.38826075  0.21844254  0.0972431   0.42089358 -0.3264124  -0.26933426 -0.39095107 -0.22648653 -0.32020715 -0.16287427 -0.03581636  0.363739    0.18583307 -0.0291401 -0.46577957  0.2916888   0.37251312 -0.23726626  0.00338617  0.41540965  0.03300428  0.4500395  -0.08159234  0.33990335  0.24497904  0.0235242 -0.1464306  -0.12644552  0.31128627 -0.15182619  0.01009398  0.49108496  0.14362407  0.11589024 -0.23236984  0.2475176   0.1836449  -0.24836856 -0.11220913 -0.23113322  0.0842896  -0.24378659  0.13307258  0.42355725  0.33348376 -0.3437014   0.0344367   0.18795514  0.20037197 -0.05355961  0.2848529   0.0717658   0.05487169 -0.08103789  0.27076873  0.11700248]Sentence: The quick brown fox jumps over the lazy dog.Embedding: [ 0.58979344 -0.23598255 -0.25411725  0.00311624 -0.08485737 -0.26799768 -0.07506651 -0.3002136   0.05151652  0.16585363  0.26076776  0.38256362  0.43732867 -0.09301949 -0.26568803 -0.09716298 -0.48096094  0.11878292  0.13675483  0.04712067 -0.23696537 -0.52332336 -0.01631867  0.06127304 -0.7433302  -0.11898906 -0.7886529  -0.48108855  0.10314927 -0.32372454  0.8144374  -0.39774537 -0.50315547 -0.7972457  -0.6324822   0.32320985 -0.38419437 -0.11186695 -0.1324357   0.02069666 -0.14309539 -0.0370119  0.06116579  0.16332883 -0.11174309  0.25234267 -1.0464071  -0.37252343  0.15601997 -0.29991606  0.19883864  0.2343344  -0.3702577   0.31733564  0.84428644  0.06977719  0.03273663  0.09948339 -0.31141308  0.50517714  0.00309272  0.38013652  0.04582737  0.00633379 -0.00142918 -0.13568659 -0.07611365 -0.25844312 -0.8022129   0.5508589  -0.09124386 -0.21782017 -0.78810936 -0.5118384   0.46672547  0.55274725 -0.37124714 -0.18645377  0.3585697  -0.19586323  0.18042535 -0.42548886 -0.09681422 -0.05536837  0.52489287  0.24481142  0.01934664 -0.29637936 -0.1277783  -0.30534947  0.45349374  0.07469101 -0.07061689  0.2624302   0.37383935  0.14306359  0.00127857 -0.41776088 -0.24014093 -0.2509353   0.34843782  0.31144044  0.0808733  -0.5764053   0.54085284 -0.01802203 -0.12959798 -0.07399664  0.3936979   0.6488388  -0.02030003 -0.5665558   0.2967598   0.520002  0.21538728  0.10369676  0.06199208  0.01896283 -0.15269236 -1.0642662  0.7614961   0.20734386  0.44718924  0.14493968  0.6580228  -0.09440905 -0.23316365  0.4215707   0.1195763  -0.32571068  0.16425563 -0.49508703 -0.19516118 -0.56183213 -0.14933276  0.610941   -0.17897959 -0.01805552 -0.5964053   0.04918591  0.15347804 -0.42829406  0.73295283 -0.35291103 -0.11159656  0.06127812 -0.29704392  0.4396664  -0.09660351  0.65579444 -0.61403424  0.02576606  0.43827453  0.01733282 -0.40002275 -0.08178308 -0.37126926  0.08230279 -0.13104396 -0.5326111  -0.29928368  0.6993657 -0.04398742 -0.15702991  0.09794132 -0.03017466 -0.10002708  0.199966 -0.4818854   0.17949156  0.5656603  -0.11954784 -0.696373    0.05259641 -0.00549608  0.16739355 -0.31692895 -0.09747531  0.33193663  0.4719962  0.12653954  0.19130926  0.42949092  0.55291235  0.31463274 -0.31433088 -0.41508684  0.32897702  0.35702732 -0.1920966   0.22239415 -0.48717856  0.3409156  -0.22137432 -0.1266758   0.21120834 -0.31347895  0.8468937  0.20112668 -0.42598733  0.5131572  -1.2351419   0.76971793 -0.17414267 -0.02181136 -0.0356865  -1.105949   -0.5720654   0.05585196  0.12461495 -0.45065832  0.06428951 -0.16033873  0.39932927 -0.10322935 -0.02025502 -0.18010448  0.06234786 -0.02188883 -0.15795426  0.28316957  0.02385282  0.03098137 -0.07853306  0.29896578 -0.06237327  0.5498678   0.17862315  0.2116474   0.44483367  0.04890747 -0.162381   -0.22669895  0.18871985  0.07943622  0.1359757  -0.18484493  1.113551    0.82809544 -0.31202707  0.09505999  0.05096091  0.38804898  0.25000468  0.558486    0.31088772 -0.05318568 -0.07675371  0.15282278  0.09189964 -0.01429148  0.6657543 -0.03346021 -0.44703493  0.80067486 -0.4799278   0.17478174 -0.30563813  0.5536521   0.42380962  0.48674306 -0.49677992 -0.45194814 -0.95563084 -0.20709987 -0.22605716 -0.0099914   0.98797685  0.5880775   0.08305439 -0.5578132   0.21136862 -0.3607222   0.52668494  0.33983573 -0.15756187  0.00423779 -0.05354516 -0.5777671   0.5595104  -0.05747148  0.16837652  0.37946853 -0.25776428  0.08421484 -0.15229936 -0.03280768  0.10083867 -0.41858304 -0.44499016 -0.29309887  0.6144206   0.08548218 -0.06349564 -0.6152552   0.79544085 -0.24058406  0.2063889  -0.5125261   0.6312013  0.36744294 -0.4400988   0.46913967  0.23087728 -0.13737966  0.21696861  0.40043226 -0.02490607 -1.139676    0.02653918 -0.32730213  0.09984124  0.05725667 -0.84722155  0.06451946  0.45698035  0.63563025  0.45185634 -0.2751906   0.21346165  0.17374253  0.42822042 -0.6584535   0.4000258 -0.02035557 -0.6730788  -1.0269238   0.16877282 -0.09248707 -0.79977626  0.38093373  0.5171233   0.04200954 -0.04867526 -0.18772238  0.16339499 -0.21974911  0.21939285  0.03676502 -0.29750267 -0.37409678 -0.52095085 -0.41314605 -0.489477   -0.8189662   0.08531482  0.34576944  0.12505981  0.24945222 -0.25254658 -0.03156116  0.27573124 -0.60857177  0.3357  0.22913106  0.6607082  -0.30215803 -0.05315317  0.22247504  0.06138719  0.33555198 -0.0848518   0.08764573  0.10872053 -0.40389338 -0.14949782  0.19458489 -0.81060654  0.79730946 -0.41162547  0.01364165  0.23472963 -0.09732277 -0.29044035  0.03843231 -0.07090472 -0.17404465 -0.44859377 -0.31867278  0.4165608  -0.05431673  0.14036179  1.0559161   0.5301814 ]</code></pre><h2 id="English-embedding-example-with-a-new-pretrained-model"><a href="#English-embedding-example-with-a-new-pretrained-model" class="headerlink" title="# English embedding example with a new pretrained model"></a># English embedding example with a new pretrained model</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line">model = SentenceTransformer(<span class="string">&#x27;distiluse-base-multilingual-cased-v1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Our sentences we like to encode</span></span><br><span class="line">sentences = [<span class="string">&#x27;早上好&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;今天天气非常不错&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Sentences are encoded by calling model.encode()</span></span><br><span class="line">embeddings = model.encode(sentences)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Print the embeddings</span></span><br><span class="line"><span class="keyword">for</span> sentence, embedding <span class="keyword">in</span> <span class="built_in">zip</span>(sentences, embeddings):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Sentence:&quot;</span>, sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Embedding:&quot;</span>, embedding)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><pre><code>Sentence: 早上好Embedding: [ 3.36048612e-03 -7.75053650e-02 -8.92517120e-02 -1.98542904e-02  4.86167856e-02  4.26223725e-02 -3.25850174e-02 -6.78801164e-03  1.58829652e-02 -2.43490171e-02  1.48126129e-02  6.55123359e-03  1.14513915e-02  3.69007923e-02 -1.88735481e-02 -1.18097216e-02  8.75925422e-02  3.32120210e-02  4.86210473e-02 -9.08677280e-03  1.27627403e-02 -3.61923464e-02 -2.31466126e-02 -2.86142770e-02 -2.80293375e-02  2.24176962e-02  9.83241759e-03 -1.76876169e-02 -3.93512547e-02 -6.60814941e-02 -6.64236844e-02  4.22375835e-02 -4.41516377e-02 -4.42469940e-02  5.83056957e-02 -6.70481995e-02 -3.44123617e-02  4.91611883e-02  1.23786274e-02  2.88232397e-02  3.48660462e-02 -9.41558462e-03 -4.65008654e-02  3.93482149e-02 -2.03807093e-02 -9.81736463e-03 -4.63420851e-03  4.13698182e-02 -7.43050594e-03  5.26707247e-02  4.63205464e-02  1.36748822e-02 -4.64802980e-02 -4.62170877e-02 -3.83359045e-02 -7.37623349e-02 -2.15301700e-02 -7.80433509e-03  6.28040507e-02 -1.95669127e-03  2.84056198e-02  5.01199141e-02 -4.69665565e-02  2.13841908e-02 -7.29201362e-02 -1.84297003e-02 -4.63314839e-02 -4.66326475e-02  4.06820178e-02 -2.62741838e-02 -1.58835202e-04  1.89249944e-02 -1.58798080e-02 -5.56862354e-02 -1.65423111e-03  5.79530513e-03 -4.80827615e-02  2.83442414e-03 -3.37332375e-02 -4.59188670e-02  1.84609480e-02 -8.43395516e-02 -4.98937443e-02  1.62628964e-02 -2.68908050e-02  2.94992961e-02  3.94213945e-02  1.89540815e-02 -1.49033396e-02  1.54328160e-02  6.68804627e-03 -2.17899680e-02 -6.37249798e-02  7.95044973e-02 -6.71640486e-02  1.53331548e-01  1.22375209e-02 -7.15146493e-03 -3.51416469e-02 -5.64979836e-02 -7.00105280e-02  2.48073991e-02  1.99343208e-02  3.48216183e-02  3.10467370e-02  4.85268384e-02 -1.48683321e-02 -1.44339688e-02 -1.83274597e-02 -2.25209910e-02 -4.66139577e-02  8.46805871e-02  5.55498600e-02 -4.86311466e-02  8.04354995e-02  5.78265125e-03 -3.33314948e-02  1.41728045e-02  7.46281222e-02  1.23108663e-02  1.29789282e-02  2.50214320e-02 -1.73974875e-02 -2.06596926e-02 -8.00771266e-03 -4.48289625e-02  3.21343057e-02  2.96824127e-02 -2.19148956e-02 -8.40266049e-02  2.08409578e-02 -5.84821552e-02  9.26640071e-03 -7.78274285e-03  3.21653970e-02  1.23768868e-02  1.75757147e-02 -3.77148017e-02 -6.50716200e-02 -2.81811506e-02  6.65956060e-04 -4.59337793e-02 -2.91092098e-02  1.06873184e-01 -9.06297788e-02  5.74022382e-02 -1.92602631e-02 -9.17858677e-04 -1.03564970e-02 -9.53326374e-03 -1.40155749e-02 -5.38532920e-02 -1.45433499e-02 -8.01574625e-03  2.73187216e-02 -1.10087404e-02 -8.70806128e-02 -5.07052056e-02 -1.94765590e-02  3.09801456e-02  5.79237528e-02 -4.61821295e-02 -6.85098171e-02 -1.12160509e-02  1.87328327e-02 -1.87243987e-02  8.43074173e-03  4.05288208e-03 -1.77395716e-03 -4.84117605e-02 -5.69200628e-02  1.21792853e-01 -8.72146338e-05  7.16463253e-02 -7.18049286e-03  1.85641591e-02  1.04164807e-02  2.23379545e-02 -2.17134301e-02  6.76098093e-02 -2.82478407e-02  3.98118485e-04  1.20027447e-02  2.38112584e-02 -3.34599502e-02 -2.01173555e-02 -6.13471568e-02  8.10436439e-03  4.63223346e-02 -7.35998601e-02 -7.45181814e-02  6.75673410e-02  4.85108085e-02  1.16789509e-02 -4.41863127e-02  3.12849879e-04 -3.95977460e-02  1.64179280e-02  7.68655736e-04  2.21294779e-02  1.06583117e-02 -1.15191847e-01 -7.83179179e-02 -9.30088758e-02  2.98546683e-02  1.93161629e-02  4.65247072e-02 -3.15551423e-02  1.53468028e-02 -2.31775502e-03 -3.51057500e-02  6.75020069e-02  3.89646366e-02  2.36660838e-02  8.71817674e-03  2.33443081e-02  6.04395606e-02 -5.73495515e-02 -7.63548985e-02  1.81578603e-02  5.78259937e-02  3.85002531e-02 -9.10978578e-03  6.28609152e-04  4.22109812e-02  2.34038550e-02 -4.32434771e-03  5.22437766e-02  2.75171399e-02  1.14117227e-02 -1.94266194e-03  4.50319564e-03  7.96783529e-03 -1.06010869e-01 -7.45600974e-03  4.15139422e-02 -2.61434522e-02 -3.02400477e-02 -3.69867403e-03  5.33738770e-02  1.22662308e-02 -7.78622404e-02 -1.04798714e-03  4.03577797e-02  1.95078198e-02  6.87584048e-03  1.52195273e-02 -2.21762992e-02  3.01569123e-02  4.99859042e-02  1.69460364e-02  2.80374940e-02 -1.22692548e-01 -6.09890744e-02  6.93573654e-02 -4.64934334e-02 -2.55377777e-03  9.13314708e-03  1.88059080e-02 -3.50909606e-02 -3.23721021e-02 -1.99456997e-02 -1.85215636e-03  9.07397363e-03 -1.60663063e-03  6.72434550e-03  1.51269864e-02 -2.88711805e-02  1.87143628e-02  3.21673527e-02  1.10762762e-02  5.36762364e-02  1.00923926e-02 -6.80830050e-03  1.38309216e-02 -1.52337942e-02 -1.88095886e-02  4.73398566e-02  1.07036727e-02 -1.34082846e-02  2.46402621e-02  4.00331616e-03 -3.54318060e-02 -3.82929370e-02  5.72114717e-03 -3.37869078e-02  9.22745746e-03 -2.55183261e-02 -6.68449188e-03 -2.95727719e-02 -5.30545451e-02 -1.42496992e-02  1.21139064e-01  5.80232916e-03  6.85878769e-02  3.29775847e-02 -3.54181491e-02  1.07272621e-02 -4.35234942e-02 -3.61797120e-03  4.35319096e-02 -7.25895017e-02  2.31458414e-02 -6.59776181e-02 -9.39039700e-03 -5.54487482e-02 -2.98391879e-02  3.77000533e-02 -4.21746895e-02 -6.79707155e-05 -4.04625982e-02  2.20605936e-02 -2.00542212e-02 -3.81324701e-02 -5.30191511e-02 -6.33813813e-02 -5.16399965e-02  9.64144524e-03  5.90449497e-02 -4.24992219e-02  1.87409557e-02  1.59757817e-03  2.12688763e-02  1.16855623e-02  8.13119933e-02 -3.76809179e-03 -4.92693763e-03  3.39190066e-02  7.72952859e-04  4.17263247e-02 -8.17925707e-02  6.20350353e-02 -1.06017468e-02  4.36364748e-02  1.06892204e-02  4.46716622e-02 -1.07703032e-03 -5.20897424e-03  4.62425686e-02 -1.77654065e-02 -4.77417782e-02 -7.94410184e-02 -3.87781188e-02  3.52257639e-02  8.99284892e-03 -4.21371032e-03 -6.33117780e-02  4.79902467e-03 -2.65776385e-02  6.36078864e-02 -2.88559869e-02 -1.88005026e-02 -6.77149072e-02 -1.77993905e-02 -1.74105745e-02  1.92977523e-03 -4.24707830e-02 -3.41327414e-02 -4.64667156e-02  1.20677715e-02 -5.59292501e-03 -2.15960406e-02  1.65096892e-03  4.98509929e-02  6.74478710e-03 -1.25451041e-02 -3.78884971e-02 -2.44544051e-03  1.05662392e-02 -2.92542093e-02 -2.42053512e-02 -4.72463332e-02 -6.66808896e-03  4.26904894e-02 -1.38995284e-02 -7.33149797e-02 -1.20323701e-02  1.33620957e-02 -6.83322325e-02  5.24532832e-02 -3.99674661e-03 -3.77754751e-03 -4.37322631e-02  3.01865134e-02 -2.41089566e-03 -3.91000248e-02 -7.14202551e-03  1.61565766e-02  2.38034059e-03 -1.91217046e-02 -3.19050848e-02  2.66811196e-02 -3.00042611e-02  6.37865961e-02  9.43038985e-03  9.79864821e-02 -1.36476476e-02 -3.53143290e-02 -1.68743916e-02 -1.17210001e-02 -1.76749416e-02 -2.15478931e-02  6.98762164e-02  6.34187385e-02  3.40041555e-02 -2.52816733e-02 -1.68120004e-02 -3.73728164e-02 -4.34950478e-02 -2.41863336e-02  5.50701953e-02 -3.69273759e-02  2.01697815e-02 -5.65395206e-02 -2.43306421e-02  3.90052013e-02  8.88361968e-03 -7.37517253e-02  1.38345852e-01  9.28618014e-02  1.69148594e-02 -6.06265031e-02 -4.29087738e-03  9.36304405e-03 -6.03743903e-02  6.65058494e-02  9.13580060e-02 -4.83134501e-02 -4.48018834e-02 -2.56855302e-02 -1.47311706e-02 -6.67072907e-02  6.08391464e-02 -1.89301930e-02  5.48280887e-02  5.90014877e-03  5.10426983e-02 -2.76698507e-02  5.75542785e-02  1.65380053e-02  4.50753085e-02 -9.17072967e-02 -2.97022844e-03 -1.58547808e-03  4.13699523e-02 -2.40925550e-02 -8.28880146e-02 -4.60402220e-02 -2.80448776e-02  8.56529176e-02  1.21937310e-02 -1.45478994e-02  2.00680923e-03  5.76159284e-02 -8.33749920e-02 -8.44795082e-04  1.61427092e-02  1.06292889e-02  4.48290072e-02  3.78188565e-02  3.22153270e-02  7.65506970e-03  8.83217156e-02  1.07656186e-03 -4.78400923e-02 -1.30352927e-02  2.12222282e-02  4.37513888e-02 -6.99853227e-02 -2.67156325e-02 -5.85299730e-03 -6.67774230e-02 -4.67196293e-02  4.51602452e-02  5.02196476e-02  7.23657906e-02 -3.45671624e-02  1.77986156e-02  6.36029616e-02  6.04263172e-02 -2.88534202e-02  7.63596641e-03  8.91817287e-02 -1.73596032e-02 -1.14401756e-03 -3.49274017e-02 -3.11373584e-02 -1.08088255e-02  6.22482738e-03  6.60343748e-03 -1.39189782e-02 -1.58823899e-03  3.98824885e-02 -1.50108114e-02  2.18414310e-02  2.50639417e-03 -2.71914285e-02  1.23682460e-02 -1.60910413e-02 -5.62604703e-02  3.08268126e-02 -4.40148003e-02  6.95617199e-02 -3.85880619e-02 -1.06069623e-02  6.90155923e-02 -2.68800631e-02 -7.05972910e-02 -8.45417567e-03 -2.90030837e-02  3.72898579e-02 -1.82219949e-02]Sentence: 今天天气非常不错Embedding: [ 0.03000144 -0.09463879 -0.00121101  0.00919701  0.09230766  0.05803198 -0.06870171  0.08796345  0.05131664  0.05268763  0.06015535 -0.01480623  0.01694882  0.02787215 -0.02760382 -0.01491595  0.04491248  0.07975394 -0.01115547 -0.0462878  -0.04860514  0.01397826  0.02661177  0.05335874  0.0504394  -0.03782453  0.00266618 -0.00529313 -0.06329554  0.00695427 -0.01284165  0.01447636 -0.07145751 -0.08993939  0.03178086 -0.06282265 -0.04155265  0.04588643  0.03874922  0.03362899 -0.00353874  0.01936172 -0.00900048  0.02823229 -0.09740815  0.03750192  0.03347944  0.02718792  0.00610443  0.00467336  0.03310893 -0.03908279 -0.0221571  -0.09013501  0.01532278 -0.05820091  0.00157651 -0.09490337  0.0537669  -0.00431305  0.04847043 -0.03206552 -0.026307   -0.01593183 -0.04248736 -0.04010082 -0.01602365 -0.02053563 -0.03909144  0.03412447  0.03093878  0.00616256  0.0216082  -0.06444417  0.080314    0.02742311 -0.06018759  0.02321919 -0.05734614 -0.06155207  0.04174984 -0.10371719  0.03880399 -0.01905175 -0.0258333   0.03389469  0.00468696  0.0387875  -0.00673322  0.00383488 -0.01235164 -0.03161037 -0.02153032  0.00984649  0.01701394  0.0436353 -0.01779626 -0.02531954 -0.04274719  0.04862759 -0.05897103  0.00572619 -0.03335102 -0.01182074  0.02701874 -0.01848033 -0.02704814  0.01843894  0.06236629  0.04626593 -0.03967442  0.06011495  0.01706262 -0.07964841  0.04118946 -0.066379    0.09199478  0.04699905  0.12130994  0.01098934 -0.02470355 -0.06073544  0.0464027   0.00273122 -0.03935859  0.02141794 -0.0184507   0.03051549 -0.00163435 -0.05913333  0.00292336 -0.07933108  0.03902374 -0.06467438 -0.0390107  -0.03507318 -0.07895196 -0.05337577 -0.09487265  0.04261077 -0.04158578 -0.0317761  -0.11317404  0.01106471 -0.05172293  0.03777007  0.00772178  0.11905682  0.01442179 -0.02014892 -0.01100211 -0.03005649 -0.04160342 -0.05648704  0.01849159 -0.05435764 -0.0839037  -0.05800341  0.02173088  0.00356943  0.05853926  0.1246719  0.02843452  0.08176696  0.0147953  -0.00317226  0.04797639 -0.00291128 -0.09280773  0.02252468 -0.05960978  0.12289534 -0.03065114  0.06989978  0.04467983  0.07636563  0.01817677 -0.00636483 -0.01898711  0.01658535  0.00860319  0.0283874  -0.05914772 -0.0190354   0.02753133 -0.05427081 -0.04155286 -0.00551601  0.01740319 -0.0476647  -0.04968425  0.04580819  0.0008345  -0.0295907  -0.03722452  0.01759684 -0.01680085 -0.00452731 -0.03103271  0.01715709 -0.02973793 -0.09613879  0.0051401  -0.05134783  0.05475045 -0.01283471  0.06491576  0.00521481 -0.02848241 -0.01567771 -0.02928415  0.06885134  0.00134412  0.02393162  0.02902504 -0.00551864  0.05685154  0.01001529 -0.00151077  0.03115507  0.06638921 -0.03961314 -0.00163929 -0.01343718  0.0455446   0.09824838 -0.0037222  -0.01031751  0.01817146 -0.00964774 -0.03243448  0.03805481  0.05487118 -0.1405063  0.02105236  0.07209678 -0.01056682  0.05282811  0.02630474  0.0514919  0.00152254 -0.02837622 -0.0032705  -0.00885593 -0.00931489  0.00091267 -0.02325741  0.03074451  0.01638401  0.07488494 -0.03075658  0.04077358  0.0087177  -0.03887089  0.00657461 -0.09632066  0.05145807  0.04517055  0.00689592  0.00326369 -0.0305842  -0.03148292 -0.01074421  0.01959825  0.06533831  0.01840545  0.05983892  0.02591163  0.04609231 -0.00414881  0.03466849 -0.03956919 -0.0252759   0.02703837 -0.05049418  0.00642855 -0.0466234   0.01452899  0.0411245   0.03267844  0.05253888  0.04270734  0.02421789 -0.02808435  0.03788607 -0.03368303  0.04734772 -0.02120586 -0.00403468  0.05083772 -0.03158763  0.00812041  0.14702259  0.05909027  0.06059919  0.04371373  0.05749655 -0.07144133 -0.007153    0.03108226 -0.00512128 -0.04756605 -0.01369407 -0.03663335 -0.02603604 -0.08464614 -0.00882994  0.05349972  0.00743798  0.0450788  -0.00615429 -0.01372156 -0.06049759 -0.00165892  0.00751451 -0.03650769 -0.05391942  0.03810795  0.01484829  0.00219441  0.02152888  0.02753042  0.06430887 -0.03992795  0.04222113 -0.01056078 -0.01716618  0.04329282  0.00051106 -0.00328042  0.00308413  0.04196681 -0.04609387 -0.04296339  0.03102    -0.03701093  0.062396   -0.06226721  0.00538336  0.0229238   0.02155858 -0.07839612  0.04539885  0.03251994 -0.00489039 -0.0397178  -0.00333692  0.00905649 -0.03641601  0.022086    0.01367772  0.00159605 -0.04355391  0.020589 -0.02687901 -0.03018762 -0.0402398  -0.0284971  -0.06481498 -0.02857979  0.02540303 -0.04830561 -0.04924891  0.08158892  0.02544646  0.01573535 -0.05373577 -0.00390225 -0.01128703 -0.00576774 -0.00892009  0.02994281 -0.02264063  0.02417267  0.05122236 -0.02454749  0.00509644 -0.01798263 -0.0216634   0.01950723 -0.08260044 -0.0616743  -0.06187451  0.03843369  0.02321616 -0.01540206  0.01407583 -0.00955944  0.00272941 -0.0103933 -0.01213074 -0.04850604 -0.03309135  0.05800785 -0.01818478  0.02047308  0.01977739  0.01210918 -0.01445558  0.0328787   0.0352786  -0.02208976 -0.02544963  0.05974025 -0.01183659  0.03732854  0.01193697 -0.03702984  0.02314256 -0.03182907 -0.02021193 -0.0746211  -0.01611404  0.01401942 -0.0582074   0.07607199 -0.02163705 -0.05099812  0.08846287  0.06345282  0.01632329  0.03178183  0.0316623   0.02768641 -0.00532748  0.02762542  0.03190726 -0.03167602 -0.06070093  0.06393433  0.04011519 -0.01285412  0.09149878 -0.03832356  0.01962792 -0.05850937 -0.03222102 -0.01088148  0.04417709 -0.05408356  0.00285973  0.01822237  0.05348348 -0.01791644  0.07268931 -0.04405991 -0.02393987 -0.03948317  0.00895625  0.02411424 -0.0503852  -0.04026405 -0.00080167  0.04002957 -0.02202688 -0.04564584  0.00108072 -0.01706082  0.02669973  0.03271101  0.02675862  0.06614731  0.09970568  0.03362572 -0.00678587  0.01031069  0.055266   -0.00729807 -0.04342917 -0.02459758  0.008681    0.03958506 -0.04298421  0.01152243  0.00646575  0.02900903 -0.02682752 -0.03343278 -0.03024075  0.00380493  0.0342885  -0.02285297  0.05209821 -0.00173273 -0.03453593 -0.02917043 -0.00853625  0.01347628 -0.06093422 -0.02397925 -0.02997962 -0.03431647  0.00035183 -0.00620178  0.00593462  0.01080737  0.01387101 -0.04454185 -0.01523613 -0.03633243  0.01572521 -0.04612231  0.08674803 -0.01647091  0.02339503 -0.01340232  0.00376191 -0.06117163  0.01253373 -0.03407933  0.00644007  0.01499923]</code></pre>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> transformer </tag>
            
            <tag> BERT </tag>
            
            <tag> SentenceTransfomer </tag>
            
            <tag> embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What is Web3? Its relationship with Web1, Web2 and metaverse</title>
      <link href="2022/03/20/2022-03-20-1/"/>
      <url>2022/03/20/2022-03-20-1/</url>
      
        <content type="html"><![CDATA[<p>The Internet has so far been in two phases: Web 1.0 and Web 2.0.</p><p>The next phase, naturally, is Web 3.0 (Web3 for short). This article talks about some of the basic understanding of Web3 and what it is.<br><img src="/content/images/2022-03-20-1.jpg" alt="png"></p><h2 id="1-Historical-review"><a href="#1-Historical-review" class="headerlink" title="1. Historical review"></a>1. Historical review</h2><p>In the Web 1.0 stage, users are pure content consumers, and the content is provided by the website. You can watch whatever the website lets you watch. A typical example is a news portal.<br><img src="/content/images/2022-03-20-2.jpg" alt="png"></p><p>In the Web 2.0 stage, users are the producers of content, and a website is just a platform that provides services to users. Typical Web 2.0 platforms include Wikipedia, Douyin, WeChat, and so on.<br><img src="/content/images/2022-03-20-3.jpg" alt="png"></p><h2 id="2-Characteristics-of-Web3"><a href="#2-Characteristics-of-Web3" class="headerlink" title="2. Characteristics of Web3"></a>2. Characteristics of Web3</h2><p>Many features of Web3 are still unclear, but many experts believe that it is related to the blockchain.<br>Simply speaking, Web 1.0 is users reading the Internet, Web 2.0 is users writing to the Internet, and Web3 is users living on the Internet.</p><p>Entertainment, work, study, consumption, and communication all take place online. A website is not just a service, it is a living space where part of people’s lives can be done online.</p><p>Study on educational sites, meet on conference sites, make friends on social networking sites, and have fun on gaming sites. All websites together form an all-encompassing online world.</p><h2 id="3-Virtual-world"><a href="#3-Virtual-world" class="headerlink" title="3. Virtual world"></a>3. Virtual world</h2><p>All the life functions of a website, if they can be linked together to allow users to move from one scene to another seamlessly, constitute a virtual world. This is probably what the recently popular metaverse looks like.</p><p>At that stage, users no longer visit the website, but enter the virtual world and live a virtual online life.</p><h2 id="4-Web3-is-distributed"><a href="#4-Web3-is-distributed" class="headerlink" title="4. Web3 is distributed"></a>4. Web3 is distributed</h2><p>Such a virtual world obviously cannot be monopolized by one or several giants, otherwise we will rely on these giants and have to abide by the rules set by them. When your life is in the virtual world, one day the giant suddenly decides to close your account, your virtual life will come to an abrupt end!</p><p>This is why many people have proposed that Web3 should be distributed. This has two meanings:</p><p>(1) It is not centralized, so no single company can control it;</p><p>(2) There are multiple providers for any kind of service, which are connected by distributed protocols, and users can transfer from one provider to another service provider with minimal cost.</p><h2 id="5-The-role-of-blockchain"><a href="#5-The-role-of-blockchain" class="headerlink" title="5. The role of blockchain"></a>5. The role of blockchain</h2><p>If Web3 is determined to be distributed, then blockchain is simply natural infrastructure. Because the blockchain is an implementation of a distributed database, it is distributed in itself, and once the information is on the chain, it cannot be modified.</p><p>This solves the core problem of Web3: data exchange between different websites. Different websites can freely read and write the same user’s data, and these data can be trusted, thus ensuring that users entering another website are like entering different regions of the same world.</p><p>Once Web3 is built on the blockchain, according to the design of the blockchain, users need to have a digital wallet, which is your ID card and bank account in the virtual world. Your identity, property, and consumption are all identified through this digital wallet. Websites identify who you are by the ID of your digital wallet.</p><p>On the other hand, with digital wallets, banking and finance become virtual, which makes the virtual world more like the real world.</p><h2 id="6-Digital-Assets"><a href="#6-Digital-Assets" class="headerlink" title="6. Digital Assets"></a>6. Digital Assets</h2><p>The blockchain allows arbitrary data to be written, so inevitably, all digital records of our virtual lives can be placed on the blockchain.</p><p>If each virtual item has its own number and records them in the blockchain, their owner (ie, linked to a digital wallet) can be determined.</p><p>For example, each digital picture in the virtual world can have a unique number on the blockchain, which will not be confused with other pictures, and the owner of each picture can be determined by linking to a digital wallet.</p><p>We could also trade the picture, register it to another digital wallet, and make its owner someone else. Now the very popular NFT is doing this, but it is not simply a picture registered on the blockchain, but a digital collectible.</p><p>Entrepreneur Chris Dixon recently said publicly: “Web3 is ownership”, which is exactly what he means.</p><p>If everyone, all items, and all transactions are registered on the blockchain, the Web3 based on it is simply endless and unimaginable now. The possibility of the virtual world is 100 times, 1000 times more than the real world.</p><p>At present, it is only the initial stage of Web3, the infrastructure has not been completed, and the gameplay is still being explored, but the progress is very fast. Countless innovations and opportunities should emerge in this area, which deserves close attention. </p>]]></content>
      
      
      <categories>
          
          <category> Metaverse </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Good use of regular expression, remove spaces between punctuation and words, normalize texts automatically</title>
      <link href="2022/03/19/2022-03-19-1/"/>
      <url>2022/03/19/2022-03-19-1/</url>
      
        <content type="html"><![CDATA[<p>Regular expression (shortened as regex) is very powerful way to improve efficiency and change formats for us.<br>Here are example how we can leverage grouping in regrex, and remove extra spaces between punctuation and chaters in fron of it.<br>Thus we can normalize format errors in texts automatically.</p><h2 id="Engish-sentence-example，remove-spaces-between-punctuation-and-words"><a href="#Engish-sentence-example，remove-spaces-between-punctuation-and-words" class="headerlink" title="Engish sentence example，remove spaces between punctuation and words"></a>Engish sentence example，remove spaces between punctuation and words</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">sent = <span class="string">&quot;What a wonderful day ,I want to go out and have a walk   !&quot;</span></span><br><span class="line">sent=re.sub(<span class="string">r&#x27;\s+([?,.!;&quot;])&#x27;</span>, <span class="string">r&#x27;\1&#x27;</span>, sent)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sent)</span><br></pre></td></tr></table></figure><pre><code>What a wonderful day,I want to go out and have a walk!</code></pre><p>In the above regrex rule definition: r’\s+([?,.!;”])’, the parentheses define a group (the first group), the square brackets in the group represent all the punctuation marks we need to distinguish by regex, and \s+ represents multiple spaces. So the whole rules means we replace the format of spaces + group with group only, so it automatically removes any extra spaces before the punctuations.</p><h2 id="Chinese-sentence-example，remove-spaces-between-punctuation-and-words"><a href="#Chinese-sentence-example，remove-spaces-between-punctuation-and-words" class="headerlink" title="Chinese sentence example，remove spaces between punctuation and words"></a>Chinese sentence example，remove spaces between punctuation and words</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">sent = <span class="string">&quot;天气真好   ! 我要出去散步 。&quot;</span></span><br><span class="line">sent=re.sub(<span class="string">r&#x27;\s+([?,.!;&quot;。，])&#x27;</span>, <span class="string">r&#x27;\1&#x27;</span>, sent)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sent)</span><br></pre></td></tr></table></figure><pre><code>天气真好! 我要出去散步。</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> regex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ten important Python libraries that Data Scientist must know</title>
      <link href="2022/03/13/2022-03-12-%201/"/>
      <url>2022/03/13/2022-03-12-%201/</url>
      
        <content type="html"><![CDATA[<p>Good libraries are like useful toolbox, and learning these libraries can make you more productive, whether you’re a novice or a data science expert.</p><p>Below is a basic introduction to some of the most popular Python libraries for data science and machine learning.</p><h2 id="1-Scikit-learn"><a href="#1-Scikit-learn" class="headerlink" title="1. Scikit-learn"></a>1. Scikit-learn</h2><p>This is the most basic and popular Python library for machine learning. In fact, Scikit-learn is the main library for machine learning. It has algorithms and modules for preprocessing, cross-validation, and other similar purposes.</p><p>Some of these algorithms involve regression, decision trees, ensemble modeling, and unsupervised learning algorithms such as clustering.</p><p>Project address: <a href="https://github.com/scikit-learn/scikit-learn">https://github.com/scikit-learn/scikit-learn</a></p><h2 id="2-NumPy"><a href="#2-NumPy" class="headerlink" title="2. NumPy"></a>2. NumPy</h2><p>NumPy is another wonderful Python library for machine learning and heavy computing. NumPy facilitates simple and efficient numerical computation. It has many other libraries built on top of it, such as Pandas.</p><p>You should at least make sure to learn about NumPy arrays, which are fundamental and have many applications in machine learning, data science, and artificial intelligence-based programs.</p><p>Project address: <a href="https://github.com/numpy/numpy">https://github.com/numpy/numpy</a></p><h2 id="3-Pandas"><a href="#3-Pandas" class="headerlink" title="3. Pandas"></a>3. Pandas</h2><p>This is a Python library built on top of NumPy. It is handy in terms of data structures and exploratory analysis. Another important feature it provides is a DataFrame, a two-dimensional data structure with potentially different types of columns.</p><p>Pandas will be one of the most important libraries you will ever need, which is why it is so important to learn Pandas well.</p><p>Project address: <a href="https://github.com/pandas-dev/pandas">https://github.com/pandas-dev/pandas</a></p><h2 id="4-Matplotlib"><a href="#4-Matplotlib" class="headerlink" title="4. Matplotlib"></a>4. Matplotlib</h2><p>If you need to plot, then Matlotlib is an option. It provides a flexible plotting and visualization library, and Matplotlib is powerful. However, it is cumbersome, so, you can choose Seaborn instead.</p><p>Project address: <a href="https://github.com/matplotlib/matplotlib">https://github.com/matplotlib/matplotlib</a></p><h2 id="5-Seaborn"><a href="#5-Seaborn" class="headerlink" title="5. Seaborn"></a>5. Seaborn</h2><p>Like Matplotlib, it’s a great plotting library, but with Seaborn it’s easier than ever to draw common data visualizations.</p><p>It builds on top of Matplotlib and provides a more pleasant high-level wrapper. You should learn effective data visualization.</p><p>Project address: <a href="https://github.com/seaborn">https://github.com/seaborn</a></p><h2 id="6-SciPy"><a href="#6-SciPy" class="headerlink" title="6. SciPy"></a>6. SciPy</h2><p>This is a Python library for scientific and technical computing. It will give you all the tools you need for scientific and technical computing.</p><p>It has modules for optimization, linear algebra, integration, interpolation, special functions, fast Fourier transforms, signal and image processing, independent dependency estimation solvers, and other tasks.</p><p>Project address: <a href="https://github.com/scipy/scipy">https://github.com/scipy/scipy</a></p><h2 id="7-OpenCV"><a href="#7-OpenCV" class="headerlink" title="7. OpenCV"></a>7. OpenCV</h2><p>This is another great library for Python developers in computer vision. In case you didn’t know, computer vision is one of the most exciting fields in machine learning and artificial intelligence.</p><p>It has applications in many industries such as self-driving cars, robotics, augmented reality, etc., and OpenCV is the best computer vision library.</p><p>Although you can use OpenCV in many programming languages ​​like C++, its Python version is beginner friendly and easy to use, which makes it a great library to be included in this list.</p><p>If you want to learn Python and OpenCV for basic image processing, and do image classification and object detection, and need a course, then I highly recommend taking a hands-on course that will teach you an OpenCV through several labs and exercises.</p><p>Project address: <a href="https://github.com/opencv/opencv">https://github.com/opencv/opencv</a></p><h2 id="8-TensorFlow"><a href="#8-TensorFlow" class="headerlink" title="8. TensorFlow"></a>8. TensorFlow</h2><p>This is one of the most popular machine learning libraries, and chances are you’ve already heard of it. You probably know TensorFlow from Google, invented by their Google Brain team, and used in the RankBrain algorithm that powers millions of search questions on Google’s search engine.</p><p>In general, it is a symbolic math library that is also used in machine learning applications such as neural networks. TensorFlow has many applications, and you can find many stories online, such as how a Japanese farmer used TensorFlow to sort cucumbers.</p><p>Project address: <a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a></p><h2 id="9-PyTorch"><a href="#9-PyTorch" class="headerlink" title="9. PyTorch"></a>9. PyTorch</h2><p>This is another exciting and powerful Python library for data science and machine learning, something every data scientist should learn.</p><p>In case you didn’t know, PyTorch is one of the best deep learning libraries developed by Facebook for deep learning applications such as face recognition self-driving cars and more.</p><p>You can also use PyTorch to build machine learning models like NLP and computer vision, to name a few. You can also use PyTorch to create deep neural networks.</p><p>Project address: <a href="https://github.com/pytorch/pytorch">https://github.com/pytorch/pytorch</a></p><h2 id="10-Keras"><a href="#10-Keras" class="headerlink" title="10. Keras"></a>10. Keras</h2><p>One of the main problems with creating machine learning and deep learning-based solutions is that implementing them can be tedious, requiring many lines of complex code. Keras is a library that makes it easier for you to create these deep learning solutions.</p><p>With just a few lines of code, you can create a model that may require hundreds of lines of traditional code.</p><p>Project address: <a href="https://github.com/keras-team/keras">https://github.com/keras-team/keras</a> </p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convert arbitrary date to the date of  Monday or Sundy within the same week in Python</title>
      <link href="2022/02/22/2022-02-22-%201/"/>
      <url>2022/02/22/2022-02-22-%201/</url>
      
        <content type="html"><![CDATA[<p>It is common practice to convert date to the week number for normalization or feature preprocessing. While this is pretty useful, sometimes we want to compare the week number in a more strict fashion, such that we can order week 50 of last year and week 2 of this year, for example.</p><p>Following code shows both<br>(1） how to get week number of datetime object<br>(2) get the exacte date of the Monday or Sunday within the same week</p><h2 id="get-week-number-for-any-date"><a href="#get-week-number-for-any-date" class="headerlink" title="get week number for any date"></a>get week number for any date</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta, datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># example of a date str</span></span><br><span class="line">dt_str = <span class="string">&#x27;2022/02/22 05:23:20&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># convert string to datetime object</span></span><br><span class="line">dt_obj = datetime.strptime(dt_str, <span class="string">&#x27;%Y/%m/%d %H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get date of that Monday </span></span><br><span class="line">year, week_num, day_of_week = dt_obj.isocalendar()</span><br><span class="line"><span class="built_in">print</span>(week_num)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>8</code></pre><h2 id="get-date-of-Monday-or-Sunday-for-any-date-within-the-same-week"><a href="#get-date-of-Monday-or-Sunday-for-any-date-within-the-same-week" class="headerlink" title="get date of Monday or Sunday for any date within the same week"></a>get date of Monday or Sunday for any date within the same week</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta, datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the date of Monday for that week</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_date_of_week</span>(<span class="params">date</span>):</span></span><br><span class="line">    start = date - timedelta(days=date.weekday())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(start)[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the date of Sunday for that week</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">end_date_of_week</span>(<span class="params">date</span>):</span></span><br><span class="line">    start = date - timedelta(days=date.weekday())</span><br><span class="line">    end = start + timedelta(days=<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(end)[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># example of a date str</span></span><br><span class="line">dt_str = <span class="string">&#x27;2022/02/22 05:23:20&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># convert string to datetime object</span></span><br><span class="line">dt_obj = datetime.strptime(dt_str, <span class="string">&#x27;%Y/%m/%d %H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get date of that Monday </span></span><br><span class="line"><span class="built_in">print</span>(start_date_of_week(dt_obj) )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get date of that Sunday </span></span><br><span class="line"><span class="built_in">print</span>(end_date_of_week(dt_obj) )</span><br></pre></td></tr></table></figure><pre><code>2022-02-212022-02-27</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A transformer example to maintain same feature order and add missing features back for feature engineering</title>
      <link href="2022/01/27/2022-01-27-1/"/>
      <url>2022/01/27/2022-01-27-1/</url>
      
        <content type="html"><![CDATA[<p>For data science projects, one important steps in feature engineering is to make sure the order of feature columns during training<br>and prediction/test time is the same. Otherwise, we will not get the results as we expect.</p><p>This is usually not a problem in train/test split or cross validation stages, where training and test data are generally split form the<br>same dataframe. However, once model is put online, and the transformer need to handel each single event, which usually comes in the<br>format of json data, then transformed to dataframe. During this process, the orignal order may not hold.</p><p>To ensure the same feature order is used, we could build a transformer for the pipeline; During the fit stage, the orignal order will be<br>remembered, and during the transform stage, the same order will be enforced; Meanwhile, if there is any missing column, we will add a null value<br>column. </p><h2 id="set-up-some-example-dataframe"><a href="#set-up-some-example-dataframe" class="headerlink" title="set up some example dataframe"></a>set up some example dataframe</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># training example, where we have 3 features</span></span><br><span class="line">df_train = pd.DataFrame(data=[[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>],[<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>]])</span><br><span class="line">df_train.columns =  [<span class="string">&#x27;cat1&#x27;</span>,<span class="string">&#x27;cat2&#x27;</span>,<span class="string">&#x27;cat3&#x27;</span>]</span><br><span class="line">display(df_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test example where we missing the 3rd feature</span></span><br><span class="line">df_test = pd.DataFrame(data=[[<span class="string">&#x27;h&#x27;</span>,<span class="string">&#x27;j&#x27;</span>]])</span><br><span class="line">df_test.columns =  [<span class="string">&#x27;cat2&#x27;</span>,<span class="string">&#x27;cat1&#x27;</span>]</span><br><span class="line">display(df_test)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cat1</th>      <th>cat2</th>      <th>cat3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>a</td>      <td>b</td>      <td>f</td>    </tr>    <tr>      <th>1</th>      <td>c</td>      <td>d</td>      <td>e</td>    </tr>  </tbody></table></div><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cat2</th>      <th>cat1</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>h</td>      <td>j</td>    </tr>  </tbody></table></div><h2 id="a-transformer-which-can-be-added-to-a-full-pipeline"><a href="#a-transformer-which-can-be-added-to-a-full-pipeline" class="headerlink" title="a transformer which can be added to a full pipeline"></a>a transformer which can be added to a full pipeline</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">orderMaitain_Transformer</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line"></span><br><span class="line">     <span class="comment"># Class Constructor</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        self.dtype_dict = &#123;&#125; </span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;initialized&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return self</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        </span><br><span class="line">        self.dtype_dict = X.dtypes.apply(<span class="keyword">lambda</span> x: x.name).to_dict()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X_, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line">        <span class="comment">#print(self.dtype_dict)</span></span><br><span class="line">        train_columns = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># add missing column if any</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> self.dtype_dict:</span><br><span class="line">            train_columns.append(col)</span><br><span class="line">            <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> X.columns:</span><br><span class="line">                <span class="comment"># null boolean are treated as False; can also use other strategy as well</span></span><br><span class="line">                <span class="keyword">if</span> self.dtype_dict[col].startswith(<span class="string">&#x27;bool&#x27;</span>):</span><br><span class="line">                    X[col]=<span class="literal">False</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    X[col] = pd.Series(dtype=self.dtype_dict[col])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># apply same order to both training and test</span></span><br><span class="line">        <span class="built_in">print</span>(train_columns)</span><br><span class="line">        X = X[train_columns]  </span><br><span class="line">        <span class="keyword">return</span> X  </span><br><span class="line">    </span><br><span class="line">orderMaitain_transformer = orderMaitain_Transformer()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>initialized</code></pre><h2 id="apply-transfomer-during-training-and-test-stages"><a href="#apply-transfomer-during-training-and-test-stages" class="headerlink" title="apply transfomer during training and test stages"></a>apply transfomer during training and test stages</h2><h3 id="during-training-stage"><a href="#during-training-stage" class="headerlink" title="during training stage"></a>during training stage</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">orderMaitain_transformer.fit_transform(df_train)</span><br></pre></td></tr></table></figure><pre><code>[&#39;cat1&#39;, &#39;cat2&#39;, &#39;cat3&#39;]</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cat1</th>      <th>cat2</th>      <th>cat3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>a</td>      <td>b</td>      <td>f</td>    </tr>    <tr>      <th>1</th>      <td>c</td>      <td>d</td>      <td>e</td>    </tr>  </tbody></table></div><h3 id="during-test-and-prediction-stage"><a href="#during-test-and-prediction-stage" class="headerlink" title="during test and prediction stage"></a>during test and prediction stage</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check that the resuls have an emppty column added, the order is the same as training</span></span><br><span class="line">orderMaitain_transformer.transform(df_test)</span><br></pre></td></tr></table></figure><pre><code>[&#39;cat1&#39;, &#39;cat2&#39;, &#39;cat3&#39;]</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cat1</th>      <th>cat2</th>      <th>cat3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>j</td>      <td>h</td>      <td>NaN</td>    </tr>  </tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pipeline </tag>
            
            <tag> transformer </tag>
            
            <tag> scikit-learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convert short texts to numeric vectors with Character ngram tf-idf vectorizer using scikit learn in Python</title>
      <link href="2022/01/15/2022-01-15-1/"/>
      <url>2022/01/15/2022-01-15-1/</url>
      
        <content type="html"><![CDATA[<p>When apply machine learning algorithms, to handel words or short texts, we usually need to get their numeric embedding vecotors first.<br>Some powerfulmethods including using pre-trained deep learning model such as BERT to more semantic embedding. If computation resource is a limit, or we want to have simpler embedding methods, we could try TF-IDF metrics. </p><p>Here we introduce a very simple way to combine character level n-gram methods and TF-IDF to convert short texts such as a few words to numeric vectors.  Within numeric vectors, we could further apply classification methods such as Gradient Boosted Machine for downstream tasks.</p><p>First, let’s review what’s n-gram:</p><p>Quote some definition from the Wikipedia N-Gram page:</p><p>…an n-gram is a contiguous sequence of n items from a given sequence of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application… An n-gram of size 1 is referred to as a “unigram”; size 2 is a “bigram”; size 3 is a “trigram”. Larger sizes are sometimes referred to by the value of n, e.g., “four-gram”, “five-gram”, and so on.</p><p>The two most common types of N-Grams, by far, are (1) character-level, where the items consist of one or more characters and (2) word-level, where the items consist of one or more words. The size of the item (or token as it’s often called) is defined by n;</p><p>Second, what’s TF-IDF metrics?</p><p>TF-IDF (Term Frequency - Inverse Document Frequency) encoding is an improved way of BOW (bag of words) which is the same as TF. It considers the frequently seen term in various documents to be less of importance.</p><p>TF (Term Frequency): Counts how many term exists in a document<br>IDF (Inverse Document Frequency): Inverse of the number of documents which contains the term</p><p>So TF-IDF is the basically product of TF and IDF metrics.</p><p>It turns out to be very simple to implement character level n-gram TF-IDF encoding of short texts by using scikit-learn package.<br>This means we can easily incorporate the process step in our data process and feature engineering pipeline</p><h2 id="Step-1-Fit-character-n-gram-tf-idf-vectorizer-with-training-data"><a href="#Step-1-Fit-character-n-gram-tf-idf-vectorizer-with-training-data" class="headerlink" title="Step 1 , Fit character n-gram tf idf vectorizer with training data"></a>Step 1 , Fit character n-gram tf idf vectorizer with training data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># using gram of length at 2 for example</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">corpus = [<span class="string">&#x27;great people&#x27;</span>, <span class="string">&#x27;feel happy&#x27;</span>, <span class="string">&#x27;nice work&#x27;</span>,<span class="string">&#x27;warm weather&#x27;</span>]</span><br><span class="line">vectorizer = TfidfVectorizer(analyzer=<span class="string">&#x27;char&#x27;</span>, ngram_range=(<span class="number">2</span>,<span class="number">2</span>)).fit(corpus)</span><br><span class="line"><span class="built_in">print</span>(vectorizer.get_feature_names())</span><br></pre></td></tr></table></figure><pre><code>[&#39; h&#39;, &#39; p&#39;, &#39; w&#39;, &#39;ap&#39;, &#39;ar&#39;, &#39;at&#39;, &#39;ce&#39;, &#39;e &#39;, &#39;ea&#39;, &#39;ee&#39;, &#39;el&#39;, &#39;eo&#39;, &#39;er&#39;, &#39;fe&#39;, &#39;gr&#39;, &#39;ha&#39;, &#39;he&#39;, &#39;ic&#39;, &#39;l &#39;, &#39;le&#39;, &#39;m &#39;, &#39;ni&#39;, &#39;op&#39;, &#39;or&#39;, &#39;pe&#39;, &#39;pl&#39;, &#39;pp&#39;, &#39;py&#39;, &#39;re&#39;, &#39;rk&#39;, &#39;rm&#39;, &#39;t &#39;, &#39;th&#39;, &#39;wa&#39;, &#39;we&#39;, &#39;wo&#39;]</code></pre><h2 id="Step-2-Transform-new-text-to-tf-idf-weighted-vector"><a href="#Step-2-Transform-new-text-to-tf-idf-weighted-vector" class="headerlink" title="Step 2, Transform new text to tf-idf weighted vector"></a>Step 2, Transform new text to tf-idf weighted vector</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">new_text = [<span class="string">&#x27;pineapple milk&#x27;</span>]</span><br><span class="line">tfidf_vector = vectorizer.transform(new_text).toarray()</span><br><span class="line"><span class="built_in">print</span>(tfidf_vector)</span><br></pre></td></tr></table></figure><pre><code>[[0.         0.         0.         0.42176478 0.         0.  0.         0.42176478 0.3325242  0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.42176478 0.         0.         0.         0.  0.         0.42176478 0.42176478 0.         0.         0.  0.         0.         0.         0.         0.         0.        ]]</code></pre>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> text mining </tag>
            
            <tag> natural language processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Use Python to solve Linear Programming optimization problem</title>
      <link href="2021/12/29/2021-12-29-1/"/>
      <url>2021/12/29/2021-12-29-1/</url>
      
        <content type="html"><![CDATA[<p>Let’s first define the standard format of linear programming problem,<br>in which we will minimize the following equation<br>$$<br>    z=CX<br>$$<br>where， C is the vector of coefficients，X is the vector of variables to be optimized.<br>The constraints of this minimization can be written as:<br>$$<br>AX&lt;=B<br>$$<br>where，A and B are both coefficient matrix。</p><p>Let’s see an specific example：<br>$$<br>min , z=10x_1 +15x_2+25x_3<br>\s.t<br>\-1x_1-1x_2-1x_3&lt;=-1000<br>\-1x_1+2x_2-0x_3&lt;=0<br>\0x_1+0x_2-1x_3&lt;=-300<br>\-1x_1&lt;=0<br>\-1x_2&lt;=0<br>\-1x_3&lt;=0<br>$$</p><p>In Python, we could call the linprog function in Scipy package to solove linear programming problem,<br>and here is a simple demo of coding in Python: </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import required libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> linprog</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the inequality constraints matrix</span></span><br><span class="line"><span class="comment"># Note: the inequality constraints must be in the form of &lt;=</span></span><br><span class="line">A = np.array([[-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the inequality constraints vector</span></span><br><span class="line">b = np.array([-<span class="number">1000</span>, <span class="number">0</span>, -<span class="number">300</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the coefficients of the linear objective function vector</span></span><br><span class="line">c = np.array([<span class="number">10</span>, <span class="number">15</span>, <span class="number">25</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solve linear programming problem</span></span><br><span class="line">res = linprog(c, A_ub=A, b_ub=b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Optimal value:&#x27;</span>, <span class="built_in">round</span>(res.fun, ndigits=<span class="number">2</span>),</span><br><span class="line">      <span class="string">&#x27;\nx values:&#x27;</span>, res.x,</span><br><span class="line">      <span class="string">&#x27;\nNumber of iterations performed:&#x27;</span>, res.nit,</span><br><span class="line">      <span class="string">&#x27;\nStatus:&#x27;</span>, res.message)</span><br></pre></td></tr></table></figure><pre><code>Optimal value: 14500.0 x values: [7.0000000e+02 7.1017063e-09 3.0000000e+02] Number of iterations performed: 7 Status: Optimization terminated successfully.</code></pre>]]></content>
      
      
      <categories>
          
          <category> optimization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linear programming </tag>
            
            <tag> optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-class classification using simple deep learning structure in Pytorch with iris dataset</title>
      <link href="2021/12/26/2021-12-26-1/"/>
      <url>2021/12/26/2021-12-26-1/</url>
      
        <content type="html"><![CDATA[<p>As one can see from the following example, it is very easy to apply deep learning structure in Pytorch<br>to perform multi-class classificatoin task. The valuation performance of this iris dataset is almost perfect.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#import matplotlib.pyplot as plt </span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">1121</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;torch._C.Generator at 0x19734b24a70&gt;</code></pre><h2 id="load-iris-dataset-for-training-and-valuation"><a href="#load-iris-dataset-for-training-and-valuation" class="headerlink" title="load iris dataset for training and valuation"></a>load iris dataset for training and valuation</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">Y = iris.target</span><br><span class="line">X=pd.DataFrame(X)</span><br><span class="line">Y=pd.DataFrame(Y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">display(X)</span><br><span class="line">display(Y)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>5.1</td>      <td>3.5</td>      <td>1.4</td>      <td>0.2</td>    </tr>    <tr>      <th>1</th>      <td>4.9</td>      <td>3.0</td>      <td>1.4</td>      <td>0.2</td>    </tr>    <tr>      <th>2</th>      <td>4.7</td>      <td>3.2</td>      <td>1.3</td>      <td>0.2</td>    </tr>    <tr>      <th>3</th>      <td>4.6</td>      <td>3.1</td>      <td>1.5</td>      <td>0.2</td>    </tr>    <tr>      <th>4</th>      <td>5.0</td>      <td>3.6</td>      <td>1.4</td>      <td>0.2</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>145</th>      <td>6.7</td>      <td>3.0</td>      <td>5.2</td>      <td>2.3</td>    </tr>    <tr>      <th>146</th>      <td>6.3</td>      <td>2.5</td>      <td>5.0</td>      <td>1.9</td>    </tr>    <tr>      <th>147</th>      <td>6.5</td>      <td>3.0</td>      <td>5.2</td>      <td>2.0</td>    </tr>    <tr>      <th>148</th>      <td>6.2</td>      <td>3.4</td>      <td>5.4</td>      <td>2.3</td>    </tr>    <tr>      <th>149</th>      <td>5.9</td>      <td>3.0</td>      <td>5.1</td>      <td>1.8</td>    </tr>  </tbody></table><p>150 rows × 4 columns</p></div><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>0</td>    </tr>    <tr>      <th>...</th>      <td>...</td>    </tr>    <tr>      <th>145</th>      <td>2</td>    </tr>    <tr>      <th>146</th>      <td>2</td>    </tr>    <tr>      <th>147</th>      <td>2</td>    </tr>    <tr>      <th>148</th>      <td>2</td>    </tr>    <tr>      <th>149</th>      <td>2</td>    </tr>  </tbody></table><p>150 rows × 1 columns</p></div><h2 id="train-and-valuation-dataset-split"><a href="#train-and-valuation-dataset-split" class="headerlink" title="train and valuation dataset split"></a>train and valuation dataset split</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X=X.values</span><br><span class="line">Y=Y.values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x, x_val, y, y_val = train_test_split(X, Y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.shape, y.shape, x_val.shape, y_val.shape</span><br></pre></td></tr></table></figure><pre><code>((100, 4), (100, 1), (50, 4), (50, 1))</code></pre><h3 id="notice-that-y-needs-to-be-one-dimension-indicating-the-class-type-not-encoded-vectors"><a href="#notice-that-y-needs-to-be-one-dimension-indicating-the-class-type-not-encoded-vectors" class="headerlink" title="notice that: y needs to be one dimension indicating the class type, not encoded vectors"></a>notice that: y needs to be one dimension indicating the class type, not encoded vectors</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_train = x.reshape(-<span class="number">1</span>, x.shape[<span class="number">1</span>]).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_train = y.reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_val = x_val.reshape(-<span class="number">1</span>, x_val.shape[<span class="number">1</span>]).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_val = y_val.reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h2 id="put-data-into-dataloader-so-we-could-train-by-batches-easily"><a href="#put-data-into-dataloader-so-we-could-train-by-batches-easily" class="headerlink" title="put data into dataloader, so we could train by batches easily"></a>put data into dataloader, so we could train by batches easily</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Data</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.x=torch.from_numpy(x_train)</span><br><span class="line">        self.y=torch.from_numpy(y_train).long()</span><br><span class="line">        self.<span class="built_in">len</span>=self.x.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,index</span>):</span>      </span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line">data_set=Data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define batch sizes here </span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">trainloader=DataLoader(dataset=data_set,batch_size=batch_size)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h2 id="build-softmax-classifier"><a href="#build-softmax-classifier" class="headerlink" title="build softmax classifier"></a>build softmax classifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># D_in, dimension of input layer</span></span><br><span class="line"><span class="comment"># H , dimension of hidden layer</span></span><br><span class="line"><span class="comment"># D_out, dimension of output layer</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,D_in,H,D_out</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line">        self.linear1=nn.Linear(D_in,H)</span><br><span class="line">        self.linear2=nn.Linear(H,D_out)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x=torch.sigmoid(self.linear1(x))  </span><br><span class="line">        x=self.linear2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input_dim=<span class="number">4</span>     <span class="comment"># how many features are in the dataset or how many input nodes in the input layer</span></span><br><span class="line">hidden_dim = <span class="number">20</span> <span class="comment"># hidden layer size</span></span><br><span class="line">output_dim=<span class="number">3</span>    <span class="comment"># number of classes</span></span><br><span class="line"><span class="built_in">print</span>(input_dim,hidden_dim,output_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate model</span></span><br><span class="line">model=Net(input_dim,hidden_dim,output_dim)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W:&#x27;</span>,<span class="built_in">list</span>(model.parameters())[<span class="number">0</span>].size())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>,<span class="built_in">list</span>(model.parameters())[<span class="number">1</span>].size())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>4 20 3W: torch.Size([20, 4])b torch.Size([20])</code></pre><h2 id="define-the-optimizer"><a href="#define-the-optimizer" class="headerlink" title="define the optimizer"></a>define the optimizer</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">learning_rate=<span class="number">0.05</span></span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_epochs=<span class="number">1000</span></span><br><span class="line">loss_list=[]</span><br><span class="line"></span><br><span class="line"><span class="comment">#n_epochs</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="keyword">if</span> epoch %<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(epoch)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> trainloader:</span><br><span class="line">      </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#clear gradient </span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment">#make a prediction </span></span><br><span class="line">        z=model(x)</span><br><span class="line">        <span class="comment">#print(z)</span></span><br><span class="line">        <span class="comment"># calculate loss, da Cross Entropy benutzt wird muss ich in den loss Klassen vorhersagen, </span></span><br><span class="line">        <span class="comment"># also Wahrscheinlichkeit pro Klasse. Das mach torch.max(y,1)[1])</span></span><br><span class="line">        loss=criterion(z,y)</span><br><span class="line">        <span class="comment"># calculate gradients of parameters </span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># update parameters </span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        loss_list.append(loss.data)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#print(&#x27;epoch &#123;&#125;, loss &#123;&#125;&#x27;.format(epoch, loss.item()))</span></span><br></pre></td></tr></table></figure><pre><code>0100200300400500600700800900</code></pre><h2 id="check-performance-using-the-valuation-data"><a href="#check-performance-using-the-valuation-data" class="headerlink" title="check performance using the valuation data"></a>check performance using the valuation data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># predict the class and give probablity for each class label</span></span><br><span class="line">x_val = torch.from_numpy(x_val)</span><br><span class="line">z=model(x_val)</span><br><span class="line">display(z)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.1493e+00,  3.6905e+00, -5.0090e-01],        [ 8.6639e+00,  2.5913e+00, -1.1538e+01],        [-7.7513e+00,  4.1365e-01,  7.2997e+00],        [-3.1786e+00,  3.3443e+00, -1.6125e-01],        [-3.0974e+00,  3.8265e+00, -6.9203e-01],        [ 8.4413e+00,  2.6384e+00, -1.1355e+01],        [-1.4718e-02,  4.3311e+00, -4.3462e+00],        [-5.4910e+00,  1.5831e+00,  3.8781e+00],        [-4.7908e+00,  2.2980e+00,  2.5141e+00],        [-1.2132e+00,  4.3453e+00, -3.1134e+00],        [-5.0060e+00,  1.9947e+00,  2.9958e+00],        [ 8.1200e+00,  2.7792e+00, -1.1151e+01],        [ 8.8828e+00,  2.5214e+00, -1.1683e+01],        [ 8.0960e+00,  2.7942e+00, -1.1141e+01],        [ 8.8283e+00,  2.5107e+00, -1.1654e+01],        [-2.5941e+00,  3.7417e+00, -1.1520e+00],        [-7.0112e+00,  6.8188e-01,  6.2887e+00],        [-1.7457e+00,  4.1789e+00, -2.4035e+00],        [-3.3078e+00,  3.3204e+00,  6.4886e-03],        [-7.0187e+00,  6.5605e-01,  6.3214e+00],        [ 7.9682e+00,  2.8094e+00, -1.1046e+01],        [-4.8998e+00,  2.0493e+00,  2.8430e+00],        [ 8.2123e+00,  2.6980e+00, -1.1198e+01],        [-6.9197e+00,  7.3409e-01,  6.1537e+00],        [-5.4359e+00,  2.1912e+00,  3.2544e+00],        [-6.1038e+00,  1.1452e+00,  4.9261e+00],        [-6.9835e+00,  8.1716e-01,  6.1667e+00],        [-6.8937e+00,  7.5489e-01,  6.1001e+00],        [ 8.0317e+00,  2.7680e+00, -1.1061e+01],        [ 7.8392e+00,  2.8607e+00, -1.0952e+01],        [ 9.1619e+00,  2.3973e+00, -1.1890e+01],        [ 9.2721e+00,  2.3691e+00, -1.1973e+01],        [-1.2764e+00,  4.5603e+00, -3.2536e+00],        [ 8.2595e+00,  2.7126e+00, -1.1257e+01],        [ 8.4267e+00,  2.6317e+00, -1.1359e+01],        [-6.1753e+00,  1.1836e+00,  4.9843e+00],        [-1.8449e+00,  4.1870e+00, -2.3373e+00],        [ 8.5922e+00,  2.6133e+00, -1.1488e+01],        [ 8.7905e+00,  2.5362e+00, -1.1630e+01],        [ 9.1236e+00,  2.4451e+00, -1.1888e+01],        [-6.4186e+00,  9.5598e-01,  5.4381e+00],        [-1.9872e+00,  3.8494e+00, -1.8866e+00],        [-2.3989e+00,  4.0929e+00, -1.6734e+00],        [ 9.1132e+00,  2.4113e+00, -1.1844e+01],        [ 8.8116e+00,  2.5441e+00, -1.1646e+01],        [-1.2458e+00,  4.3741e+00, -3.0913e+00],        [-4.9320e+00,  2.3103e+00,  2.6452e+00],        [-5.8854e+00,  1.5035e+00,  4.3829e+00],        [-1.6208e+00,  4.4212e+00, -2.7724e+00],        [-6.7249e+00,  8.5383e-01,  5.8288e+00]], grad_fn=&lt;AddmmBackward&gt;)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># choose the predicted class to be the one with maximum probablity</span></span><br><span class="line">yhat=torch.<span class="built_in">max</span>(z.data,<span class="number">1</span>)</span><br><span class="line">display(yhat)</span><br></pre></td></tr></table></figure><pre><code>torch.return_types.max(values=tensor([3.6905, 8.6639, 7.2997, 3.3443, 3.8265, 8.4413, 4.3311, 3.8781, 2.5141,        4.3453, 2.9958, 8.1200, 8.8828, 8.0960, 8.8283, 3.7417, 6.2887, 4.1789,        3.3204, 6.3214, 7.9682, 2.8430, 8.2123, 6.1537, 3.2544, 4.9261, 6.1667,        6.1001, 8.0317, 7.8392, 9.1619, 9.2721, 4.5603, 8.2595, 8.4267, 4.9843,        4.1870, 8.5922, 8.7905, 9.1236, 5.4381, 3.8494, 4.0929, 9.1132, 8.8116,        4.3741, 2.6452, 4.3829, 4.4212, 5.8288]),indices=tensor([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,        2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2,        1, 2]))</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get the indicies</span></span><br><span class="line">y_pred=yhat.indices.detach().numpy()</span><br><span class="line">display(y_pred)</span><br></pre></td></tr></table></figure><pre><code>array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,       0, 1, 2, 2, 1, 2], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">display(y_val)</span><br></pre></td></tr></table></figure><pre><code>array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,       0, 1, 2, 2, 1, 2])</code></pre><h2 id="check-the-multi-class-confusion-matric"><a href="#check-the-multi-class-confusion-matric" class="headerlink" title="check the multi-class confusion matric"></a>check the multi-class confusion matric</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> multilabel_confusion_matrix</span><br><span class="line">display(multilabel_confusion_matrix(y_val, y_pred))</span><br></pre></td></tr></table></figure><pre><code>array([[[31,  0],        [ 0, 19]],       [[35,  0],        [ 1, 14]],       [[33,  1],        [ 0, 16]]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> multi-class </tag>
            
            <tag> classification </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to auto run python jobs using crontab</title>
      <link href="2021/10/24/2021-10-24-1/"/>
      <url>2021/10/24/2021-10-24-1/</url>
      
        <content type="html"><![CDATA[<p>In ubuntu Linux，many times we need to run certain tasks regularly, such as every 10 minutes, at 2 o’clock in the morning every day, etc.<br>The tasks can be varied, but as data scientists, many of our tasks are based on python code. </p><h2 id="A-simple-python-job"><a href="#A-simple-python-job" class="headerlink" title="A simple python job"></a>A simple python job</h2><p>Suppose we have a very simple python text that needs to be run at 2 AM every day. The python text is named test.py, and the code is as follows: </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a=3</span><br><span class="line">b=5</span><br><span class="line">print(a+b)</span><br></pre></td></tr></table></figure><p>we could write a bash script，run.sh to run the above python job：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">python test.py &gt;&gt; log.txt</span><br></pre></td></tr></table></figure><p>we need to make the run.sh to be excecutable:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod +x run.sh</span><br></pre></td></tr></table></figure><p>We then can run the script，implement the python code，got the answer of a+b and pipeline it to the file log.txt:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./run.sh</span><br></pre></td></tr></table></figure><p>Our job is now to figure out how to run.sh script file automatically。</p><h2 id="Install-crontab"><a href="#Install-crontab" class="headerlink" title="Install crontab"></a>Install crontab</h2><p>If your ubuntu doesn’t have contab</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">install：apt-get install cron</span><br><span class="line">start：service cron start</span><br><span class="line">restart：service cron restart</span><br><span class="line">stop：service cron stop</span><br><span class="line">check status：service cron status</span><br><span class="line">check scheduled jobs：crontab -l</span><br></pre></td></tr></table></figure><h2 id="add-crontab-job"><a href="#add-crontab-job" class="headerlink" title="add crontab job"></a>add crontab job</h2><p>the command is：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure><p>follow the hint and choose the edit environment you like, such as nano or vi.<br>If we want to run the job 2 am every day, the logic is like this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 2 * * * /home/user_name/run.sh</span><br></pre></td></tr></table></figure><p>If we want to run the job every 5 minutes, then rule is this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*/5 * * * * /home/user_name/run.sh</span><br></pre></td></tr></table></figure><p>After save the above work, we have successfully scheduled the jobs.<br>Using the following command,</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">crontab -l</span><br></pre></td></tr></table></figure><p>we could confirm all the scheduled jobs including the one we just put in.</p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> crontab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to serve the Flask app with nginx as the reverse proxy</title>
      <link href="2021/10/01/2021-10-01-1/"/>
      <url>2021/10/01/2021-10-01-1/</url>
      
        <content type="html"><![CDATA[<p>We are going to build a simple and smooth process using the following steps:</p><ol><li><p> if you don’t have uwsgi installed, try this on ubuntu:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip3 install uwsgi</span><br></pre></td></tr></table></figure></li><li><p>locate your flask project folder, if you don’t know how to create a a flask app, check this link:<br><a href="https://datasciencebyexample.com/2021/09/29/2021-09-29-1/">flask app creation</a><br><a href="https://datasciencebyexample.com/2021/09/29/2021-09-29-1/">https://datasciencebyexample.com/2021/09/29/2021-09-29-1/</a></p></li><li><p>create a uswgi init file inside your flask project, for example, you can call it myproject.ini</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[uwsgi]</span><br><span class="line">module = main:app</span><br><span class="line"></span><br><span class="line">master = true</span><br><span class="line">processes = 2</span><br><span class="line"></span><br><span class="line">socket = myproject.sock</span><br><span class="line">chmod-socket = 660</span><br><span class="line">vacuum = true</span><br><span class="line"></span><br><span class="line">die-on-term = true</span><br></pre></td></tr></table></figure></li><li><p>Let’s then create the systemd service unit file. Creating a systemd unit file will allow Ubuntu’s init system to automatically start uWSGI and serve the Flask application whenever the server boots.</p></li></ol><p>Create a unit file ending in .service within the /etc/systemd/system directory to begin, for example</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo emacs /etc/systemd/system/myproject.service</span><br></pre></td></tr></table></figure><p>inside the file:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=uWSGI instance to serve myproject</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=&lt;your user name&gt;</span><br><span class="line">Group=www-data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">WorkingDirectory=&lt;your flask app directory&gt;</span><br><span class="line"></span><br><span class="line">ExecStart=/usr/local/bin/uwsgi --ini myproject.ini</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Then type these in the command line:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl start myproject</span><br><span class="line">sudo systemctl enable myproject</span><br></pre></td></tr></table></figure><p>you can check the service status</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl status myproject</span><br></pre></td></tr></table></figure><p>if any changes to the project, just do this to reflect new web app:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service myproject restart</span><br></pre></td></tr></table></figure><ol start="5"><li>install the nginx if you don’t have one<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install nginx</span><br></pre></td></tr></table></figure>At the end of the installation process, Ubuntu (18.04) will start Nginx. The web server should already be up and running.</li></ol><p>We can check with the systemd init system to make sure the service is running by typing:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl status nginx</span><br></pre></td></tr></table></figure><ol start="6"><li><p>Begin by creating a new server block configuration file in Nginx’s sites-available directory. Let’s call this myproject to keep in line with the rest of the guide:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo emacs /etc/nginx/sites-available/myproject</span><br></pre></td></tr></table></figure><p>inside the file:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name englishlearningbyexample.com www.englishlearningbyexample.com;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        include uwsgi_params;</span><br><span class="line">        uwsgi_pass unix:&lt;your flask app dir&gt;/myproject.sock;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>above I was using<br><a href="http://www.englishlearningbyexample.com/">www.englishlearningbyexample.com</a><br>as the example for server_name, but you should replace with yours.</p></li><li><p>final steps</p></li></ol><p>To enable the Nginx server block configuration you’ve just created, link the file to the sites-enabled directory:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ln -s /etc/nginx/sites-available/myproject /etc/nginx/sites-enabled</span><br></pre></td></tr></table></figure><p>then do </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart nginx</span><br></pre></td></tr></table></figure><p>now you should see the website running</p><p>If you encounter any errors, trying checking the following:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo less /var/log/nginx/error.log: checks the Nginx error logs.</span><br><span class="line">sudo less /var/log/nginx/access.log: checks the Nginx access logs.</span><br><span class="line">sudo journalctl -u nginx: checks the Nginx process logs.</span><br><span class="line">sudo journalctl -u myproject: checks your Flask app’s uWSGI logs.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flask app </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Set up Flask app to implement GET and POST API</title>
      <link href="2021/09/29/2021-09-29-1/"/>
      <url>2021/09/29/2021-09-29-1/</url>
      
        <content type="html"><![CDATA[<p>Flask app is one of the easiest ways to setup APIs on the server side for data engineering and data science purpose.<br>Here we show an simple set up process, an example python file, and how to run it in an development environment.</p><h2 id="packages-to-install"><a href="#packages-to-install" class="headerlink" title="packages to install"></a>packages to install</h2><p>assume we are using python3 environment</p><ol><li>install flask</li></ol><p>sudo apt install python3-flask</p><ol start="2"><li>to allow Cross-Origin Resource Sharing</li></ol><p>pip3 install flask_cors</p><h2 id="A-simple-example-python-file-main-py-to-setup-flask-GET-and-POST-APIS"><a href="#A-simple-example-python-file-main-py-to-setup-flask-GET-and-POST-APIS" class="headerlink" title="A simple example python file (main.py) to setup flask GET and POST APIS"></a>A simple example python file (main.py) to setup flask GET and POST APIS</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,request</span><br><span class="line"><span class="keyword">from</span> flask_cors <span class="keyword">import</span> CORS</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line">CORS(app)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">helloWorld</span>():</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello, cross-origin-world!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># GET method</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/get&quot;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getexample</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># GET data</span></span><br><span class="line">    query = request.args.get(<span class="string">&quot;query&quot;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(query)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> query</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#post method</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/post&quot;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postexample</span>():</span></span><br><span class="line">    <span class="comment">##  Get POST input form data</span></span><br><span class="line">    <span class="comment">#data = dict((key, request.form.get(key)) for key in request.form.keys())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  Get POST input json data</span></span><br><span class="line">    data = <span class="built_in">dict</span>((key, request.json.get(key)) <span class="keyword">for</span> key <span class="keyword">in</span> request.json.keys())</span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;post request with &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(data))</span><br><span class="line"></span><br><span class="line">    output=&#123;<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> json.dumps(output)</span><br></pre></td></tr></table></figure><h2 id="to-run-the-flask-API-in-the-command-line-to-run-the-following-command"><a href="#to-run-the-flask-API-in-the-command-line-to-run-the-following-command" class="headerlink" title="to run the flask API: in the command line to run the following command"></a>to run the flask API: in the command line to run the following command</h2><p>sudo FLASK_APP=main.py flask run –host=0.0.0.0 –port 3000</p>]]></content>
      
      
      <categories>
          
          <category> data engineering </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flask app </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Prep and Visualization Example using matplotlib in Python</title>
      <link href="2021/08/25/2021-08-25-1/"/>
      <url>2021/08/25/2021-08-25-1/</url>
      
        <content type="html"><![CDATA[<p>Some simple ways to make histogram or line plots using matplotlib.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install the pydataset package. This package gives us data sets to work with very easily</span></span><br><span class="line">! pip install pydataset</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The convention for importing matplotlib with an alias is &quot;plt&quot;. We&#x27;ll also need pandas and numpy</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="The-Air-Passengers-Dataset"><a href="#The-Air-Passengers-Dataset" class="headerlink" title="The Air Passengers Dataset"></a>The Air Passengers Dataset</h2><p>This dataset shows the number of passengers flying United States airlines by month from 1949-1960. </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pydataset <span class="keyword">import</span> data</span><br><span class="line"></span><br><span class="line">passengers = data(<span class="string">&#x27;AirPassengers&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">passengers.head(<span class="number">12</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>time</th>      <th>AirPassengers</th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1949.000000</td>      <td>112</td>    </tr>    <tr>      <th>2</th>      <td>1949.083333</td>      <td>118</td>    </tr>    <tr>      <th>3</th>      <td>1949.166667</td>      <td>132</td>    </tr>    <tr>      <th>4</th>      <td>1949.250000</td>      <td>129</td>    </tr>    <tr>      <th>5</th>      <td>1949.333333</td>      <td>121</td>    </tr>    <tr>      <th>6</th>      <td>1949.416667</td>      <td>135</td>    </tr>    <tr>      <th>7</th>      <td>1949.500000</td>      <td>148</td>    </tr>    <tr>      <th>8</th>      <td>1949.583333</td>      <td>148</td>    </tr>    <tr>      <th>9</th>      <td>1949.666667</td>      <td>136</td>    </tr>    <tr>      <th>10</th>      <td>1949.750000</td>      <td>119</td>    </tr>    <tr>      <th>11</th>      <td>1949.833333</td>      <td>104</td>    </tr>    <tr>      <th>12</th>      <td>1949.916667</td>      <td>118</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1-Add-a-‘year’-column-to-passengers-that-reflects-the-current-year"><a href="#1-Add-a-‘year’-column-to-passengers-that-reflects-the-current-year" class="headerlink" title="#1 Add a ‘year’ column to passengers that reflects the current year"></a>#1 Add a ‘year’ column to passengers that reflects the current year</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">passengers[<span class="string">&#x27;Year&#x27;</span>] = passengers[<span class="string">&#x27;time&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x))</span><br><span class="line">passengers</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>time</th>      <th>AirPassengers</th>      <th>year</th>      <th>month</th>      <th>Year</th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1949.000000</td>      <td>112</td>      <td>1949</td>      <td>1.0</td>      <td>1949</td>    </tr>    <tr>      <th>2</th>      <td>1949.083333</td>      <td>118</td>      <td>1949</td>      <td>2.0</td>      <td>1949</td>    </tr>    <tr>      <th>3</th>      <td>1949.166667</td>      <td>132</td>      <td>1949</td>      <td>3.0</td>      <td>1949</td>    </tr>    <tr>      <th>4</th>      <td>1949.250000</td>      <td>129</td>      <td>1949</td>      <td>4.0</td>      <td>1949</td>    </tr>    <tr>      <th>5</th>      <td>1949.333333</td>      <td>121</td>      <td>1949</td>      <td>5.0</td>      <td>1949</td>    </tr>    <tr>      <th>6</th>      <td>1949.416667</td>      <td>135</td>      <td>1949</td>      <td>6.0</td>      <td>1949</td>    </tr>    <tr>      <th>7</th>      <td>1949.500000</td>      <td>148</td>      <td>1949</td>      <td>7.0</td>      <td>1949</td>    </tr>    <tr>      <th>8</th>      <td>1949.583333</td>      <td>148</td>      <td>1949</td>      <td>8.0</td>      <td>1949</td>    </tr>    <tr>      <th>9</th>      <td>1949.666667</td>      <td>136</td>      <td>1949</td>      <td>9.0</td>      <td>1949</td>    </tr>    <tr>      <th>10</th>      <td>1949.750000</td>      <td>119</td>      <td>1949</td>      <td>10.0</td>      <td>1949</td>    </tr>    <tr>      <th>11</th>      <td>1949.833333</td>      <td>104</td>      <td>1949</td>      <td>11.0</td>      <td>1949</td>    </tr>    <tr>      <th>12</th>      <td>1949.916667</td>      <td>118</td>      <td>1949</td>      <td>12.0</td>      <td>1949</td>    </tr>    <tr>      <th>13</th>      <td>1950.000000</td>      <td>115</td>      <td>1950</td>      <td>1.0</td>      <td>1950</td>    </tr>    <tr>      <th>14</th>      <td>1950.083333</td>      <td>126</td>      <td>1950</td>      <td>2.0</td>      <td>1950</td>    </tr>    <tr>      <th>15</th>      <td>1950.166667</td>      <td>141</td>      <td>1950</td>      <td>3.0</td>      <td>1950</td>    </tr>    <tr>      <th>16</th>      <td>1950.250000</td>      <td>135</td>      <td>1950</td>      <td>4.0</td>      <td>1950</td>    </tr>    <tr>      <th>17</th>      <td>1950.333333</td>      <td>125</td>      <td>1950</td>      <td>5.0</td>      <td>1950</td>    </tr>    <tr>      <th>18</th>      <td>1950.416667</td>      <td>149</td>      <td>1950</td>      <td>6.0</td>      <td>1950</td>    </tr>    <tr>      <th>19</th>      <td>1950.500000</td>      <td>170</td>      <td>1950</td>      <td>7.0</td>      <td>1950</td>    </tr>    <tr>      <th>20</th>      <td>1950.583333</td>      <td>170</td>      <td>1950</td>      <td>8.0</td>      <td>1950</td>    </tr>    <tr>      <th>21</th>      <td>1950.666667</td>      <td>158</td>      <td>1950</td>      <td>9.0</td>      <td>1950</td>    </tr>    <tr>      <th>22</th>      <td>1950.750000</td>      <td>133</td>      <td>1950</td>      <td>10.0</td>      <td>1950</td>    </tr>    <tr>      <th>23</th>      <td>1950.833333</td>      <td>114</td>      <td>1950</td>      <td>11.0</td>      <td>1950</td>    </tr>    <tr>      <th>24</th>      <td>1950.916667</td>      <td>140</td>      <td>1950</td>      <td>12.0</td>      <td>1950</td>    </tr>    <tr>      <th>25</th>      <td>1951.000000</td>      <td>145</td>      <td>1951</td>      <td>1.0</td>      <td>1951</td>    </tr>    <tr>      <th>26</th>      <td>1951.083333</td>      <td>150</td>      <td>1951</td>      <td>2.0</td>      <td>1951</td>    </tr>    <tr>      <th>27</th>      <td>1951.166667</td>      <td>178</td>      <td>1951</td>      <td>3.0</td>      <td>1951</td>    </tr>    <tr>      <th>28</th>      <td>1951.250000</td>      <td>163</td>      <td>1951</td>      <td>4.0</td>      <td>1951</td>    </tr>    <tr>      <th>29</th>      <td>1951.333333</td>      <td>172</td>      <td>1951</td>      <td>5.0</td>      <td>1951</td>    </tr>    <tr>      <th>30</th>      <td>1951.416667</td>      <td>178</td>      <td>1951</td>      <td>6.0</td>      <td>1951</td>    </tr>    <tr>      <th>31</th>      <td>1951.500000</td>      <td>199</td>      <td>1951</td>      <td>7.0</td>      <td>1951</td>    </tr>    <tr>      <th>32</th>      <td>1951.583333</td>      <td>199</td>      <td>1951</td>      <td>8.0</td>      <td>1951</td>    </tr>    <tr>      <th>33</th>      <td>1951.666667</td>      <td>184</td>      <td>1951</td>      <td>9.0</td>      <td>1951</td>    </tr>    <tr>      <th>34</th>      <td>1951.750000</td>      <td>162</td>      <td>1951</td>      <td>10.0</td>      <td>1951</td>    </tr>    <tr>      <th>35</th>      <td>1951.833333</td>      <td>146</td>      <td>1951</td>      <td>11.0</td>      <td>1951</td>    </tr>    <tr>      <th>36</th>      <td>1951.916667</td>      <td>166</td>      <td>1951</td>      <td>12.0</td>      <td>1951</td>    </tr>    <tr>      <th>37</th>      <td>1952.000000</td>      <td>171</td>      <td>1952</td>      <td>1.0</td>      <td>1952</td>    </tr>    <tr>      <th>38</th>      <td>1952.083333</td>      <td>180</td>      <td>1952</td>      <td>2.0</td>      <td>1952</td>    </tr>    <tr>      <th>39</th>      <td>1952.166667</td>      <td>193</td>      <td>1952</td>      <td>3.0</td>      <td>1952</td>    </tr>    <tr>      <th>40</th>      <td>1952.250000</td>      <td>181</td>      <td>1952</td>      <td>4.0</td>      <td>1952</td>    </tr>    <tr>      <th>41</th>      <td>1952.333333</td>      <td>183</td>      <td>1952</td>      <td>5.0</td>      <td>1952</td>    </tr>    <tr>      <th>42</th>      <td>1952.416667</td>      <td>218</td>      <td>1952</td>      <td>6.0</td>      <td>1952</td>    </tr>    <tr>      <th>43</th>      <td>1952.500000</td>      <td>230</td>      <td>1952</td>      <td>7.0</td>      <td>1952</td>    </tr>    <tr>      <th>44</th>      <td>1952.583333</td>      <td>242</td>      <td>1952</td>      <td>8.0</td>      <td>1952</td>    </tr>    <tr>      <th>45</th>      <td>1952.666667</td>      <td>209</td>      <td>1952</td>      <td>9.0</td>      <td>1952</td>    </tr>    <tr>      <th>46</th>      <td>1952.750000</td>      <td>191</td>      <td>1952</td>      <td>10.0</td>      <td>1952</td>    </tr>    <tr>      <th>47</th>      <td>1952.833333</td>      <td>172</td>      <td>1952</td>      <td>11.0</td>      <td>1952</td>    </tr>    <tr>      <th>48</th>      <td>1952.916667</td>      <td>194</td>      <td>1952</td>      <td>12.0</td>      <td>1952</td>    </tr>    <tr>      <th>49</th>      <td>1953.000000</td>      <td>196</td>      <td>1953</td>      <td>1.0</td>      <td>1953</td>    </tr>    <tr>      <th>50</th>      <td>1953.083333</td>      <td>196</td>      <td>1953</td>      <td>2.0</td>      <td>1953</td>    </tr>    <tr>      <th>51</th>      <td>1953.166667</td>      <td>236</td>      <td>1953</td>      <td>3.0</td>      <td>1953</td>    </tr>    <tr>      <th>52</th>      <td>1953.250000</td>      <td>235</td>      <td>1953</td>      <td>4.0</td>      <td>1953</td>    </tr>    <tr>      <th>53</th>      <td>1953.333333</td>      <td>229</td>      <td>1953</td>      <td>5.0</td>      <td>1953</td>    </tr>    <tr>      <th>54</th>      <td>1953.416667</td>      <td>243</td>      <td>1953</td>      <td>6.0</td>      <td>1953</td>    </tr>    <tr>      <th>55</th>      <td>1953.500000</td>      <td>264</td>      <td>1953</td>      <td>7.0</td>      <td>1953</td>    </tr>    <tr>      <th>56</th>      <td>1953.583333</td>      <td>272</td>      <td>1953</td>      <td>8.0</td>      <td>1953</td>    </tr>    <tr>      <th>57</th>      <td>1953.666667</td>      <td>237</td>      <td>1953</td>      <td>9.0</td>      <td>1953</td>    </tr>    <tr>      <th>58</th>      <td>1953.750000</td>      <td>211</td>      <td>1953</td>      <td>10.0</td>      <td>1953</td>    </tr>    <tr>      <th>59</th>      <td>1953.833333</td>      <td>180</td>      <td>1953</td>      <td>11.0</td>      <td>1953</td>    </tr>    <tr>      <th>60</th>      <td>1953.916667</td>      <td>201</td>      <td>1953</td>      <td>12.0</td>      <td>1953</td>    </tr>    <tr>      <th>61</th>      <td>1954.000000</td>      <td>204</td>      <td>1954</td>      <td>1.0</td>      <td>1954</td>    </tr>    <tr>      <th>62</th>      <td>1954.083333</td>      <td>188</td>      <td>1954</td>      <td>2.0</td>      <td>1954</td>    </tr>    <tr>      <th>63</th>      <td>1954.166667</td>      <td>235</td>      <td>1954</td>      <td>3.0</td>      <td>1954</td>    </tr>    <tr>      <th>64</th>      <td>1954.250000</td>      <td>227</td>      <td>1954</td>      <td>4.0</td>      <td>1954</td>    </tr>    <tr>      <th>65</th>      <td>1954.333333</td>      <td>234</td>      <td>1954</td>      <td>5.0</td>      <td>1954</td>    </tr>    <tr>      <th>66</th>      <td>1954.416667</td>      <td>264</td>      <td>1954</td>      <td>6.0</td>      <td>1954</td>    </tr>    <tr>      <th>67</th>      <td>1954.500000</td>      <td>302</td>      <td>1954</td>      <td>7.0</td>      <td>1954</td>    </tr>    <tr>      <th>68</th>      <td>1954.583333</td>      <td>293</td>      <td>1954</td>      <td>8.0</td>      <td>1954</td>    </tr>    <tr>      <th>69</th>      <td>1954.666667</td>      <td>259</td>      <td>1954</td>      <td>9.0</td>      <td>1954</td>    </tr>    <tr>      <th>70</th>      <td>1954.750000</td>      <td>229</td>      <td>1954</td>      <td>10.0</td>      <td>1954</td>    </tr>    <tr>      <th>71</th>      <td>1954.833333</td>      <td>203</td>      <td>1954</td>      <td>11.0</td>      <td>1954</td>    </tr>    <tr>      <th>72</th>      <td>1954.916667</td>      <td>229</td>      <td>1954</td>      <td>12.0</td>      <td>1954</td>    </tr>    <tr>      <th>73</th>      <td>1955.000000</td>      <td>242</td>      <td>1955</td>      <td>1.0</td>      <td>1955</td>    </tr>    <tr>      <th>74</th>      <td>1955.083333</td>      <td>233</td>      <td>1955</td>      <td>2.0</td>      <td>1955</td>    </tr>    <tr>      <th>75</th>      <td>1955.166667</td>      <td>267</td>      <td>1955</td>      <td>3.0</td>      <td>1955</td>    </tr>    <tr>      <th>76</th>      <td>1955.250000</td>      <td>269</td>      <td>1955</td>      <td>4.0</td>      <td>1955</td>    </tr>    <tr>      <th>77</th>      <td>1955.333333</td>      <td>270</td>      <td>1955</td>      <td>5.0</td>      <td>1955</td>    </tr>    <tr>      <th>78</th>      <td>1955.416667</td>      <td>315</td>      <td>1955</td>      <td>6.0</td>      <td>1955</td>    </tr>    <tr>      <th>79</th>      <td>1955.500000</td>      <td>364</td>      <td>1955</td>      <td>7.0</td>      <td>1955</td>    </tr>    <tr>      <th>80</th>      <td>1955.583333</td>      <td>347</td>      <td>1955</td>      <td>8.0</td>      <td>1955</td>    </tr>    <tr>      <th>81</th>      <td>1955.666667</td>      <td>312</td>      <td>1955</td>      <td>9.0</td>      <td>1955</td>    </tr>    <tr>      <th>82</th>      <td>1955.750000</td>      <td>274</td>      <td>1955</td>      <td>10.0</td>      <td>1955</td>    </tr>    <tr>      <th>83</th>      <td>1955.833333</td>      <td>237</td>      <td>1955</td>      <td>11.0</td>      <td>1955</td>    </tr>    <tr>      <th>84</th>      <td>1955.916667</td>      <td>278</td>      <td>1955</td>      <td>12.0</td>      <td>1955</td>    </tr>    <tr>      <th>85</th>      <td>1956.000000</td>      <td>284</td>      <td>1956</td>      <td>1.0</td>      <td>1956</td>    </tr>    <tr>      <th>86</th>      <td>1956.083333</td>      <td>277</td>      <td>1956</td>      <td>2.0</td>      <td>1956</td>    </tr>    <tr>      <th>87</th>      <td>1956.166667</td>      <td>317</td>      <td>1956</td>      <td>3.0</td>      <td>1956</td>    </tr>    <tr>      <th>88</th>      <td>1956.250000</td>      <td>313</td>      <td>1956</td>      <td>4.0</td>      <td>1956</td>    </tr>    <tr>      <th>89</th>      <td>1956.333333</td>      <td>318</td>      <td>1956</td>      <td>5.0</td>      <td>1956</td>    </tr>    <tr>      <th>90</th>      <td>1956.416667</td>      <td>374</td>      <td>1956</td>      <td>6.0</td>      <td>1956</td>    </tr>    <tr>      <th>91</th>      <td>1956.500000</td>      <td>413</td>      <td>1956</td>      <td>7.0</td>      <td>1956</td>    </tr>    <tr>      <th>92</th>      <td>1956.583333</td>      <td>405</td>      <td>1956</td>      <td>8.0</td>      <td>1956</td>    </tr>    <tr>      <th>93</th>      <td>1956.666667</td>      <td>355</td>      <td>1956</td>      <td>9.0</td>      <td>1956</td>    </tr>    <tr>      <th>94</th>      <td>1956.750000</td>      <td>306</td>      <td>1956</td>      <td>10.0</td>      <td>1956</td>    </tr>    <tr>      <th>95</th>      <td>1956.833333</td>      <td>271</td>      <td>1956</td>      <td>11.0</td>      <td>1956</td>    </tr>    <tr>      <th>96</th>      <td>1956.916667</td>      <td>306</td>      <td>1956</td>      <td>12.0</td>      <td>1956</td>    </tr>    <tr>      <th>97</th>      <td>1957.000000</td>      <td>315</td>      <td>1957</td>      <td>1.0</td>      <td>1957</td>    </tr>    <tr>      <th>98</th>      <td>1957.083333</td>      <td>301</td>      <td>1957</td>      <td>2.0</td>      <td>1957</td>    </tr>    <tr>      <th>99</th>      <td>1957.166667</td>      <td>356</td>      <td>1957</td>      <td>3.0</td>      <td>1957</td>    </tr>    <tr>      <th>100</th>      <td>1957.250000</td>      <td>348</td>      <td>1957</td>      <td>4.0</td>      <td>1957</td>    </tr>    <tr>      <th>101</th>      <td>1957.333333</td>      <td>355</td>      <td>1957</td>      <td>5.0</td>      <td>1957</td>    </tr>    <tr>      <th>102</th>      <td>1957.416667</td>      <td>422</td>      <td>1957</td>      <td>6.0</td>      <td>1957</td>    </tr>    <tr>      <th>103</th>      <td>1957.500000</td>      <td>465</td>      <td>1957</td>      <td>7.0</td>      <td>1957</td>    </tr>    <tr>      <th>104</th>      <td>1957.583333</td>      <td>467</td>      <td>1957</td>      <td>8.0</td>      <td>1957</td>    </tr>    <tr>      <th>105</th>      <td>1957.666667</td>      <td>404</td>      <td>1957</td>      <td>9.0</td>      <td>1957</td>    </tr>    <tr>      <th>106</th>      <td>1957.750000</td>      <td>347</td>      <td>1957</td>      <td>10.0</td>      <td>1957</td>    </tr>    <tr>      <th>107</th>      <td>1957.833333</td>      <td>305</td>      <td>1957</td>      <td>11.0</td>      <td>1957</td>    </tr>    <tr>      <th>108</th>      <td>1957.916667</td>      <td>336</td>      <td>1957</td>      <td>12.0</td>      <td>1957</td>    </tr>    <tr>      <th>109</th>      <td>1958.000000</td>      <td>340</td>      <td>1958</td>      <td>1.0</td>      <td>1958</td>    </tr>    <tr>      <th>110</th>      <td>1958.083333</td>      <td>318</td>      <td>1958</td>      <td>2.0</td>      <td>1958</td>    </tr>    <tr>      <th>111</th>      <td>1958.166667</td>      <td>362</td>      <td>1958</td>      <td>3.0</td>      <td>1958</td>    </tr>    <tr>      <th>112</th>      <td>1958.250000</td>      <td>348</td>      <td>1958</td>      <td>4.0</td>      <td>1958</td>    </tr>    <tr>      <th>113</th>      <td>1958.333333</td>      <td>363</td>      <td>1958</td>      <td>5.0</td>      <td>1958</td>    </tr>    <tr>      <th>114</th>      <td>1958.416667</td>      <td>435</td>      <td>1958</td>      <td>6.0</td>      <td>1958</td>    </tr>    <tr>      <th>115</th>      <td>1958.500000</td>      <td>491</td>      <td>1958</td>      <td>7.0</td>      <td>1958</td>    </tr>    <tr>      <th>116</th>      <td>1958.583333</td>      <td>505</td>      <td>1958</td>      <td>8.0</td>      <td>1958</td>    </tr>    <tr>      <th>117</th>      <td>1958.666667</td>      <td>404</td>      <td>1958</td>      <td>9.0</td>      <td>1958</td>    </tr>    <tr>      <th>118</th>      <td>1958.750000</td>      <td>359</td>      <td>1958</td>      <td>10.0</td>      <td>1958</td>    </tr>    <tr>      <th>119</th>      <td>1958.833333</td>      <td>310</td>      <td>1958</td>      <td>11.0</td>      <td>1958</td>    </tr>    <tr>      <th>120</th>      <td>1958.916667</td>      <td>337</td>      <td>1958</td>      <td>12.0</td>      <td>1958</td>    </tr>    <tr>      <th>121</th>      <td>1959.000000</td>      <td>360</td>      <td>1959</td>      <td>1.0</td>      <td>1959</td>    </tr>    <tr>      <th>122</th>      <td>1959.083333</td>      <td>342</td>      <td>1959</td>      <td>2.0</td>      <td>1959</td>    </tr>    <tr>      <th>123</th>      <td>1959.166667</td>      <td>406</td>      <td>1959</td>      <td>3.0</td>      <td>1959</td>    </tr>    <tr>      <th>124</th>      <td>1959.250000</td>      <td>396</td>      <td>1959</td>      <td>4.0</td>      <td>1959</td>    </tr>    <tr>      <th>125</th>      <td>1959.333333</td>      <td>420</td>      <td>1959</td>      <td>5.0</td>      <td>1959</td>    </tr>    <tr>      <th>126</th>      <td>1959.416667</td>      <td>472</td>      <td>1959</td>      <td>6.0</td>      <td>1959</td>    </tr>    <tr>      <th>127</th>      <td>1959.500000</td>      <td>548</td>      <td>1959</td>      <td>7.0</td>      <td>1959</td>    </tr>    <tr>      <th>128</th>      <td>1959.583333</td>      <td>559</td>      <td>1959</td>      <td>8.0</td>      <td>1959</td>    </tr>    <tr>      <th>129</th>      <td>1959.666667</td>      <td>463</td>      <td>1959</td>      <td>9.0</td>      <td>1959</td>    </tr>    <tr>      <th>130</th>      <td>1959.750000</td>      <td>407</td>      <td>1959</td>      <td>10.0</td>      <td>1959</td>    </tr>    <tr>      <th>131</th>      <td>1959.833333</td>      <td>362</td>      <td>1959</td>      <td>11.0</td>      <td>1959</td>    </tr>    <tr>      <th>132</th>      <td>1959.916667</td>      <td>405</td>      <td>1959</td>      <td>12.0</td>      <td>1959</td>    </tr>    <tr>      <th>133</th>      <td>1960.000000</td>      <td>417</td>      <td>1960</td>      <td>1.0</td>      <td>1960</td>    </tr>    <tr>      <th>134</th>      <td>1960.083333</td>      <td>391</td>      <td>1960</td>      <td>2.0</td>      <td>1960</td>    </tr>    <tr>      <th>135</th>      <td>1960.166667</td>      <td>419</td>      <td>1960</td>      <td>3.0</td>      <td>1960</td>    </tr>    <tr>      <th>136</th>      <td>1960.250000</td>      <td>461</td>      <td>1960</td>      <td>4.0</td>      <td>1960</td>    </tr>    <tr>      <th>137</th>      <td>1960.333333</td>      <td>472</td>      <td>1960</td>      <td>5.0</td>      <td>1960</td>    </tr>    <tr>      <th>138</th>      <td>1960.416667</td>      <td>535</td>      <td>1960</td>      <td>6.0</td>      <td>1960</td>    </tr>    <tr>      <th>139</th>      <td>1960.500000</td>      <td>622</td>      <td>1960</td>      <td>7.0</td>      <td>1960</td>    </tr>    <tr>      <th>140</th>      <td>1960.583333</td>      <td>606</td>      <td>1960</td>      <td>8.0</td>      <td>1960</td>    </tr>    <tr>      <th>141</th>      <td>1960.666667</td>      <td>508</td>      <td>1960</td>      <td>9.0</td>      <td>1960</td>    </tr>    <tr>      <th>142</th>      <td>1960.750000</td>      <td>461</td>      <td>1960</td>      <td>10.0</td>      <td>1960</td>    </tr>    <tr>      <th>143</th>      <td>1960.833333</td>      <td>390</td>      <td>1960</td>      <td>11.0</td>      <td>1960</td>    </tr>    <tr>      <th>144</th>      <td>1960.916667</td>      <td>432</td>      <td>1960</td>      <td>12.0</td>      <td>1960</td>    </tr>  </tbody></table></div><h2 id="2-Add-a-“month”-column"><a href="#2-Add-a-“month”-column" class="headerlink" title="#2 Add a “month” column"></a>#2 Add a “month” column</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">passengers[<span class="string">&#x27;month&#x27;</span>] = (passengers[<span class="string">&#x27;time&#x27;</span>] -passengers[<span class="string">&#x27;year&#x27;</span>])*<span class="number">12</span>+<span class="number">1</span></span><br><span class="line">passengers[<span class="string">&#x27;Month&#x27;</span>]= (passengers[<span class="string">&#x27;Year&#x27;</span>]-<span class="built_in">min</span>(passengers[<span class="string">&#x27;Year&#x27;</span>]))*<span class="number">12</span>+passengers[<span class="string">&#x27;month&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="3-Generate-the-plot-below-of-passengers-vs-time-using-each-monthly-count"><a href="#3-Generate-the-plot-below-of-passengers-vs-time-using-each-monthly-count" class="headerlink" title="#3 Generate the plot below of passengers vs. time using each monthly count"></a>#3 Generate the plot below of passengers vs. time using each monthly count</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp=passengers.groupby([<span class="string">&#x27;Month&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[<span class="string">&#x27;Month&#x27;</span>],temp[<span class="string">&#x27;AirPassengers&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&quot;Month&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Hundreds of thousands&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;plot with Matplotlib&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;plot with Matplotlib&#39;)</code></pre><p><img src="/content/images/2021-08-25-output_12_1.png" alt="png"></p><h2 id="4-Generate-the-plot-below-of-passengers-vs-time-using-an-annual-count"><a href="#4-Generate-the-plot-below-of-passengers-vs-time-using-an-annual-count" class="headerlink" title="#4 Generate the plot below of passengers vs. time using an annual count"></a>#4 Generate the plot below of passengers vs. time using an annual count</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp=passengers.groupby([<span class="string">&#x27;Year&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(temp[<span class="string">&#x27;Year&#x27;</span>],temp[<span class="string">&#x27;AirPassengers&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&quot;Year&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Hundreds of thousands&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;plot with Matplotlib&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;plot with Matplotlib&#39;)</code></pre><p><img src="/content/images/2021-08-25-output_14_1.png" alt="png"></p><h2 id="5-Generate-the-barplot-below-of-passengers-by-year"><a href="#5-Generate-the-barplot-below-of-passengers-by-year" class="headerlink" title="#5 Generate the barplot below of passengers by year"></a>#5 Generate the barplot below of passengers by year</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp=passengers.groupby([<span class="string">&#x27;Year&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.bar(temp[<span class="string">&#x27;Year&#x27;</span>],temp[<span class="string">&#x27;AirPassengers&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&quot;Year&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Hundreds of thousands&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">6000</span>])</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;plot with Matplotlib&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;plot with Matplotlib&#39;)</code></pre><p><img src="/content/images/2021-08-25-output_16_1.png" alt="png"></p><h2 id="6-Generate-the-histogram-below-of-monthly-passengers"><a href="#6-Generate-the-histogram-below-of-monthly-passengers" class="headerlink" title="#6 Generate the histogram below of monthly passengers"></a>#6 Generate the histogram below of monthly passengers</h2><p><strong>Additional requirements:</strong></p><ul><li>Only include 1955 and beyond</li><li>Use a binwidth of 50, a min of 200, and a max of 700</li><li>Set the yticks to start at 0, end at 25 by interval of 5</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp=passengers[passengers[<span class="string">&#x27;Year&#x27;</span>]&gt;=<span class="number">1955</span>].groupby([<span class="string">&#x27;Month&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.hist(temp[<span class="string">&#x27;AirPassengers&#x27;</span>],bins=<span class="number">10</span>,<span class="built_in">range</span>=(<span class="number">200</span>,<span class="number">700</span>))</span><br><span class="line">plt.xlabel(<span class="string">&quot;Month&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Hundreds of thousands&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;plot with Matplotlib&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;plot with Matplotlib&#39;)</code></pre><p><img src="/content/images/2021-08-25-output_18_1.png" alt="png"></p><h2 id="7-Generate-the-histogram-below-of-monthly-passengers"><a href="#7-Generate-the-histogram-below-of-monthly-passengers" class="headerlink" title="#7 Generate the histogram below of monthly passengers"></a>#7 Generate the histogram below of monthly passengers</h2><p><strong>Additional requirements:</strong></p><ul><li>Generate two groups to compare. Group 1 should be the years 1949-1950. Group 2 should be the years 1959-60.</li><li>Binwidth of 50 from 100 to 700</li><li>yticks from 0 to 24, spaced by 2</li><li>Be sure to include a legend</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp1=passengers[ (passengers[<span class="string">&#x27;Year&#x27;</span>]&gt;=<span class="number">1949</span>) &amp; (passengers[<span class="string">&#x27;Year&#x27;</span>]&lt;=<span class="number">1950</span>)].groupby([<span class="string">&#x27;Month&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line">temp2=passengers[ (passengers[<span class="string">&#x27;Year&#x27;</span>]&gt;=<span class="number">1959</span>) &amp; (passengers[<span class="string">&#x27;Year&#x27;</span>]&lt;=<span class="number">1960</span>)].groupby([<span class="string">&#x27;Month&#x27;</span>])[<span class="string">&#x27;AirPassengers&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.hist(temp1[<span class="string">&#x27;AirPassengers&#x27;</span>],bins=<span class="number">12</span>,alpha=<span class="number">0.5</span>,<span class="built_in">range</span>=(<span class="number">100</span>,<span class="number">700</span>),label=<span class="string">&#x27;1949-50&#x27;</span>)</span><br><span class="line">plt.hist(temp2[<span class="string">&#x27;AirPassengers&#x27;</span>],bins=<span class="number">12</span>,alpha=<span class="number">0.5</span>,<span class="built_in">range</span>=(<span class="number">100</span>,<span class="number">700</span>),label=<span class="string">&#x27;1959-60&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Month&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Hundreds of thousands&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">24</span>, <span class="number">2.0</span>))</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;plot with Matplotlib&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x2d3705b9d90&gt;</code></pre><p><img src="/content/images/2021-08-25-output_20_1.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matplotlib tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Add ssh key to access github and simple git commands</title>
      <link href="2021/08/23/2021-08-23-1/"/>
      <url>2021/08/23/2021-08-23-1/</url>
      
        <content type="html"><![CDATA[<p>Here are ways to add ssh key in Github, such that one can connect to github repositories without typing username and passwords.</p><h5 id="For-MAC-Users"><a href="#For-MAC-Users" class="headerlink" title="For MAC Users:"></a>For MAC Users:</h5><p>To create an SSH Key, go to your terminal (or iTerm 2) and enter <code>ssh-keygen</code>. You will be prompted for a file in which to save the key (.ssh/id_rsa). There’s no need to enter anything, just press enter. When prompted for a passphrase, you can enter one or just press enter to ignore creating a passphrase.</p><p>Your SSH key has been saved to ssh/id_rsa.pub, run the command <code>pbcopy &lt; ~/.ssh/id_rsa.pub</code> to copy this to your clipboard.</p><p>Now go to your Github account setting for Key: <a href="https://github.com/settings/keys">https://github.com/settings/keys</a> and click ‘New SSH key’. Add any title you want, like ‘First SSH Key’, paste in your SSH key, and click the ‘Add SSH key’ button.</p><h5 id="For-PC-Users"><a href="#For-PC-Users" class="headerlink" title="For PC Users:"></a>For PC Users:</h5><p>To create an SSH Key, go to your terminal and enter <code>ssh-keygen</code>. You will be prompted for a file in which to save the key (.ssh/id_rsa). There’s no need to enter anything, just press enter. When prompted for a passphrase, you can enter one or just press enter to ignore creating a passphrase.</p><p>Your SSH key has been saved to ssh/id_rsa.pub, run the command <code>cat ~/.ssh/id_rsa.pub</code> to see your SSH key in the proper format. Copy the whole text string starting with ‘ssh’ to the end.</p><p>Now go to your Github account setting for keys: <a href="https://github.com/settings/keys">https://github.com/settings/keys</a> and click ‘New SSH key’. Add any title you want, like ‘First SSH Key’. Paste your SSH key to the Key window, and click the ‘Add SSH key’ button.</p><p>There are a lot of complex functionalities of Git, but for 99% of work there are 4 things that you need to be able to do:</p><ol><li><p>Create a branch <code>git checkout -b my-branch-name</code></p></li><li><p>Add files that you want to queue up for saving.</p><ul><li><p>To add all files: <code>git add .</code></p></li><li><p>To add a specific file: <code>git add path-to-file</code></p></li></ul></li><li><p>Save (commit) changes to the files that you added above. <code>git commit -m &quot;message about this commit. Ex: change button color to green.&quot;</code></p></li><li><p>Sync your branch to Github so that you can later make a pull request. <code>git push -u origin my-branch-name</code></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git and github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overlay histogram distributions using seaborn or matplotlib</title>
      <link href="2021/07/26/2021-07-26-1/"/>
      <url>2021/07/26/2021-07-26-1/</url>
      
        <content type="html"><![CDATA[<p>In this example, we show two methods to overlay histogram distributions using seaborn and matplotlib separately.</p><h2 id="import-library"><a href="#import-library" class="headerlink" title="import library"></a>import library</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="generate-some-data-for-histgram"><a href="#generate-some-data-for-histgram" class="headerlink" title="generate some data for histgram"></a>generate some data for histgram</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1 = np.random.randint(<span class="number">100</span>,size=<span class="number">1000</span>)</span><br><span class="line">list2 = np.random.randint(<span class="number">200</span>,size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># also getthem into a dataframe into one column, but add a second column to label source</span></span><br><span class="line"><span class="built_in">list</span> = np.concatenate([list1,list2])</span><br><span class="line">lables = [<span class="string">&#x27;l1&#x27;</span>]*<span class="built_in">len</span>(list1)+[<span class="string">&#x27;l2&#x27;</span>]*<span class="built_in">len</span>(list2)</span><br><span class="line">d = &#123;<span class="string">&#x27;x&#x27;</span>:<span class="built_in">list</span>,<span class="string">&#x27;label&#x27;</span>:lables&#125;</span><br><span class="line">df = pd.DataFrame(d)</span><br><span class="line">display(df)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>x</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>49</td>      <td>l1</td>    </tr>    <tr>      <th>1</th>      <td>93</td>      <td>l1</td>    </tr>    <tr>      <th>2</th>      <td>38</td>      <td>l1</td>    </tr>    <tr>      <th>3</th>      <td>96</td>      <td>l1</td>    </tr>    <tr>      <th>4</th>      <td>32</td>      <td>l1</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>1995</th>      <td>18</td>      <td>l2</td>    </tr>    <tr>      <th>1996</th>      <td>102</td>      <td>l2</td>    </tr>    <tr>      <th>1997</th>      <td>1</td>      <td>l2</td>    </tr>    <tr>      <th>1998</th>      <td>175</td>      <td>l2</td>    </tr>    <tr>      <th>1999</th>      <td>77</td>      <td>l2</td>    </tr>  </tbody></table><p>2000 rows × 2 columns</p></div><h2 id="method-1-overlay-dataframe-columns-with-different-labels"><a href="#method-1-overlay-dataframe-columns-with-different-labels" class="headerlink" title="method 1, overlay dataframe columns with different labels"></a>method 1, overlay dataframe columns with different labels</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.displot(df, x=<span class="string">&quot;x&quot;</span>, hue=<span class="string">&quot;label&quot;</span>, stat=<span class="string">&quot;density&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x24b5c685988&gt;</code></pre><p><img src="/content/images/2021-07-26-1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h2 id="method-2-overlay-two-seperate-lists-into-histograms-using-matplotlib"><a href="#method-2-overlay-two-seperate-lists-into-histograms-using-matplotlib" class="headerlink" title="method 2,  overlay two seperate lists into histograms using matplotlib"></a>method 2,  overlay two seperate lists into histograms using matplotlib</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.hist(list1,bins=<span class="number">20</span>, alpha=<span class="number">0.5</span>, label=<span class="string">&quot;data1&quot;</span>)</span><br><span class="line">plt.hist(list2, bins=<span class="number">20</span>, alpha=<span class="number">0.5</span>, label=<span class="string">&quot;data2&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Data&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Count&quot;</span>, size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Multiple Histograms with Matplotlib&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x24b5face788&gt;</code></pre><p><img src="/content/images/2021-07-26-2.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> seaborn tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>robust method to parse time string to datetime using dateutil parser</title>
      <link href="2021/07/14/2021-07-14-1/"/>
      <url>2021/07/14/2021-07-14-1/</url>
      
        <content type="html"><![CDATA[<p>Convert time strings into datetime format coudd be very tedious, because we need to make sure the every new data<br>follow the exact format required by the conversion functions, otherwise it will raise error.</p><p>One good way is to user the dateutil.parser package, which is much more flexiable. It can also support some fuzziness.<br>With this package, even some data has slightly different formats than we expect, it will not cause error.</p><h2 id="The-traditional-way-to-convert-time-string-to-datatime-format"><a href="#The-traditional-way-to-convert-time-string-to-datatime-format" class="headerlink" title="The traditional way to convert time string to datatime format"></a>The traditional way to convert time string to datatime format</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># without milliseconds format</span></span><br><span class="line">item = <span class="string">&#x27;2022/01/01 10:49:12&#x27;</span></span><br><span class="line">result = datetime.datetime.strptime(item, <span class="string">&quot;%Y/%m/%d %H:%M:%S&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result.year)</span><br><span class="line"></span><br><span class="line"><span class="comment"># with milliseconds format</span></span><br><span class="line">item = <span class="string">&#x27;2022/01/01 10:49:12.213&#x27;</span></span><br><span class="line">result = datetime.datetime.strptime(item, <span class="string">&quot;%Y/%m/%d %H:%M:%S.%f&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result.year)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in the above example if there is a new item that doesn&#x27;t follow the milliseconds format, it will raise error</span></span><br><span class="line">item = <span class="string">&#x27;2022/01/01 10:49:12&#x27;</span></span><br><span class="line">result = datetime.datetime.strptime(item, <span class="string">&quot;%Y/%m/%d %H:%M:%S.%f&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result.year)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>20222022---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)&lt;ipython-input-20-a29c39b3ca30&gt; in &lt;module&gt;     15 # in the above example if there is a new item that doesn&#39;t follow the milliseconds format, it will raise error     16 item = &#39;2022/01/01 10:49:12&#39;---&gt; 17 result = datetime.datetime.strptime(item, &quot;%Y/%m/%d %H:%M:%S.%f&quot;)     18      19 print(result.year)D:\Anaconda3\lib\_strptime.py in _strptime_datetime(cls, data_string, format)    575     &quot;&quot;&quot;Return a class cls instance based on the input string and the    576     format string.&quot;&quot;&quot;--&gt; 577     tt, fraction, gmtoff_fraction = _strptime(data_string, format)    578     tzname, gmtoff = tt[-2:]    579     args = tt[:6] + (fraction,)D:\Anaconda3\lib\_strptime.py in _strptime(data_string, format)    357     if not found:    358         raise ValueError(&quot;time data %r does not match format %r&quot; %--&gt; 359                          (data_string, format))    360     if len(data_string) != found.end():    361         raise ValueError(&quot;unconverted data remains: %s&quot; %ValueError: time data &#39;2022/01/01 10:49:12&#39; does not match format &#39;%Y/%m/%d %H:%M:%S.%f&#39;</code></pre><h2 id="use-parser-in-dateutil-package-a-more-stable-way"><a href="#use-parser-in-dateutil-package-a-more-stable-way" class="headerlink" title="use parser in dateutil package, a more stable way"></a>use parser in dateutil package, a more stable way</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># for the same example above, it will not raiser error</span></span><br><span class="line"></span><br><span class="line">item = <span class="string">&#x27;2022/01/01 10:49:12&#x27;</span></span><br><span class="line">result = parse(item)</span><br><span class="line"><span class="built_in">print</span>(result.year)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">item = <span class="string">&#x27;2022/01/01 10:49:12.213&#x27;</span></span><br><span class="line">result = parse(item)</span><br><span class="line"><span class="built_in">print</span>(result.year)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>20222022</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> feature extraction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dataframe histogram visualization with seaborn using countplot</title>
      <link href="2021/07/06/2021-07-06-1/"/>
      <url>2021/07/06/2021-07-06-1/</url>
      
        <content type="html"><![CDATA[<p>We often need to plot histograms to visualize distributions of certain features or variables.<br>How to quickly obtain a useful plot and get the work done？ If what we care is the frequency of each values, seaborn provides<br>a convenient way, count_plot() function, to get the plot without count the data by ourself and then do the bar chars.</p><p>Check the following example:</p><h1 id="get-the-data-and-do-a-count-plot"><a href="#get-the-data-and-do-a-count-plot" class="headerlink" title="get the data and do a count plot"></a>get the data and do a count plot</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&quot;titanic&quot;</span>)</span><br><span class="line">titanic[<span class="string">&#x27;class&#x27;</span>] = titanic[<span class="string">&#x27;class&#x27;</span>].astype(<span class="string">&#x27;str&#x27;</span>)</span><br><span class="line">display(titanic)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>survived</th>      <th>pclass</th>      <th>sex</th>      <th>age</th>      <th>sibsp</th>      <th>parch</th>      <th>fare</th>      <th>embarked</th>      <th>class</th>      <th>who</th>      <th>adult_male</th>      <th>deck</th>      <th>embark_town</th>      <th>alive</th>      <th>alone</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>3</td>      <td>male</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>7.2500</td>      <td>S</td>      <td>Third</td>      <td>man</td>      <td>True</td>      <td>NaN</td>      <td>Southampton</td>      <td>no</td>      <td>False</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>1</td>      <td>female</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>71.2833</td>      <td>C</td>      <td>First</td>      <td>woman</td>      <td>False</td>      <td>C</td>      <td>Cherbourg</td>      <td>yes</td>      <td>False</td>    </tr>    <tr>      <th>2</th>      <td>1</td>      <td>3</td>      <td>female</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>7.9250</td>      <td>S</td>      <td>Third</td>      <td>woman</td>      <td>False</td>      <td>NaN</td>      <td>Southampton</td>      <td>yes</td>      <td>True</td>    </tr>    <tr>      <th>3</th>      <td>1</td>      <td>1</td>      <td>female</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>53.1000</td>      <td>S</td>      <td>First</td>      <td>woman</td>      <td>False</td>      <td>C</td>      <td>Southampton</td>      <td>yes</td>      <td>False</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>3</td>      <td>male</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>8.0500</td>      <td>S</td>      <td>Third</td>      <td>man</td>      <td>True</td>      <td>NaN</td>      <td>Southampton</td>      <td>no</td>      <td>True</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>886</th>      <td>0</td>      <td>2</td>      <td>male</td>      <td>27.0</td>      <td>0</td>      <td>0</td>      <td>13.0000</td>      <td>S</td>      <td>Second</td>      <td>man</td>      <td>True</td>      <td>NaN</td>      <td>Southampton</td>      <td>no</td>      <td>True</td>    </tr>    <tr>      <th>887</th>      <td>1</td>      <td>1</td>      <td>female</td>      <td>19.0</td>      <td>0</td>      <td>0</td>      <td>30.0000</td>      <td>S</td>      <td>First</td>      <td>woman</td>      <td>False</td>      <td>B</td>      <td>Southampton</td>      <td>yes</td>      <td>True</td>    </tr>    <tr>      <th>888</th>      <td>0</td>      <td>3</td>      <td>female</td>      <td>NaN</td>      <td>1</td>      <td>2</td>      <td>23.4500</td>      <td>S</td>      <td>Third</td>      <td>woman</td>      <td>False</td>      <td>NaN</td>      <td>Southampton</td>      <td>no</td>      <td>False</td>    </tr>    <tr>      <th>889</th>      <td>1</td>      <td>1</td>      <td>male</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>30.0000</td>      <td>C</td>      <td>First</td>      <td>man</td>      <td>True</td>      <td>C</td>      <td>Cherbourg</td>      <td>yes</td>      <td>True</td>    </tr>    <tr>      <th>890</th>      <td>0</td>      <td>3</td>      <td>male</td>      <td>32.0</td>      <td>0</td>      <td>0</td>      <td>7.7500</td>      <td>Q</td>      <td>Third</td>      <td>man</td>      <td>True</td>      <td>NaN</td>      <td>Queenstown</td>      <td>no</td>      <td>True</td>    </tr>  </tbody></table><p>891 rows × 15 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set_theme(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br><span class="line">ax = sns.countplot(x=<span class="string">&quot;embark_town&quot;</span>, data=titanic)</span><br></pre></td></tr></table></figure><p><img src="/content/images/2021-07-06-1.png" alt="png"></p><h1 id="what-if-we-have-too-many-values-for-the-feature-and-we-can’t-plot-all-of-their-distributions-in-the-histogram"><a href="#what-if-we-have-too-many-values-for-the-feature-and-we-can’t-plot-all-of-their-distributions-in-the-histogram" class="headerlink" title="what if we have too many values for the feature, and we can’t plot all of their distributions in the histogram?"></a>what if we have too many values for the feature, and we can’t plot all of their distributions in the histogram?</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get the distinct values first, then choose the top n values we want to present; here we choose 2 as an example</span></span><br><span class="line"></span><br><span class="line">sub_index = titanic[<span class="string">&#x27;class&#x27;</span>].value_counts().index[:<span class="number">2</span>]</span><br><span class="line">sub_data = titanic[titanic[<span class="string">&#x27;class&#x27;</span>].isin(sub_index)]</span><br><span class="line">sub_data = sub_data.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax = sns.countplot(x=<span class="string">&quot;class&quot;</span>, data=sub_data)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/content/images/2021-07-06-2.png" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># we can also explicitly require the order to be ascending</span></span><br><span class="line">ax = sns.countplot(x=<span class="string">&quot;class&quot;</span>, data=sub_data,order=sub_index[::-<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/content/images/2021-07-06-3.png" alt="png"></p><h1 id="now-how-to-show-the-value-counts-for-two-categorical-variables"><a href="#now-how-to-show-the-value-counts-for-two-categorical-variables" class="headerlink" title="now how to show the value counts for two categorical variables?"></a>now how to show the value counts for two categorical variables?</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.countplot(x=<span class="string">&quot;class&quot;</span>, hue=<span class="string">&quot;who&quot;</span>, data=titanic)</span><br></pre></td></tr></table></figure><p><img src="/content/images/2021-07-06-4.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> seaborn tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>multi line plot with seaborn</title>
      <link href="2021/07/01/2021-07-01-1/"/>
      <url>2021/07/01/2021-07-01-1/</url>
      
        <content type="html"><![CDATA[<p>In this example, we show to do multi-plot graph using seaborn.<br>In addtion, some of the ways to change fonts sizes are also shown.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = [</span><br><span class="line">         [<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;10&#x27;</span>,<span class="string">&#x27;2021-07-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;12&#x27;</span>,<span class="string">&#x27;2021-08-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;15&#x27;</span>,<span class="string">&#x27;2021-09-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;20&#x27;</span>,<span class="string">&#x27;2021-10-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;20&#x27;</span>,<span class="string">&#x27;2021-07-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;22&#x27;</span>,<span class="string">&#x27;2021-08-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;25&#x27;</span>,<span class="string">&#x27;2021-09-01&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;30&#x27;</span>,<span class="string">&#x27;2021-10-01&#x27;</span>],</span><br><span class="line">        </span><br><span class="line">       ]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data=data, columns=[<span class="string">&#x27;company&#x27;</span>,<span class="string">&#x27;price&#x27;</span>,<span class="string">&#x27;date&#x27;</span>])</span><br><span class="line">display(df)</span><br><span class="line"></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>company</th>      <th>price</th>      <th>date</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>A</td>      <td>10</td>      <td>2021-07-01</td>    </tr>    <tr>      <th>1</th>      <td>A</td>      <td>12</td>      <td>2021-08-01</td>    </tr>    <tr>      <th>2</th>      <td>A</td>      <td>15</td>      <td>2021-09-01</td>    </tr>    <tr>      <th>3</th>      <td>A</td>      <td>20</td>      <td>2021-10-01</td>    </tr>    <tr>      <th>4</th>      <td>B</td>      <td>20</td>      <td>2021-07-01</td>    </tr>    <tr>      <th>5</th>      <td>B</td>      <td>22</td>      <td>2021-08-01</td>    </tr>    <tr>      <th>6</th>      <td>B</td>      <td>25</td>      <td>2021-09-01</td>    </tr>    <tr>      <th>7</th>      <td>B</td>      <td>30</td>      <td>2021-10-01</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># global change the font scales of the sns plot for easy set up</span></span><br><span class="line">sns.<span class="built_in">set</span>(font_scale=<span class="number">2</span>) </span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&#x27;white&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">temp = df.sort_values(by=<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plot_= sns.lineplot(x=<span class="string">&quot;date&quot;</span>, y=<span class="string">&quot;price&quot;</span>, hue=<span class="string">&quot;company&quot;</span>, data=temp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># in case too many data points, we can skip some ticks on the x axis</span></span><br><span class="line"><span class="keyword">for</span> ind, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(plot_.get_xticklabels()):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ind % <span class="number">2</span> == <span class="number">0</span>:  <span class="comment"># every second label is kept</span></span><br><span class="line">        label.set_visible(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        label.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># adjust fonrt size of x axis , y axis and title</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#plot_.set_title(&#x27;example plot&#x27;)</span></span><br><span class="line">plot_.axes.set_title(<span class="string">&quot;Title&quot;</span>,fontsize=<span class="number">50</span>)</span><br><span class="line">plot_.set_xlabel(<span class="string">&quot;X Label&quot;</span>,fontsize=<span class="number">30</span>)</span><br><span class="line">plot_.set_ylabel(<span class="string">&quot;Y Label&quot;</span>,fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># adjust lengend font size</span></span><br><span class="line">plot_.legend(fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)                                                               </span><br><span class="line">plt.tight_layout()     </span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/content/images/2021-07-01-1.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> seaborn tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rare event encoding for categorical feature in machine learning in pandas dataframe</title>
      <link href="2021/06/23/2021-06-23-1/"/>
      <url>2021/06/23/2021-06-23-1/</url>
      
        <content type="html"><![CDATA[<p>If categorical features has too many values, it will generate too many features after encoding, such as one-hot encoding.<br>We could set the threshold, if certan value has percentage less than the threshold, we change the value to be ‘rare event’ or<br>something like that. By doing this, we make sure there are not too many levels for a categorical feature.</p><p>The following code can be applied on a dataframe:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def cat_rare_event(df,threshold=0.005):</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    for col in df.columns:</span><br><span class="line"></span><br><span class="line">        #print(df[col].dtype)</span><br><span class="line"></span><br><span class="line">        if df[col].dtype ==&#x27;object&#x27;:</span><br><span class="line"></span><br><span class="line">            print(col)</span><br><span class="line"></span><br><span class="line">            df.loc[df[col].value_counts()[df[col]].values &lt; int(len(df)*threshold), col] = &quot;rare_value&quot;</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    return df</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>or we could put this step as a customized pipeline:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">class cat_rare_event_Transformer(BaseEstimator, TransformerMixin):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Class Constructor</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def __init__(self,threshold=0.005):</span><br><span class="line"></span><br><span class="line">        self.threshold = threshold</span><br><span class="line"></span><br><span class="line">        print(&#x27;initialized&#x27;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Return self, nothing else to do here</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def transform(self, X_, y=None):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X = cat_rare_event(X,self.threshold)</span><br><span class="line"></span><br><span class="line">               </span><br><span class="line"></span><br><span class="line">        return X    </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> pandas tip </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>handles feature order in training and online production stage to avoid inconsistent error</title>
      <link href="2021/06/18/2021-06-18-1/"/>
      <url>2021/06/18/2021-06-18-1/</url>
      
        <content type="html"><![CDATA[<p>In applying machine learning models in production stage, like lightGBM model or any models.<br>While we all know the order of features shoud be same for both training stage, test stage, and the production stage.</p><p>In practice we might ignore that. In produciton stage, new data might come as a json format, where orders will disappear,<br>it has nothing to do with the original feature order in the model training stage.</p><p>The comming json will be converted to dataframe format, and passed to the model for prediction. We might usually<br>igore the fact that, the new dataframe column order is different from the original training dataframe column order now.<br>And it’s important to make sure they are consistent, and not up to the randome fate.</p><p>There are many ways to achieve this, the following shows how to do it in a pipeline fashion.</p><h2 id="define-piplenow-to-treat-the-effects-systematically"><a href="#define-piplenow-to-treat-the-effects-systematically" class="headerlink" title="define piplenow, to treat the effects systematically"></a>define piplenow, to treat the effects systematically</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LastStepTransformer</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Class Constructor</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        self.traincolumns = []</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;initialized&#x27;</span>)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># Return self, nothing else to do here</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        self.traincolumns = X.columns</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X_, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line">        <span class="comment"># make sure any new data follows the same order of features used in the training stage</span></span><br><span class="line">        <span class="keyword">return</span> X[self.traincolumns]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># make an data process pipeline, using the above transformer as the last steps here.</span></span><br><span class="line"><span class="comment"># in practice, any preprocessing steps can be put here as well</span></span><br><span class="line"></span><br><span class="line">dataPipeline = Pipeline([</span><br><span class="line"> (<span class="string">&#x27;last_step&#x27;</span>,LastStepTransformer())   </span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>initialized</code></pre><h2 id="show-an-example"><a href="#show-an-example" class="headerlink" title="show an example"></a>show an example</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">data_train =[[<span class="number">1.1</span>,<span class="number">2.2</span>],[<span class="number">2.1</span>,<span class="number">3.2</span>]]</span><br><span class="line">data_test =[[<span class="number">3.1</span>,<span class="number">5.2</span>],[<span class="number">1.1</span>,<span class="number">2.2</span>]]</span><br><span class="line"></span><br><span class="line">df_train = pd.DataFrame(data=data_train,columns=[<span class="string">&#x27;col1&#x27;</span>,<span class="string">&#x27;col2&#x27;</span>])</span><br><span class="line">df_test = pd.DataFrame(data=data_test,columns=[<span class="string">&#x27;col2&#x27;</span>,<span class="string">&#x27;col1&#x27;</span>])</span><br><span class="line"></span><br><span class="line">display(df_train)</span><br><span class="line">display(df_test)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>col1</th>      <th>col2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1.1</td>      <td>2.2</td>    </tr>    <tr>      <th>1</th>      <td>2.1</td>      <td>3.2</td>    </tr>  </tbody></table></div><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>col2</th>      <th>col1</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>3.1</td>      <td>5.2</td>    </tr>    <tr>      <th>1</th>      <td>1.1</td>      <td>2.2</td>    </tr>  </tbody></table></div><h2 id="now-in-the-training-stage-we-call-fit-transform-of-the-data-pipeline-so-the-pipeline-will-remembers-the-orignal-order"><a href="#now-in-the-training-stage-we-call-fit-transform-of-the-data-pipeline-so-the-pipeline-will-remembers-the-orignal-order" class="headerlink" title="now in the training stage, we call fit_transform() of the data pipeline, so the pipeline will remembers the orignal order"></a>now in the training stage, we call fit_transform() of the data pipeline, so the pipeline will remembers the orignal order</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">dataPipeline.fit_transform(df_train)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>col1</th>      <th>col2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1.1</td>      <td>2.2</td>    </tr>    <tr>      <th>1</th>      <td>2.1</td>      <td>3.2</td>    </tr>  </tbody></table></div><h2 id="now-in-the-test-stage-we-only-call-transform-of-the-datapipleine-so-any-new-data-will-be-reordered-as-the-training-data"><a href="#now-in-the-test-stage-we-only-call-transform-of-the-datapipleine-so-any-new-data-will-be-reordered-as-the-training-data" class="headerlink" title="now in the test stage, we only call transform() of the datapipleine, so any new data will be reordered as the training data"></a>now in the test stage, we only call transform() of the datapipleine, so any new data will be reordered as the training data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test data, notice the column order&#x27;</span>)</span><br><span class="line">display(df_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;after transform, notice the column order now changes&#x27;</span>)</span><br><span class="line">dataPipeline.transform(df_test)</span><br></pre></td></tr></table></figure><pre><code>test data, notice the column order</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>col2</th>      <th>col1</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>3.1</td>      <td>5.2</td>    </tr>    <tr>      <th>1</th>      <td>1.1</td>      <td>2.2</td>    </tr>  </tbody></table></div><pre><code>after transform, ontice the column order now changes</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>col1</th>      <th>col2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>5.2</td>      <td>3.1</td>    </tr>    <tr>      <th>1</th>      <td>2.2</td>      <td>1.1</td>    </tr>  </tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> pandas tip </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>some handy functions to group continous variables and missing value imputation in dataframe</title>
      <link href="2021/06/15/2021-06-15-1/"/>
      <url>2021/06/15/2021-06-15-1/</url>
      
        <content type="html"><![CDATA[<p>Following example shows how to group age variable into groups,<br>and some simple missing value imputaiton proecdures.</p><p>There is also an example to transform timestamp variable to week day and hour infomation.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># utility functions</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">def age_input(age):</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    if pd.isnull(age):</span><br><span class="line"></span><br><span class="line">        return &#x27;missing&#x27;</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    age = int(age)</span><br><span class="line"></span><br><span class="line">    if age&lt;=20:</span><br><span class="line"></span><br><span class="line">        return &#x27;16-20&#x27;</span><br><span class="line"></span><br><span class="line">    elif age&lt;=24:</span><br><span class="line"></span><br><span class="line">        return &#x27;21-24&#x27;</span><br><span class="line"></span><br><span class="line">    elif age&lt;=34:</span><br><span class="line"></span><br><span class="line">        return &#x27;25-34&#x27;</span><br><span class="line"></span><br><span class="line">    elif age&lt;=44:</span><br><span class="line"></span><br><span class="line">        return &#x27;35-44&#x27;</span><br><span class="line"></span><br><span class="line">    elif age&lt;=54:</span><br><span class="line"></span><br><span class="line">        return &#x27;45-54&#x27;</span><br><span class="line"></span><br><span class="line">    elif age&lt;=64:</span><br><span class="line"></span><br><span class="line">        return &#x27;55-64&#x27;</span><br><span class="line"></span><br><span class="line">    else:</span><br><span class="line"></span><br><span class="line">        return &#x27;65+&#x27;</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"># missing value handelling or imputation in dataframe </span><br><span class="line"></span><br><span class="line">def missing_handle(df):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">    for col in df.columns:</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line"></span><br><span class="line">        if df[col].dtype==object:</span><br><span class="line"></span><br><span class="line">            df[col] = df[col].fillna(&#x27;missing&#x27;)</span><br><span class="line"></span><br><span class="line">        elif df[col].dtype == bool:</span><br><span class="line"></span><br><span class="line">            df[col+&#x27;_null&#x27;] = df[col].apply(lambda x: 1 if pd.isnull(x) else 0)</span><br><span class="line"></span><br><span class="line">            df[col] = data[col].fillna(data[col].mode()[0])</span><br><span class="line"></span><br><span class="line">          </span><br><span class="line"></span><br><span class="line">        else:</span><br><span class="line"></span><br><span class="line">            df[col] = df[col].fillna(-999)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    return df</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">class dayandhour_Transformer(BaseEstimator, TransformerMixin):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Class Constructor</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        print(&#x27;initialized&#x27;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Return self, nothing else to do here</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Customized transformer method</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    def transform(self, X_, y=None):</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X[&#x27;dayofweek&#x27;]=pd.to_datetime(X[&#x27;sentat&#x27;]).dt.dayofweek</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X[&#x27;hour&#x27;]=pd.to_datetime(X[&#x27;sentat&#x27;]).dt.hour</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        X = X.drop(&#x27;sentat&#x27;,axis=1)</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">        # apply age group function here</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">        X[&#x27;age_group&#x27;] = X[&#x27;age&#x27;].apply(age_input)</span><br><span class="line"></span><br><span class="line">        X = X.drop(&#x27;age&#x27;,axis=1)</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        # apply missing handelling here</span><br><span class="line"></span><br><span class="line">        X = missing_handle(X)</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        return X</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"># define the transformer</span><br><span class="line">dayandhour_transformer = dayandhour_Transformer()</span><br><span class="line"></span><br><span class="line"># usage example</span><br><span class="line">df_new = dayandhour_transformer.transform(df)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> python </tag>
            
            <tag> pandas tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>explode and expand rows to multiple rows or columns to multiple columns using pandas dataframe</title>
      <link href="2021/06/14/2021-06-14-1/"/>
      <url>2021/06/14/2021-06-14-1/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="generate-some-example-some-data"><a href="#generate-some-example-some-data" class="headerlink" title="generate some example some data"></a>generate some example some data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [ [[<span class="string">&#x27;python&#x27;</span>,<span class="string">&#x27;C&#x27;</span>],<span class="string">&#x27;John&#x27;</span>],[[<span class="string">&#x27;python&#x27;</span>,<span class="string">&#x27;Go&#x27;</span>],<span class="string">&#x27;Mark&#x27;</span>] ]</span><br><span class="line">df = pd.DataFrame(data=data,columns=[<span class="string">&#x27;language&#x27;</span>,<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>       language  name0   [python, C]  John1  [python, Go]  Mark</code></pre><h2 id="1-First-we-expload-the-laguage-column-put-each-of-the-array-element-into-a-single-row"><a href="#1-First-we-expload-the-laguage-column-put-each-of-the-array-element-into-a-single-row" class="headerlink" title="1. First, we expload the laguage column, put each of the array element into a single row"></a>1. First, we expload the laguage column, put each of the array element into a single row</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df2 = df.explode(<span class="string">&#x27;language&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>  language  name0   python  John0        C  John1   python  Mark1       Go  Mark</code></pre><h3 id="if-we-want-to-reset-the-index…"><a href="#if-we-want-to-reset-the-index…" class="headerlink" title="if we want to reset the index…."></a>if we want to reset the index….</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df2 = df.explode(<span class="string">&#x27;language&#x27;</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>  language  name0   python  John1        C  John2   python  Mark3       Go  Mark</code></pre><h3 id="1-2-now-how-about-the-original-column-is-not-list-but-strings-we-need-to-split-use-assign-then-chain-it-with-explode"><a href="#1-2-now-how-about-the-original-column-is-not-list-but-strings-we-need-to-split-use-assign-then-chain-it-with-explode" class="headerlink" title="1.2 now how about the original column is not list, but strings we need to split? use assign then chain it with explode"></a>1.2 now how about the original column is not list, but strings we need to split? use assign then chain it with explode</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [ [<span class="string">&#x27;python,C&#x27;</span>,<span class="string">&#x27;John&#x27;</span>],[<span class="string">&#x27;python,Go&#x27;</span>,<span class="string">&#x27;Mark&#x27;</span>] ]</span><br><span class="line">df = pd.DataFrame(data=data,columns=[<span class="string">&#x27;language&#x27;</span>,<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>    language  name0   python,C  John1  python,Go  Mark</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df2 = df.assign(language=df.language.<span class="built_in">str</span>.split(<span class="string">&quot;,&quot;</span>)).explode(<span class="string">&#x27;language&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br></pre></td></tr></table></figure><pre><code>  language  name0   python  John0        C  John1   python  Mark1       Go  Mark</code></pre><h2 id="2-in-the-above-example-we-expand-rows-into-multiple-rows-by-one-column’s-list-like-element-now-sometimes-we-need-to-expand-columns-into-multiple-columns"><a href="#2-in-the-above-example-we-expand-rows-into-multiple-rows-by-one-column’s-list-like-element-now-sometimes-we-need-to-expand-columns-into-multiple-columns" class="headerlink" title="2. in the above example, we expand rows into multiple rows by one column’s list like element; now sometimes we need to expand columns into multiple columns"></a>2. in the above example, we expand rows into multiple rows by one column’s list like element; now sometimes we need to expand columns into multiple columns</h2><h3 id="let’s-generate-some-data-again"><a href="#let’s-generate-some-data-again" class="headerlink" title="let’s generate some data again"></a>let’s generate some data again</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [ [[<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;27&#x27;</span>],<span class="string">&#x27;John&#x27;</span>],[[<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;30&#x27;</span>],<span class="string">&#x27;Mark&#x27;</span>] ]</span><br><span class="line">df = pd.DataFrame(data=data,columns=[<span class="string">&#x27;age_info&#x27;</span>,<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>    age_info  name0  [age, 27]  John1  [age, 30]  Mark</code></pre><h3 id="we-could-use-to-list"><a href="#we-could-use-to-list" class="headerlink" title="we could use to_list()"></a>we could use to_list()</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[[<span class="string">&#x27;attribute&#x27;</span>,<span class="string">&#x27;value&#x27;</span>]] = df.age_info.to_list()</span><br><span class="line"><span class="comment"># or df[[&#x27;First&#x27;,&#x27;Last&#x27;]] = df[&#x27;age_info&#x27;].to_list()</span></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>    age_info  name attribute value0  [age, 27]  John       age    271  [age, 30]  Mark       age    30</code></pre><h3 id="now-same-quesiton-how-about-the-column-is-a-string-that-can-be-split"><a href="#now-same-quesiton-how-about-the-column-is-a-string-that-can-be-split" class="headerlink" title="now same quesiton, how about the column is a string that can be split?"></a>now same quesiton, how about the column is a string that can be split?</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [ [<span class="string">&#x27;john,f&#x27;</span>,<span class="string">&#x27;1&#x27;</span>],[<span class="string">&#x27;mark,y&#x27;</span>,<span class="string">&#x27;2&#x27;</span>] ]</span><br><span class="line">df = pd.DataFrame(data=data,columns=[<span class="string">&#x27;full_name&#x27;</span>,<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df[[<span class="string">&#x27;First&#x27;</span>,<span class="string">&#x27;Last&#x27;</span>]] = df.full_name.<span class="built_in">str</span>.split(<span class="string">&quot;,&quot;</span>,expand=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>  full_name id0    john,f  11    mark,y  2  full_name id First Last0    john,f  1  john    f1    mark,y  2  mark    y</code></pre>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> python </tag>
            
            <tag> pandas tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>aggregate features from different rows into one row in pandas dataframe</title>
      <link href="2021/06/12/2021-06-12-1/"/>
      <url>2021/06/12/2021-06-12-1/</url>
      
        <content type="html"><![CDATA[<p>In many use cases, different features of the same event are stored in a table by multiple rows.<br>multiple columns will indicate each characteristics of one feature, such as name, value, timestamp, etc.</p><p>In machine learning, we need to aggregate them into one row for training, and the following shows how do do it in dataframe easily.</p><h2 id="generate-some-example-dataframe"><a href="#generate-some-example-dataframe" class="headerlink" title="generate some example dataframe"></a>generate some example dataframe</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = [ [<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;name1&#x27;</span>,<span class="string">&#x27;value1&#x27;</span>],[<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;name2&#x27;</span>,<span class="string">&#x27;value2&#x27;</span>],[<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;name3&#x27;</span>,<span class="string">&#x27;value3&#x27;</span>],</span><br><span class="line">         [<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;name1&#x27;</span>,<span class="string">&#x27;value4&#x27;</span>],[<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;name2&#x27;</span>,<span class="string">&#x27;value5&#x27;</span>] </span><br><span class="line">       ]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data=data)</span><br><span class="line">df.columns =[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">display(df)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>name</th>      <th>value</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>name1</td>      <td>value1</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>name2</td>      <td>value2</td>    </tr>    <tr>      <th>2</th>      <td>1</td>      <td>name3</td>      <td>value3</td>    </tr>    <tr>      <th>3</th>      <td>2</td>      <td>name1</td>      <td>value4</td>    </tr>    <tr>      <th>4</th>      <td>2</td>      <td>name2</td>      <td>value5</td>    </tr>  </tbody></table></div><h2 id="group-the-dataframe-by-id-then-aggregate-all-the-feature-values-into-one-column"><a href="#group-the-dataframe-by-id-then-aggregate-all-the-feature-values-into-one-column" class="headerlink" title="group the dataframe by id, then aggregate all the feature values into one column"></a>group the dataframe by id, then aggregate all the feature values into one column</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df2 = df.groupby(<span class="string">&#x27;id&#x27;</span>).apply(<span class="keyword">lambda</span> x: <span class="built_in">dict</span>(x[[<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;value&#x27;</span>]].values.tolist())).reset_index()</span><br><span class="line">df3 = pd.DataFrame(data=df2[<span class="number">0</span>].values.tolist())</span><br><span class="line">display(df3)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name1</th>      <th>name2</th>      <th>name3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>value1</td>      <td>value2</td>      <td>value3</td>    </tr>    <tr>      <th>1</th>      <td>value4</td>      <td>value5</td>      <td>NaN</td>    </tr>  </tbody></table></div><h1 id="put-the-above-the-transformation-into-a-scikit-learn-customed-transformer"><a href="#put-the-above-the-transformation-into-a-scikit-learn-customed-transformer" class="headerlink" title="put the above the transformation into a scikit-learn customed transformer"></a>put the above the transformation into a scikit-learn customed transformer</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">my_Transformer</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">#Class Constructor</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;start&#x27;</span>)</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">           </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return self</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment">#Customized transformer</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X_, y=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line"></span><br><span class="line">        X2 = X.groupby(<span class="string">&#x27;id&#x27;</span>).apply(<span class="keyword">lambda</span> x: <span class="built_in">dict</span>(x[[<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;value&#x27;</span>]].values.tolist())).reset_index()</span><br><span class="line">        X3 = pd.DataFrame(data=X2[<span class="number">0</span>].values.tolist())     </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X3</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X1</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line"></span><br><span class="line"><span class="comment"># get a transformer object</span></span><br><span class="line">my_transformer = my_Transformer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># apply the transform on the original data</span></span><br><span class="line"></span><br><span class="line">df_new = my_transformer.transform(df)</span><br><span class="line">display(df_new)</span><br></pre></td></tr></table></figure><pre><code>start</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name1</th>      <th>name2</th>      <th>name3</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>value1</td>      <td>value2</td>      <td>value3</td>    </tr>    <tr>      <th>1</th>      <td>value4</td>      <td>value5</td>      <td>NaN</td>    </tr>  </tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pipeline </tag>
            
            <tag> preprocessing </tag>
            
            <tag> feature engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>time series feature engineering using tsfresh, training vs test</title>
      <link href="2021/06/10/2021-06-10-1/"/>
      <url>2021/06/10/2021-06-10-1/</url>
      
        <content type="html"><![CDATA[<p>During the test stage, i.e., once the model is on production, for any new data,<br>tsfresh feature generation does not depend the training data. So one can apply the same feature engineering process as the training data<br>without worrying about stroing information from training stage.</p><p>On ther hand, one can also use the following example to leverage scikit learn pipleline style to handel the feature generation<br>for both training and test stages.</p><h1 id="Feature-Selection-in-a-sklearn-pipeline"><a href="#Feature-Selection-in-a-sklearn-pipeline" class="headerlink" title="Feature Selection in a sklearn pipeline"></a>Feature Selection in a sklearn pipeline</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tsfresh.examples <span class="keyword">import</span> load_robot_execution_failures</span><br><span class="line"><span class="keyword">from</span> tsfresh.transformers <span class="keyword">import</span> RelevantFeatureAugmenter</span><br><span class="line"><span class="keyword">from</span> tsfresh.utilities.dataframe_functions <span class="keyword">import</span> impute</span><br></pre></td></tr></table></figure><h2 id="Load-and-Prepare-the-Data"><a href="#Load-and-Prepare-the-Data" class="headerlink" title="Load and Prepare the Data"></a>Load and Prepare the Data</h2><p>Check out the first example notebook to learn more about the data and format.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tsfresh.examples.robot_execution_failures <span class="keyword">import</span> download_robot_execution_failures</span><br><span class="line">download_robot_execution_failures() </span><br><span class="line">df_ts, y = load_robot_execution_failures()</span><br></pre></td></tr></table></figure><p>We want to use the extracted features to predict for each of the robot executions, if it was a failure or not.<br>Therefore our basic “entity” is a single robot execution given by a distinct <code>id</code>.</p><p>A dataframe with these identifiers as index needs to be prepared for the pipeline.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X = pd.DataFrame(index=y.index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data into train and test set</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y)</span><br></pre></td></tr></table></figure><h2 id="Build-the-pipeline"><a href="#Build-the-pipeline" class="headerlink" title="Build the pipeline"></a>Build the pipeline</h2><p>We build a sklearn pipeline that consists of a feature extraction step (<code>RelevantFeatureAugmenter</code>) with a subsequent <code>RandomForestClassifier</code>.</p><p>The <code>RelevantFeatureAugmenter</code> takes roughly the same arguments as <code>extract_features</code> and <code>select_features</code> do.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl = Pipeline([</span><br><span class="line">        (<span class="string">&#x27;augmenter&#x27;</span>, RelevantFeatureAugmenter(column_id=<span class="string">&#x27;id&#x27;</span>, column_sort=<span class="string">&#x27;time&#x27;</span>)),</span><br><span class="line">        (<span class="string">&#x27;classifier&#x27;</span>, RandomForestClassifier())</span><br><span class="line">      ])</span><br></pre></td></tr></table></figure><div class="alert alert-warning">    <p>Here comes the tricky part!</p><p>The input to the pipeline will be our dataframe <code>X</code>, which one row per identifier.<br>It is currently empty.<br>But which time series data should the <code>RelevantFeatureAugmenter</code> to actually extract the features from?</p><p>We need to pass the time series data (stored in <code>df_ts</code>) to the transformer.</p></div><p>In this case, df_ts contains the time series of both train and test set, if you have different dataframes for<br>train and test set, you have to call set_params two times<br>(see further below on how to deal with two independent data sets)</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts);</span><br></pre></td></tr></table></figure><p>We are now ready to fit the pipeline</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><p>The augmenter has used the input time series data to extract time series features for each of the identifiers in the <code>X_train</code> and selected only the relevant ones using the passed <code>y_train</code> as target.<br>These features have been added to <code>X_train</code> as new columns.<br>The classifier can now use these features during trainings.</p><h2 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h2><p>During interference, the augmentor does only extract the relevant features it has found out in the training phase and the classifier predicts the target using these features.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_pred = ppl.predict(X_test)</span><br></pre></td></tr></table></figure><p>So, finally we inspect the performance:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure><p>You can also find out, which columns the augmenter has selected</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl.named_steps[<span class="string">&quot;augmenter&quot;</span>].feature_selector.relevant_features</span><br></pre></td></tr></table></figure><div class="alert alert-info">    <p>In this example we passed in an empty (except the index) <code>X_train</code> or <code>X_test</code> into the pipeline.<br>However, you can also fill the input with other features you have (e.g. features extracted from the metadata)<br>or even use other pipeline components before.</p></div><h2 id="Separating-the-time-series-data-containers"><a href="#Separating-the-time-series-data-containers" class="headerlink" title="Separating the time series data containers"></a>Separating the time series data containers</h2><p>In the example above we passed in a single <code>df_ts</code> into the <code>RelevantFeatureAugmenter</code>, which was used both for training and predicting.<br>During training, only the data with the <code>id</code>s from <code>X_train</code> where extracted and during prediction the rest.</p><p>However, it is perfectly fine to call <code>set_params</code> twice: once before training and once before prediction.<br>This can be handy if you for example dump the trained pipeline to disk and re-use it only later for prediction.<br>You only need to make sure that the <code>id</code>s of the enteties you use during training/prediction are actually present in the passed time series data.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_ts_train = df_ts[df_ts[<span class="string">&quot;id&quot;</span>].isin(y_train.index)]</span><br><span class="line">df_ts_test = df_ts[df_ts[<span class="string">&quot;id&quot;</span>].isin(y_test.index)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts_train);</span><br><span class="line">ppl.fit(X_train, y_train);</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;pipeline.pkl&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(ppl, f)</span><br></pre></td></tr></table></figure><p>Later: load the fitted model and do predictions on new, unseen data</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;pipeline.pkl&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    ppk = pickle.load(f)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts_test);</span><br><span class="line">y_pred = ppl.predict(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pipeline </tag>
            
            <tag> preprocessing </tag>
            
            <tag> tsfresh </tag>
            
            <tag> time series </tag>
            
            <tag> feature engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>word tokenization and sentence tokenization in python using NLTK package</title>
      <link href="2021/06/09/2021-06-09-1/"/>
      <url>2021/06/09/2021-06-09-1/</url>
      
        <content type="html"><![CDATA[<h1 id="What-is-Tokenization"><a href="#What-is-Tokenization" class="headerlink" title="What is Tokenization?"></a>What is Tokenization?</h1><p>Tokenization is the process by which a large quantity of text is divided into smaller parts called tokens.<br>These tokens are very useful for finding patterns and are considered as a base step for stemming and lemmatization.<br>Tokenization also helps to substitute sensitive data elements with non-sensitive data elements.</p><p>Natural language processing is used for building applications such as Text classification, intelligent chatbot, sentimental analysis, language translation, etc.<br>It becomes vital to understand the pattern in the text to achieve the above-stated purpose.</p><h1 id="Tokenization-of-words"><a href="#Tokenization-of-words" class="headerlink" title="Tokenization of words"></a>Tokenization of words</h1><p>We use the method word_tokenize() to split a sentence into words.<br>The output of word tokenization can be converted to Data Frame for better text understanding in machine learning applications.<br>It can also be provided as input for further text cleaning steps such as punctuation removal, numeric character removal or stemming.</p><p>Code example:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from nltk.tokenize import word_tokenize</span><br><span class="line">text = &quot;God is Great! I won a lottery.&quot;</span><br><span class="line">print(word_tokenize(text))</span><br><span class="line"></span><br><span class="line">Output: [&#x27;God&#x27;, &#x27;is&#x27;, &#x27;Great&#x27;, &#x27;!&#x27;, &#x27;I&#x27;, &#x27;won&#x27;, &#x27;a&#x27;, &#x27;lottery&#x27;, &#x27;.&#x27;]</span><br></pre></td></tr></table></figure><p>From the above example, one can see the punctuationa are also included. Sometimes we want to exclude that.<br>To achieve this purpose, there are two ways:</p><h2 id="USE-nltk-RegexpTokenizer-TO-REMOVE-ALL-PUNCTUATION-MARKS"><a href="#USE-nltk-RegexpTokenizer-TO-REMOVE-ALL-PUNCTUATION-MARKS" class="headerlink" title="USE nltk.RegexpTokenizer() TO REMOVE ALL PUNCTUATION MARKS"></a>USE nltk.RegexpTokenizer() TO REMOVE ALL PUNCTUATION MARKS</h2><p>Call nltk.RegexpTokenizer(pattern) with pattern as r”\w+” to create a tokenzier that uses pattern to split a string.<br>Call RegexpTokenizer.tokenize(text) with RegexpTokenizer as the previous result and text as a string representing a sentence to return text as a list of words with punctuation’s removed.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sentence  = &quot;Think and wonder, wonder and think.&quot;</span><br><span class="line"></span><br><span class="line">tokenizer = nltk.RegexpTokenizer(r&quot;\w+&quot;)</span><br><span class="line">new_words = tokenizer.tokenize(sentence)</span><br><span class="line"></span><br><span class="line">print(new_words)</span><br><span class="line">OUTPUT</span><br><span class="line">[&#x27;Think&#x27;, &#x27;and&#x27;, &#x27;wonder&#x27;, &#x27;wonder&#x27;, &#x27;and&#x27;, &#x27;think&#x27;]</span><br></pre></td></tr></table></figure><h2 id="USE-nltk-word-tokenize-AND-LIST-COMPREHENSION-TO-REMOVE-ALL-PUNCTUATION-MARKS"><a href="#USE-nltk-word-tokenize-AND-LIST-COMPREHENSION-TO-REMOVE-ALL-PUNCTUATION-MARKS" class="headerlink" title="USE nltk.word_tokenize() AND LIST COMPREHENSION TO REMOVE ALL PUNCTUATION MARKS"></a>USE nltk.word_tokenize() AND LIST COMPREHENSION TO REMOVE ALL PUNCTUATION MARKS</h2><p>Call nltk.word_tokenize(text) with text as a string representing a sentence to return text as a list of words. Use the syntax [word for word in words if condition] with words as the previous result and condition as word.isalnum() to create a list containing each word in words that only contain alphanumeric characters.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sentence  = &quot;Think and wonder, wonder and think.&quot;</span><br><span class="line"></span><br><span class="line">words = nltk.word_tokenize(sentence)</span><br><span class="line">new_words= [word for word in words if word.isalnum()]</span><br><span class="line"></span><br><span class="line">print(new_words)</span><br><span class="line">OUTPUT</span><br><span class="line">[&#x27;Think&#x27;, &#x27;and&#x27;, &#x27;wonder&#x27;, &#x27;wonder&#x27;, &#x27;and&#x27;, &#x27;think&#x27;]</span><br></pre></td></tr></table></figure><h1 id="Tokenization-of-Sentences"><a href="#Tokenization-of-Sentences" class="headerlink" title="Tokenization of Sentences"></a>Tokenization of Sentences</h1><p>Sometimes you need to get sentences out of the texts at first.</p><p>Code example:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from nltk.tokenize import sent_tokenize</span><br><span class="line">text = &quot;God is Great! I won a lottery.&quot;</span><br><span class="line">print(sent_tokenize(text))</span><br><span class="line"></span><br><span class="line">Output: [&#x27;God is Great!&#x27;, &#x27;I won a lottery &#x27;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tokenization </tag>
            
            <tag> NLTK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>missing value or null value processing in pandas dataframe</title>
      <link href="2021/06/08/2021-06-08-1/"/>
      <url>2021/06/08/2021-06-08-1/</url>
      
        <content type="html"><![CDATA[<h1 id="obtain-null-or-missing-values-of-a-dataframe"><a href="#obtain-null-or-missing-values-of-a-dataframe" class="headerlink" title="obtain null or missing values of a dataframe"></a>obtain null or missing values of a dataframe</h1><p>Suppose the dataframe has the following formats, with 10 rows and 5 clomns:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">          0         1         2         3         4         5</span><br><span class="line">0  0.520113  0.884000  1.260966 -0.236597  0.312972 -0.196281</span><br><span class="line">1 -0.837552       NaN  0.143017  0.862355  0.346550  0.842952</span><br><span class="line">2 -0.452595       NaN -0.420790  0.456215  1.203459  0.527425</span><br><span class="line">3  0.317503 -0.917042  1.780938 -1.584102  0.432745  0.389797</span><br><span class="line">4 -0.722852  1.704820 -0.113821 -1.466458  0.083002  0.011722</span><br><span class="line">5 -0.622851 -0.251935 -1.498837       NaN  1.098323  0.273814</span><br><span class="line">6  0.329585  0.075312 -0.690209 -3.807924  0.489317 -0.841368</span><br><span class="line">7 -1.123433 -1.187496  1.868894 -2.046456 -0.949718       NaN</span><br><span class="line">8  1.133880 -0.110447  0.050385 -1.158387  0.188222       NaN</span><br><span class="line">9 -0.513741  1.196259  0.704537  0.982395 -0.585040 -1.693810</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>the isnull() function which would return a dataframe like this:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">       0      1      2      3      4      5</span><br><span class="line">0  False  False  False  False  False  False</span><br><span class="line">1  False   True  False  False  False  False</span><br><span class="line">2  False   True  False  False  False  False</span><br><span class="line">3  False  False  False  False  False  False</span><br><span class="line">4  False  False  False  False  False  False</span><br><span class="line">5  False  False  False   True  False  False</span><br><span class="line">6  False  False  False  False  False  False</span><br><span class="line">7  False  False  False  False  False   True</span><br><span class="line">8  False  False  False  False  False   True</span><br><span class="line">9  False  False  False  False  False  False</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>following command will select rows that has any null values</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">df[df.isnull().any(axis=1)]</span><br></pre></td></tr></table></figure><p>following command will select columns that has any null values</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">df[df.columns[df.isna().any()]]</span><br></pre></td></tr></table></figure><p>follwoing command will select rows that have null values for a specific column, e.g., column=3</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">df[df[3].isnull()]</span><br></pre></td></tr></table></figure><h1 id="Drop-null-values"><a href="#Drop-null-values" class="headerlink" title="Drop null values"></a>Drop null values</h1><blockquote><blockquote><blockquote><p>df = pd.DataFrame({“name”: [‘Alfred’, ‘Batman’, ‘Catwoman’],<br>…                    “toy”: [np.nan, ‘Batmobile’, ‘Bullwhip’],<br>…                    “born”: [pd.NaT, pd.Timestamp(“1940-04-25”),<br>…                             pd.NaT]})</p></blockquote></blockquote></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df</span><br><span class="line">       name        toy       born</span><br><span class="line">0    Alfred        NaN        NaT</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Drop the rows where at least one element is missing.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna()</span><br><span class="line">     name        toy       born</span><br><span class="line">1  Batman  Batmobile 1940-04-25</span><br></pre></td></tr></table></figure><p>Drop the columns where at least one element is missing.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(axis=&#x27;columns&#x27;)</span><br><span class="line">       name</span><br><span class="line">0    Alfred</span><br><span class="line">1    Batman</span><br><span class="line">2  Catwoman</span><br></pre></td></tr></table></figure><p>Drop the rows where all elements are missing.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(how=&#x27;all&#x27;)</span><br><span class="line">       name        toy       born</span><br><span class="line">0    Alfred        NaN        NaT</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Keep only the rows with at least 2 non-NA values.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(thresh=2)</span><br><span class="line">       name        toy       born</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Define in which columns to look for missing values.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(subset=[&#x27;name&#x27;, &#x27;toy&#x27;])</span><br><span class="line">       name        toy       born</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Keep the DataFrame with valid entries in the same variable.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(inplace=True)</span><br><span class="line">&gt;&gt;&gt; df</span><br><span class="line">     name        toy       born</span><br><span class="line">1  Batman  Batmobile 1940-04-25</span><br></pre></td></tr></table></figure><h1 id="Fill-missing-values"><a href="#Fill-missing-values" class="headerlink" title="Fill missing values"></a>Fill missing values</h1><p>Filling missing values using fillna(), replace() and interpolate()</p><p>In order to fill null values in a datasets, we use fillna(), replace() and interpolate() function these function replace NaN values with some value of their own. All these function help in filling a null values in datasets of a DataFrame. Interpolate() function is basically used to fill NA values in the dataframe but it uses various interpolation technique to fill the missing values rather than hard-coding the value.</p><p>Code #1: Filling null values with a single value</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling missing value using fillna()  </span><br><span class="line"></span><br><span class="line">df.fillna(0)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Code #2: Filling null values with the previous ones</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling a missing value with</span><br><span class="line"></span><br><span class="line"># previous ones  </span><br><span class="line"></span><br><span class="line">df.fillna(method =&#x27;pad&#x27;)</span><br></pre></td></tr></table></figure><p>Code #3: Filling null value with the next ones</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling  null value using fillna() function  </span><br><span class="line"></span><br><span class="line">df.fillna(method =&#x27;bfill&#x27;) </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> dataframe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>boost exact phrase search results ranking in elasticsearch</title>
      <link href="2021/06/05/2021-06-05-1/"/>
      <url>2021/06/05/2021-06-05-1/</url>
      
        <content type="html"><![CDATA[<p>Elasticsearch use the DSL format to create query.</p><p>One easy search is to use multi_match by passing the query key word, and give the fields to search for.</p><p>Here is an example:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">es = Elasticsearch()</span><br><span class="line">indexname = &#x27;myindex&#x27;</span><br><span class="line"></span><br><span class="line">keyword = &#x27;test&#x27;</span><br><span class="line">   dsl=&#123;</span><br><span class="line">       &quot;query&quot;: &#123;</span><br><span class="line">           &quot;multi_match&quot; : &#123;</span><br><span class="line">                   &quot;query&quot;:  keyword,</span><br><span class="line">                   &quot;fields&quot;: [ &quot;content&quot;]</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"> </span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">   dsize=10</span><br><span class="line">   result_r = es.search(index=indexname, body=dsl,size=dsize)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The problem with the above query is that:if your query keyword is a phrase, you might find many results that have the exact match are ranked lower.</p><p>To solve this problem, you might want to try this new dsl format:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dsl=&#123;</span><br><span class="line">   </span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">       &quot;bool&quot;: &#123;</span><br><span class="line">         &quot;must&quot;: [</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">                  &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ]</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">         ],</span><br><span class="line">         &quot;should&quot;: [</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">                  &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ],</span><br><span class="line">               &quot;type&quot;: &quot;phrase&quot;,</span><br><span class="line">               &quot;boost&quot;: 10</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;,</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">               &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ],</span><br><span class="line">               &quot;operator&quot;: &quot;and&quot;,</span><br><span class="line">               &quot;boost&quot;: 4</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">         ]</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">           </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>one thing to explain in the above the query, is the ‘operator’; According to the official elasticsearch webpage:</p><p>operator and minimum_should_match<br>The best_fields and most_fields types are field-centric — they generate a match query per field. This means that the operator and minimum_should_match parameters are applied to each field individually, which is probably not what you want.</p><p>Take this query for example:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot; : &#123;</span><br><span class="line">      &quot;query&quot;:      &quot;Will Smith&quot;,</span><br><span class="line">      &quot;type&quot;:       &quot;best_fields&quot;,</span><br><span class="line">      &quot;fields&quot;:     [ &quot;first_name&quot;, &quot;last_name&quot; ],</span><br><span class="line">      &quot;operator&quot;:   &quot;and&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This query is executed as:</p><p>  (+first_name:will +first_name:smith)<br>| (+last_name:will  +last_name:smith)</p><p>In other words, all terms must be present in a single field for a document to match.</p>]]></content>
      
      
      <categories>
          
          <category> search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>how to convert timestamp column of pandas dataframe into hour and day features using transformer</title>
      <link href="2021/06/04/2021-06-04-1/"/>
      <url>2021/06/04/2021-06-04-1/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">class dayandhour_Transformer(BaseEstimator, TransformerMixin):</span><br><span class="line"></span><br><span class="line">    # Class Constructor</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line"></span><br><span class="line">        print(&#x27;initialized&#x27;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Return self, nothing else to do here</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line"></span><br><span class="line">       return self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # Customized transformer method</span><br><span class="line"></span><br><span class="line">    def transform(self, X_, y=None):</span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line"></span><br><span class="line">        X[&#x27;dayofweek&#x27;]=pd.to_datetime(X[&#x27;timestamp&#x27;]).dt.dayofweek</span><br><span class="line"></span><br><span class="line">        X[&#x27;hour&#x27;]=pd.to_datetime(X[&#x27;timestamp&#x27;]).dt.hour</span><br><span class="line"></span><br><span class="line">        X = X.drop(&#x27;timestamp&#x27;,axis=1)</span><br><span class="line"></span><br><span class="line">        return X</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">dayandhour_transformer = dayandhour_Transformer() </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">df = dayandhour_transformer.transform(df)</span><br></pre></td></tr></table></figure><p>Suppose we have a dataframe df with a column “timestamp”.</p><p>before apply the code, we have:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(df[&#x27;timestamp&#x27;])</span><br><span class="line"></span><br><span class="line">0        2021-03-28 03:28:10.205000</span><br><span class="line"></span><br><span class="line">1        2021-03-28 21:31:43.290000</span><br><span class="line"></span><br><span class="line">2        2021-03-28 21:16:18.771000</span><br><span class="line"></span><br><span class="line">3        2021-03-28 18:39:13.344000</span><br><span class="line"></span><br><span class="line">4        2021-03-28 00:54:57.544000</span><br></pre></td></tr></table></figure><p>after we apply the code, we have:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print( df[[&#x27;hour&#x27;,&#x27;dayofweek&#x27;]])</span><br><span class="line"></span><br><span class="line">       hour  dayofweek</span><br><span class="line"></span><br><span class="line">0         3          6</span><br><span class="line"></span><br><span class="line">1        21          6</span><br><span class="line"></span><br><span class="line">2        21          6</span><br><span class="line"></span><br><span class="line">3        18          6</span><br><span class="line"></span><br><span class="line">4         0          6</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> preprocessing </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
