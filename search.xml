<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>time series feature engineering using tsfresh, training vs test</title>
      <link href="2021/06/10/2021-06-10-1/"/>
      <url>2021/06/10/2021-06-10-1/</url>
      
        <content type="html"><![CDATA[<p>During the test stage, i.e., once the model is on production, for any new data,<br>tsfresh feature generation does not depend the training data. So one can apply the same feature engineering process as the training data<br>without worrying about stroing information from training stage.</p><p>On ther hand, one can also use the following example to leverage scikit learn pipleline style to handel the feature generation<br>for both training and test stages.</p><h1 id="Feature-Selection-in-a-sklearn-pipeline"><a href="#Feature-Selection-in-a-sklearn-pipeline" class="headerlink" title="Feature Selection in a sklearn pipeline"></a>Feature Selection in a sklearn pipeline</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tsfresh.examples <span class="keyword">import</span> load_robot_execution_failures</span><br><span class="line"><span class="keyword">from</span> tsfresh.transformers <span class="keyword">import</span> RelevantFeatureAugmenter</span><br><span class="line"><span class="keyword">from</span> tsfresh.utilities.dataframe_functions <span class="keyword">import</span> impute</span><br></pre></td></tr></table></figure><h2 id="Load-and-Prepare-the-Data"><a href="#Load-and-Prepare-the-Data" class="headerlink" title="Load and Prepare the Data"></a>Load and Prepare the Data</h2><p>Check out the first example notebook to learn more about the data and format.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tsfresh.examples.robot_execution_failures <span class="keyword">import</span> download_robot_execution_failures</span><br><span class="line">download_robot_execution_failures() </span><br><span class="line">df_ts, y = load_robot_execution_failures()</span><br></pre></td></tr></table></figure><p>We want to use the extracted features to predict for each of the robot executions, if it was a failure or not.<br>Therefore our basic “entity” is a single robot execution given by a distinct <code>id</code>.</p><p>A dataframe with these identifiers as index needs to be prepared for the pipeline.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = pd.DataFrame(index=y.index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data into train and test set</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y)</span><br></pre></td></tr></table></figure><h2 id="Build-the-pipeline"><a href="#Build-the-pipeline" class="headerlink" title="Build the pipeline"></a>Build the pipeline</h2><p>We build a sklearn pipeline that consists of a feature extraction step (<code>RelevantFeatureAugmenter</code>) with a subsequent <code>RandomForestClassifier</code>.</p><p>The <code>RelevantFeatureAugmenter</code> takes roughly the same arguments as <code>extract_features</code> and <code>select_features</code> do.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ppl = Pipeline([</span><br><span class="line">        (<span class="string">&#x27;augmenter&#x27;</span>, RelevantFeatureAugmenter(column_id=<span class="string">&#x27;id&#x27;</span>, column_sort=<span class="string">&#x27;time&#x27;</span>)),</span><br><span class="line">        (<span class="string">&#x27;classifier&#x27;</span>, RandomForestClassifier())</span><br><span class="line">      ])</span><br></pre></td></tr></table></figure><div class="alert alert-warning">    <p>Here comes the tricky part!</p><p>The input to the pipeline will be our dataframe <code>X</code>, which one row per identifier.<br>It is currently empty.<br>But which time series data should the <code>RelevantFeatureAugmenter</code> to actually extract the features from?</p><p>We need to pass the time series data (stored in <code>df_ts</code>) to the transformer.</p></div><p>In this case, df_ts contains the time series of both train and test set, if you have different dataframes for<br>train and test set, you have to call set_params two times<br>(see further below on how to deal with two independent data sets)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts);</span><br></pre></td></tr></table></figure><p>We are now ready to fit the pipeline</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ppl.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><p>The augmenter has used the input time series data to extract time series features for each of the identifiers in the <code>X_train</code> and selected only the relevant ones using the passed <code>y_train</code> as target.<br>These features have been added to <code>X_train</code> as new columns.<br>The classifier can now use these features during trainings.</p><h2 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h2><p>During interference, the augmentor does only extract the relevant features it has found out in the training phase and the classifier predicts the target using these features.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = ppl.predict(X_test)</span><br></pre></td></tr></table></figure><p>So, finally we inspect the performance:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure><p>You can also find out, which columns the augmenter has selected</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ppl.named_steps[<span class="string">&quot;augmenter&quot;</span>].feature_selector.relevant_features</span><br></pre></td></tr></table></figure><div class="alert alert-info">    <p>In this example we passed in an empty (except the index) <code>X_train</code> or <code>X_test</code> into the pipeline.<br>However, you can also fill the input with other features you have (e.g. features extracted from the metadata)<br>or even use other pipeline components before.</p></div><h2 id="Separating-the-time-series-data-containers"><a href="#Separating-the-time-series-data-containers" class="headerlink" title="Separating the time series data containers"></a>Separating the time series data containers</h2><p>In the example above we passed in a single <code>df_ts</code> into the <code>RelevantFeatureAugmenter</code>, which was used both for training and predicting.<br>During training, only the data with the <code>id</code>s from <code>X_train</code> where extracted and during prediction the rest.</p><p>However, it is perfectly fine to call <code>set_params</code> twice: once before training and once before prediction.<br>This can be handy if you for example dump the trained pipeline to disk and re-use it only later for prediction.<br>You only need to make sure that the <code>id</code>s of the enteties you use during training/prediction are actually present in the passed time series data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_ts_train = df_ts[df_ts[<span class="string">&quot;id&quot;</span>].isin(y_train.index)]</span><br><span class="line">df_ts_test = df_ts[df_ts[<span class="string">&quot;id&quot;</span>].isin(y_test.index)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts_train);</span><br><span class="line">ppl.fit(X_train, y_train);</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;pipeline.pkl&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(ppl, f)</span><br></pre></td></tr></table></figure><p>Later: load the fitted model and do predictions on new, unseen data</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;pipeline.pkl&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    ppk = pickle.load(f)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ppl.set_params(augmenter__timeseries_container=df_ts_test);</span><br><span class="line">y_pred = ppl.predict(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> preprocessing </tag>
            
            <tag> pipeline </tag>
            
            <tag> tsfresh </tag>
            
            <tag> time series </tag>
            
            <tag> feature engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>word tokenization and sentence tokenization in python using NLTK package</title>
      <link href="2021/06/09/2021-06-09-1/"/>
      <url>2021/06/09/2021-06-09-1/</url>
      
        <content type="html"><![CDATA[<h1 id="What-is-Tokenization"><a href="#What-is-Tokenization" class="headerlink" title="What is Tokenization?"></a>What is Tokenization?</h1><p>Tokenization is the process by which a large quantity of text is divided into smaller parts called tokens.<br>These tokens are very useful for finding patterns and are considered as a base step for stemming and lemmatization.<br>Tokenization also helps to substitute sensitive data elements with non-sensitive data elements.</p><p>Natural language processing is used for building applications such as Text classification, intelligent chatbot, sentimental analysis, language translation, etc.<br>It becomes vital to understand the pattern in the text to achieve the above-stated purpose.</p><h1 id="Tokenization-of-words"><a href="#Tokenization-of-words" class="headerlink" title="Tokenization of words"></a>Tokenization of words</h1><p>We use the method word_tokenize() to split a sentence into words.<br>The output of word tokenization can be converted to Data Frame for better text understanding in machine learning applications.<br>It can also be provided as input for further text cleaning steps such as punctuation removal, numeric character removal or stemming.</p><p>Code example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from nltk.tokenize import word_tokenize</span><br><span class="line">text = &quot;God is Great! I won a lottery.&quot;</span><br><span class="line">print(word_tokenize(text))</span><br><span class="line"></span><br><span class="line">Output: [&#x27;God&#x27;, &#x27;is&#x27;, &#x27;Great&#x27;, &#x27;!&#x27;, &#x27;I&#x27;, &#x27;won&#x27;, &#x27;a&#x27;, &#x27;lottery&#x27;, &#x27;.&#x27;]</span><br></pre></td></tr></table></figure><p>From the above example, one can see the punctuationa are also included. Sometimes we want to exclude that.<br>To achieve this purpose, there are two ways:</p><h2 id="USE-nltk-RegexpTokenizer-TO-REMOVE-ALL-PUNCTUATION-MARKS"><a href="#USE-nltk-RegexpTokenizer-TO-REMOVE-ALL-PUNCTUATION-MARKS" class="headerlink" title="USE nltk.RegexpTokenizer() TO REMOVE ALL PUNCTUATION MARKS"></a>USE nltk.RegexpTokenizer() TO REMOVE ALL PUNCTUATION MARKS</h2><p>Call nltk.RegexpTokenizer(pattern) with pattern as r”\w+” to create a tokenzier that uses pattern to split a string.<br>Call RegexpTokenizer.tokenize(text) with RegexpTokenizer as the previous result and text as a string representing a sentence to return text as a list of words with punctuation’s removed.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sentence  = &quot;Think and wonder, wonder and think.&quot;</span><br><span class="line"></span><br><span class="line">tokenizer = nltk.RegexpTokenizer(r&quot;\w+&quot;)</span><br><span class="line">new_words = tokenizer.tokenize(sentence)</span><br><span class="line"></span><br><span class="line">print(new_words)</span><br><span class="line">OUTPUT</span><br><span class="line">[&#x27;Think&#x27;, &#x27;and&#x27;, &#x27;wonder&#x27;, &#x27;wonder&#x27;, &#x27;and&#x27;, &#x27;think&#x27;]</span><br></pre></td></tr></table></figure><h2 id="USE-nltk-word-tokenize-AND-LIST-COMPREHENSION-TO-REMOVE-ALL-PUNCTUATION-MARKS"><a href="#USE-nltk-word-tokenize-AND-LIST-COMPREHENSION-TO-REMOVE-ALL-PUNCTUATION-MARKS" class="headerlink" title="USE nltk.word_tokenize() AND LIST COMPREHENSION TO REMOVE ALL PUNCTUATION MARKS"></a>USE nltk.word_tokenize() AND LIST COMPREHENSION TO REMOVE ALL PUNCTUATION MARKS</h2><p>Call nltk.word_tokenize(text) with text as a string representing a sentence to return text as a list of words. Use the syntax [word for word in words if condition] with words as the previous result and condition as word.isalnum() to create a list containing each word in words that only contain alphanumeric characters.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sentence  = &quot;Think and wonder, wonder and think.&quot;</span><br><span class="line"></span><br><span class="line">words = nltk.word_tokenize(sentence)</span><br><span class="line">new_words= [word for word in words if word.isalnum()]</span><br><span class="line"></span><br><span class="line">print(new_words)</span><br><span class="line">OUTPUT</span><br><span class="line">[&#x27;Think&#x27;, &#x27;and&#x27;, &#x27;wonder&#x27;, &#x27;wonder&#x27;, &#x27;and&#x27;, &#x27;think&#x27;]</span><br></pre></td></tr></table></figure><h1 id="Tokenization-of-Sentences"><a href="#Tokenization-of-Sentences" class="headerlink" title="Tokenization of Sentences"></a>Tokenization of Sentences</h1><p>Sometimes you need to get sentences out of the texts at first.</p><p>Code example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from nltk.tokenize import sent_tokenize</span><br><span class="line">text = &quot;God is Great! I won a lottery.&quot;</span><br><span class="line">print(sent_tokenize(text))</span><br><span class="line"></span><br><span class="line">Output: [&#x27;God is Great!&#x27;, &#x27;I won a lottery &#x27;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tokenization </tag>
            
            <tag> NLTK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>missing value or null value processing in pandas dataframe</title>
      <link href="2021/06/08/2021-06-08-1/"/>
      <url>2021/06/08/2021-06-08-1/</url>
      
        <content type="html"><![CDATA[<h1 id="obtain-null-or-missing-values-of-a-dataframe"><a href="#obtain-null-or-missing-values-of-a-dataframe" class="headerlink" title="obtain null or missing values of a dataframe"></a>obtain null or missing values of a dataframe</h1><p>Suppose the dataframe has the following formats, with 10 rows and 5 clomns:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">          0         1         2         3         4         5</span><br><span class="line">0  0.520113  0.884000  1.260966 -0.236597  0.312972 -0.196281</span><br><span class="line">1 -0.837552       NaN  0.143017  0.862355  0.346550  0.842952</span><br><span class="line">2 -0.452595       NaN -0.420790  0.456215  1.203459  0.527425</span><br><span class="line">3  0.317503 -0.917042  1.780938 -1.584102  0.432745  0.389797</span><br><span class="line">4 -0.722852  1.704820 -0.113821 -1.466458  0.083002  0.011722</span><br><span class="line">5 -0.622851 -0.251935 -1.498837       NaN  1.098323  0.273814</span><br><span class="line">6  0.329585  0.075312 -0.690209 -3.807924  0.489317 -0.841368</span><br><span class="line">7 -1.123433 -1.187496  1.868894 -2.046456 -0.949718       NaN</span><br><span class="line">8  1.133880 -0.110447  0.050385 -1.158387  0.188222       NaN</span><br><span class="line">9 -0.513741  1.196259  0.704537  0.982395 -0.585040 -1.693810</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>the isnull() function which would return a dataframe like this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">       0      1      2      3      4      5</span><br><span class="line">0  False  False  False  False  False  False</span><br><span class="line">1  False   True  False  False  False  False</span><br><span class="line">2  False   True  False  False  False  False</span><br><span class="line">3  False  False  False  False  False  False</span><br><span class="line">4  False  False  False  False  False  False</span><br><span class="line">5  False  False  False   True  False  False</span><br><span class="line">6  False  False  False  False  False  False</span><br><span class="line">7  False  False  False  False  False   True</span><br><span class="line">8  False  False  False  False  False   True</span><br><span class="line">9  False  False  False  False  False  False</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>following command will select rows that has any null values</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df.isnull().any(axis=1)]</span><br></pre></td></tr></table></figure><p>following command will select columns that has any null values</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df.columns[df.isna().any()]]</span><br></pre></td></tr></table></figure><p>follwoing command will select rows that have null values for a specific column, e.g., column=3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df[3].isnull()]</span><br></pre></td></tr></table></figure><h1 id="Drop-null-values"><a href="#Drop-null-values" class="headerlink" title="Drop null values"></a>Drop null values</h1><blockquote><blockquote><blockquote><p>df = pd.DataFrame({“name”: [‘Alfred’, ‘Batman’, ‘Catwoman’],<br>…                    “toy”: [np.nan, ‘Batmobile’, ‘Bullwhip’],<br>…                    “born”: [pd.NaT, pd.Timestamp(“1940-04-25”),<br>…                             pd.NaT]})</p></blockquote></blockquote></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df</span><br><span class="line">       name        toy       born</span><br><span class="line">0    Alfred        NaN        NaT</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Drop the rows where at least one element is missing.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna()</span><br><span class="line">     name        toy       born</span><br><span class="line">1  Batman  Batmobile 1940-04-25</span><br></pre></td></tr></table></figure><p>Drop the columns where at least one element is missing.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(axis=&#x27;columns&#x27;)</span><br><span class="line">       name</span><br><span class="line">0    Alfred</span><br><span class="line">1    Batman</span><br><span class="line">2  Catwoman</span><br></pre></td></tr></table></figure><p>Drop the rows where all elements are missing.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(how=&#x27;all&#x27;)</span><br><span class="line">       name        toy       born</span><br><span class="line">0    Alfred        NaN        NaT</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Keep only the rows with at least 2 non-NA values.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(thresh=2)</span><br><span class="line">       name        toy       born</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Define in which columns to look for missing values.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(subset=[&#x27;name&#x27;, &#x27;toy&#x27;])</span><br><span class="line">       name        toy       born</span><br><span class="line">1    Batman  Batmobile 1940-04-25</span><br><span class="line">2  Catwoman   Bullwhip        NaT</span><br></pre></td></tr></table></figure><p>Keep the DataFrame with valid entries in the same variable.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; df.dropna(inplace=True)</span><br><span class="line">&gt;&gt;&gt; df</span><br><span class="line">     name        toy       born</span><br><span class="line">1  Batman  Batmobile 1940-04-25</span><br></pre></td></tr></table></figure><h1 id="Fill-missing-values"><a href="#Fill-missing-values" class="headerlink" title="Fill missing values"></a>Fill missing values</h1><p>Filling missing values using fillna(), replace() and interpolate()</p><p>In order to fill null values in a datasets, we use fillna(), replace() and interpolate() function these function replace NaN values with some value of their own. All these function help in filling a null values in datasets of a DataFrame. Interpolate() function is basically used to fill NA values in the dataframe but it uses various interpolation technique to fill the missing values rather than hard-coding the value.</p><p>Code #1: Filling null values with a single value</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling missing value using fillna()  </span><br><span class="line"></span><br><span class="line">df.fillna(0)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Code #2: Filling null values with the previous ones</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling a missing value with</span><br><span class="line"></span><br><span class="line"># previous ones  </span><br><span class="line"></span><br><span class="line">df.fillna(method =&#x27;pad&#x27;)</span><br></pre></td></tr></table></figure><p>Code #3: Filling null value with the next ones</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># importing pandas as pd</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># importing numpy as np</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># dictionary of lists</span><br><span class="line"></span><br><span class="line">dict = &#123;&#x27;First Score&#x27;:[100, 90, np.nan, 95],</span><br><span class="line"></span><br><span class="line">        &#x27;Second Score&#x27;: [30, 45, 56, np.nan],</span><br><span class="line"></span><br><span class="line">        &#x27;Third Score&#x27;:[np.nan, 40, 80, 98]&#125;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># creating a dataframe from dictionary</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(dict)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># filling  null value using fillna() function  </span><br><span class="line"></span><br><span class="line">df.fillna(method =&#x27;bfill&#x27;) </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> dataframe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>boost exact phrase search results ranking in elasticsearch</title>
      <link href="2021/06/05/2021-06-05-1/"/>
      <url>2021/06/05/2021-06-05-1/</url>
      
        <content type="html"><![CDATA[<p>Elasticsearch use the DSL format to create query.</p><p>One easy search is to use multi_match by passing the query key word, and give the fields to search for.</p><p>Here is an example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">es = Elasticsearch()</span><br><span class="line">indexname = &#x27;myindex&#x27;</span><br><span class="line"></span><br><span class="line">keyword = &#x27;test&#x27;</span><br><span class="line">   dsl=&#123;</span><br><span class="line">       &quot;query&quot;: &#123;</span><br><span class="line">           &quot;multi_match&quot; : &#123;</span><br><span class="line">                   &quot;query&quot;:  keyword,</span><br><span class="line">                   &quot;fields&quot;: [ &quot;content&quot;]</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"> </span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">   dsize=10</span><br><span class="line">   result_r = es.search(index=indexname, body=dsl,size=dsize)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The problem with the above query is that:if your query keyword is a phrase, you might find many results that have the exact match are ranked lower.</p><p>To solve this problem, you might want to try this new dsl format:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">dsl=&#123;</span><br><span class="line">   </span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">       &quot;bool&quot;: &#123;</span><br><span class="line">         &quot;must&quot;: [</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">                  &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ]</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">         ],</span><br><span class="line">         &quot;should&quot;: [</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">                  &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ],</span><br><span class="line">               &quot;type&quot;: &quot;phrase&quot;,</span><br><span class="line">               &quot;boost&quot;: 10</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;,</span><br><span class="line">           &#123;</span><br><span class="line">             &quot;multi_match&quot;: &#123;</span><br><span class="line">               &quot;query&quot;: keyword,</span><br><span class="line">               &quot;fields&quot;: [</span><br><span class="line">               &quot;content1&quot;,&quot;content2&quot;</span><br><span class="line">               ],</span><br><span class="line">               &quot;operator&quot;: &quot;and&quot;,</span><br><span class="line">               &quot;boost&quot;: 4</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">         ]</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">           </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>one thing to explain in the above the query, is the ‘operator’; According to the official elasticsearch webpage:</p><p>operator and minimum_should_match<br>The best_fields and most_fields types are field-centric — they generate a match query per field. This means that the operator and minimum_should_match parameters are applied to each field individually, which is probably not what you want.</p><p>Take this query for example:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot; : &#123;</span><br><span class="line">      &quot;query&quot;:      &quot;Will Smith&quot;,</span><br><span class="line">      &quot;type&quot;:       &quot;best_fields&quot;,</span><br><span class="line">      &quot;fields&quot;:     [ &quot;first_name&quot;, &quot;last_name&quot; ],</span><br><span class="line">      &quot;operator&quot;:   &quot;and&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This query is executed as:</p><p>  (+first_name:will +first_name:smith)<br>| (+last_name:will  +last_name:smith)</p><p>In other words, all terms must be present in a single field for a document to match.</p>]]></content>
      
      
      <categories>
          
          <category> search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>how to convert timestamp column of pandas dataframe into hour and day features using transformer</title>
      <link href="2021/06/04/2021-06-04-1/"/>
      <url>2021/06/04/2021-06-04-1/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">class dayandhour_Transformer(BaseEstimator, TransformerMixin):</span><br><span class="line"></span><br><span class="line">    # Class Constructor</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line"></span><br><span class="line">        print(&#x27;initialized&#x27;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    # Return self, nothing else to do here</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line"></span><br><span class="line">       return self</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # Customized transformer method</span><br><span class="line"></span><br><span class="line">    def transform(self, X_, y=None):</span><br><span class="line"></span><br><span class="line">        X = X_.copy()</span><br><span class="line"></span><br><span class="line">        X[&#x27;dayofweek&#x27;]=pd.to_datetime(X[&#x27;timestamp&#x27;]).dt.dayofweek</span><br><span class="line"></span><br><span class="line">        X[&#x27;hour&#x27;]=pd.to_datetime(X[&#x27;timestamp&#x27;]).dt.hour</span><br><span class="line"></span><br><span class="line">        X = X.drop(&#x27;timestamp&#x27;,axis=1)</span><br><span class="line"></span><br><span class="line">        return X</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">dayandhour_transformer = dayandhour_Transformer() </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">df = dayandhour_transformer.transform(df)</span><br></pre></td></tr></table></figure><p>Suppose we have a dataframe df with a column “timestamp”.</p><p>before apply the code, we have:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(df[&#x27;timestamp&#x27;])</span><br><span class="line"></span><br><span class="line">0        2021-03-28 03:28:10.205000</span><br><span class="line"></span><br><span class="line">1        2021-03-28 21:31:43.290000</span><br><span class="line"></span><br><span class="line">2        2021-03-28 21:16:18.771000</span><br><span class="line"></span><br><span class="line">3        2021-03-28 18:39:13.344000</span><br><span class="line"></span><br><span class="line">4        2021-03-28 00:54:57.544000</span><br></pre></td></tr></table></figure><p>after we apply the code, we have:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print( df[[&#x27;hour&#x27;,&#x27;dayofweek&#x27;]])</span><br><span class="line"></span><br><span class="line">       hour  dayofweek</span><br><span class="line"></span><br><span class="line">0         3          6</span><br><span class="line"></span><br><span class="line">1        21          6</span><br><span class="line"></span><br><span class="line">2        21          6</span><br><span class="line"></span><br><span class="line">3        18          6</span><br><span class="line"></span><br><span class="line">4         0          6</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> pandas </tag>
            
            <tag> preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
